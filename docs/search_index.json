[["index.html", "Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos 1 Presentación del Bookdown", " Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos Fredy A. Ordoñez · Oscar F. Velásquez · José L. Sánchez 17 de noviembre de 2025 1 Presentación del Bookdown Este Bookdown recopila las actividades desarrolladas a lo largo del curso de Series de Tiempo. Cada capítulo corresponde a una entrega o avance del proyecto, permitiendo evidenciar el progreso del análisis, los modelos aplicados y las conclusiones del trabajo final. ## NULL "],["propuesta.html", "2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? 2.2 ¿Por qué es importante? 2.3 Fuente de datos y permisos 2.4 Impacto esperado 2.5 Referencias", " 2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? La demanda eléctrica de corto plazo (1 hora adelante) en una subestación de distribución, usando la serie de potencia activa (kW) con resolución horaria. 2.2 ¿Por qué es importante? Operación eficiente: anticipar picos para evitar sobrecargas y maniobras reactivas. Calidad del servicio (SAIDI/SAIFI): programar mantenimientos y gestionar eventos reduciendo frecuencia y duración de interrupciones.SAIFI (System Average Interruption Frequency Index) indica la frecuencia promedio de las interrupciones que un cliente experimenta en un período determinado (por ejemplo, cuántas veces se va la luz al año), y el SAIDI (System Average Interruption Duration Index) mide la duración promedio acumulada de esas interrupciones para un cliente en ese mismo período (cuánto tiempo en total está sin servicio). Valor agregado: entregar una plantilla reproducible (scripts, métricas y gráficos) que soporte decisiones operativas. 2.3 Fuente de datos y permisos Fuente: datos SCADA históricos del operador de red de una subestación específica resolución horaria. Permisos: uso académico con anonimización de subestación y operador; no se publican datos crudos, solo resultados agregados y visualizaciones. Alcance: una subestación; análisis offline (sin integración en tiempo real). 2.4 Impacto esperado Técnico: reducción de error frente a métodos manuales; soporte a decisiones en turnos. Económico: mejor dimensionamiento de respaldo y diferimiento de inversiones. Académico: caso replicable en otras subestaciones con datos equivalentes. 2.5 Referencias Hyndman, R. &amp; Athanasopoulos (2018). Forecasting: Principles and Practice (3ª). Box, G. et al. (2015). Time Series Analysis: Forecasting and Control (5ª). Zhang, H. et al. (2019). “Short-term Load Forecasting Using LSTM Networks”, IEEE TSG. Herramienta TIC: Bookdown + GitHub Pages Sitio: https://joseluissanchezceballos.github.io/TimeSeries/propuesta.html Repo: https://github.com/joseluissanchezceballos/TimeSeries "],["análisis-de-serie-de-tiempo-potencia-eléctrica-horaria.html", "3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos 3.2 Cargue de Librerías 3.3 Lectura y preparación de los datos 3.4 Funciones auxiliares de visualización de la serie de tiempo 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) 3.7 Promedios móviles 3.8 Rezagos (lags) y autocorrelación 3.9 Estacionalidad (gráficos y descomposición) 3.10 Indicadores resumidos 3.11 Conclusiones", " 3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos El estudio analiza una serie temporal de potencia eléctrica horaria entre 2018 y 2025. El objetivo fue detectar patrones, ciclos y estacionalidades usando herramientas de R (lubridate, zoo, forecast) y visualizar la calidad de los datos (huecos, tendencias, estacionalidad, rezagos). El conjunto de datos es altamente completo: Completitud global: 99.48%. Años con menos completitud: 2019 (97.9%) y 2021 (99.4%). Años recientes (2022–2025): 100% de registros, sin huecos. La idea es detectar patrones y ciclos del comportamiento de la potencia eléctrica. 3.2 Cargue de Librerías library(readr) library(dplyr) ## ## Adjuntando el paquete: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(tidyr) library(lubridate) ## ## Adjuntando el paquete: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(ggplot2) library(scales) ## ## Adjuntando el paquete: &#39;scales&#39; ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor library(zoo) ## ## Adjuntando el paquete: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo 3.3 Lectura y preparación de los datos csv_dir &lt;- &quot;C:/Users/Lenovo/PUJ Cali/OSCAR VELASQUEZ CHALA - Proyecto Aplicado - Proy. Demanda Electrica/2. Fuentes de Datos&quot; csv_name &lt;- &quot;015 SOLO POTENCIA PARA SUBI A BOOKDOWN.csv&quot; csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot; y_col &lt;- &quot;VALOR_IMPUTADO&quot; TZ &lt;- &quot;America/Bogota&quot; # Lectura robusta df &lt;- tryCatch( readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE) ) stopifnot(time_col %in% names(df), y_col %in% names(df)) # Parseo de fechas (varios formatos) df[[time_col]] &lt;- parse_date_time( df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ ) # A numérico df[[y_col]] &lt;- suppressWarnings(readr::parse_number(as.character(df[[y_col]]))) # Malla horaria completa (sin imputar, para marcar huecos) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% select(!!time_col, !!y_col) %&gt;% arrange(.data[[time_col]]) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) summary(df_full[[y_col]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0 1241 3550 3244 4996 10000 610 cat(&quot;Proporción de NA:&quot;, mean(is.na(df_full[[y_col]])), &quot;\\n&quot;) ## Proporción de NA: 0.005141302 3.4 Funciones auxiliares de visualización de la serie de tiempo # Unir horas NA contiguas en bandas na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% dplyr::filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } # Agregación genérica sin imputar tagrega &lt;- function(data, unit, time_col, y_col, tz = TZ) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) } 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) plot_df &lt;- bind_rows( tagrega(df_full, &quot;day&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Diaria&quot;), tagrega(df_full, &quot;week&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Semanal&quot;), tagrega(df_full, &quot;month&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Mensual&quot;), tagrega(df_full, &quot;year&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Anual&quot;) ) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;,&quot;Semanal&quot;,&quot;Mensual&quot;,&quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.25) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.7, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + scale_x_datetime(labels = date_format(&quot;%Y&quot;), date_breaks = &quot;1 year&quot;) + labs(title = &quot;Potencia con huecos (NA)&quot;, subtitle = &quot;Bandas rojas = periodos con NA en la serie horaria original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Curva de Potencia Diaria: muestra alta variabilidad horaria con picos bien definidos, evidenciando que la potencia cambia fuertemente a lo largo del día. Curva de Potencia Semanal: suaviza los ciclos, pero aún se aprecian repeticiones cada pocos días, sugiriendo un patrón operativo estable. Curva de Potencia Mensual: las oscilaciones se atenúan, revelando la tendencia global; los huecos rojos (NA) se observan concentrados en pocos periodos. Curva de Potencia Anual: la línea muestra el comportamiento global a largo rango: valores medios estables sin deriva significativa, lo que sugiere una operación controlada y sin aumento sostenido del consumo. La serie mantiene un patrón estacional fuerte (diario y semanal) y una tendencia global estacionaria. Los huecos (en rojo) son mínimos y no distorsionan las medias agregadas. 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) # Día dia_obj &lt;- as.Date(&quot;2023-02-01&quot;) ini_dia &lt;- as.POSIXct(dia_obj, tz = TZ); fin_dia &lt;- ini_dia + days(1) df_day &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_dia, .data[[time_col]] &lt; fin_dia) na_day &lt;- na_spans_runs(df_day[[time_col]], df_day$is_na) g_day &lt;- ggplot() + geom_rect(data = na_day, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_day, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_dia, fin_dia), date_labels=&quot;%H:%M&quot;, breaks=seq(ini_dia, fin_dia, by=&quot;2 hour&quot;)) + labs(title=paste0(&quot;Curva horaria — &quot;, dia_obj), x=&quot;Hora&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_day Día: 1 febrero 2023:Curva con forma sinusoidal: potencia baja en la madrugada, aumento progresivo durante el día, pico en horas centrales y descenso nocturno. Refleja un ciclo operativo típico diario. # Semana semana_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_sem &lt;- as.POSIXct(floor_date(semana_ref, &quot;week&quot;, week_start=1), tz=TZ) fin_sem &lt;- ini_sem + weeks(1) df_week &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_sem, .data[[time_col]] &lt; fin_sem) na_week &lt;- na_spans_runs(df_week[[time_col]], df_week$is_na) g_week &lt;- ggplot() + geom_rect(data = na_week, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_week, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_sem, fin_sem), date_labels=&quot;%a %d&quot;, breaks=seq(ini_sem, fin_sem, by=&quot;1 day&quot;)) + labs(title=paste0(&quot;Semana del &quot;, ini_sem), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_week Semana: 1–7 febrero 2021: Repetición diaria clara, pero con leves diferencias entre días. Puede reflejar cambios de carga entre jornadas laborales y fines de semana. # Mes mes_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_mes &lt;- as.POSIXct(floor_date(mes_ref, &quot;month&quot;), tz=TZ); fin_mes &lt;- as.POSIXct(ceiling_date(mes_ref, &quot;month&quot;), tz=TZ) df_month &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_mes, .data[[time_col]] &lt; fin_mes) na_month &lt;- na_spans_runs(df_month[[time_col]], df_month$is_na) g_month &lt;- ggplot() + geom_rect(data = na_month, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.25) + geom_line(data = filter(df_month, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.6) + scale_x_datetime(limits=c(ini_mes, fin_mes), date_labels=&quot;%d-%b&quot;, breaks=seq(ini_mes, fin_mes, by=&quot;3 days&quot;)) + labs(title=paste0(&quot;Mes &quot;, format(ini_mes, &#39;%Y-%m&#39;)), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_month Mes: febrero 2021: Patrón reiterado de picos semanales. Los huecos rojos (NA) marcan interrupciones puntuales sin afectar la tendencia global. # Año (panel único) anio_ref &lt;- 2021 ini_anio &lt;- as.POSIXct(ymd(paste0(anio_ref, &quot;-01-01&quot;)), tz=TZ); fin_anio &lt;- as.POSIXct(ymd(paste0(anio_ref+1, &quot;-01-01&quot;)), tz=TZ) df_year &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_anio, .data[[time_col]] &lt; fin_anio) na_year &lt;- na_spans_runs(df_year[[time_col]], df_year$is_na) g_year &lt;- ggplot() + geom_rect(data = na_year, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.20) + geom_line(data = filter(df_year, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.3) + scale_x_datetime(limits=c(ini_anio, fin_anio), date_labels=&quot;%b&quot;, breaks=seq(ini_anio, fin_anio, by=&quot;1 month&quot;)) + labs(title=paste0(&quot;Año &quot;, anio_ref), x=&quot;Mes&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_year Año: 2021: Oscilaciones estacionales sin tendencia definida. No se observan desviaciones estructurales. A nivel temporal, la potencia responde a ciclos regulares con comportamiento casi periódico. 3.7 Promedios móviles Promedios móviles sobre la serie horaria (imputada solo para continuidad visual con na.interp). # --- Promedios móviles coloreados (24h, 168h, 720h) --- # 1) Crea la serie imputada y los MAs df_impu &lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) df_ma &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), `MA 24h` = zoo::rollmean(val_impu, k = 24, align = &quot;right&quot;, fill = NA), `MA 168h` = zoo::rollmean(val_impu, k = 168, align = &quot;right&quot;, fill = NA), `MA 720h` = zoo::rollmean(val_impu, k = 720, align = &quot;right&quot;, fill = NA) ) # 2) Pasar los MAs a formato largo para mapear color por serie library(tidyr) df_ma_long &lt;- df_ma %&gt;% tidyr::pivot_longer(cols = c(`MA 24h`,`MA 168h`,`MA 720h`), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) # 3) Graficar: original en gris, MAs en colores ggplot(df_ma, aes(x = time)) + # Serie original geom_line(aes(y = y), color = &quot;grey80&quot;, linewidth = 0.2, alpha = 0.6) + # Promedio móvil corto (24h) — se dibuja primero geom_line(aes(y = `MA 24h`), color = &quot;#1f77b4&quot;, linewidth = 0.6, alpha = 0.8) + # Promedio móvil intermedio (168h) — encima de la azul geom_line(aes(y = `MA 168h`), color = &quot;#2ca02c&quot;, linewidth = 0.9, alpha = 0.9) + # Promedio móvil largo (720h) — encima de las anteriores geom_line(aes(y = `MA 720h`), color = &quot;#d62728&quot;, linewidth = 1.1, alpha = 1) + labs( title = &quot;Promedios móviles (24h, 168h, 720h)&quot;, subtitle = &quot;Curvas suavizadas de corto, mediano y largo plazo&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;)) La línea gris (serie original) muestra picos horarios abruptos. La línea azul (media móvil 24h) suaviza el ruido diario. La línea verde (media móvil 168h) identifica la tendencia semanal. La línea roja (media móvil 720h) resume la tendencia mensual. No se observan rupturas ni tendencias marcadas. Las tres medias convergen en un rango estable. 3.8 Rezagos (lags) y autocorrelación # --- Rezagos a nivel horario (1, 24, 168, 720) --- df_lags &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), lag_1 = dplyr::lag(as.numeric(val_impu), 1), lag_24 = dplyr::lag(as.numeric(val_impu), 24), lag_168 = dplyr::lag(as.numeric(val_impu), 168), lag_720 = dplyr::lag(as.numeric(val_impu), 720) ) # Correlaciones cors &lt;- c( cor(df_lags$y, df_lags$lag_1, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_24, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_168, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_720, use = &quot;complete.obs&quot;) ) setNames(round(cors, 3), c(&quot;lag1&quot;,&quot;lag24&quot;,&quot;lag168&quot;,&quot;lag720&quot;)) ## lag1 lag24 lag168 lag720 ## 0.977 0.802 0.766 0.749 Lag 1: 0.977 → fuerte dependencia entre horas consecutivas. Lag 24: 0.802 → patrón diario repetitivo. Lag 168: 0.766 → correlación semanal clara. Lag 720: 0.749 → correlación mensual aún significativa. Los altos valores confirman una autocorrelación fuerte y múltiple (hora, día, semana, mes). Esto valida la presencia de estacionalidad múltiple y un comportamiento cíclico persistente. #ACF y PACF: Análisis de Autocorrelación library(ggplot2) # 1) Serie imputada -&gt; vector numérico sin NA serie_vec &lt;- as.numeric(df_impu$val_impu) serie_vec &lt;- serie_vec[!is.na(serie_vec)] # 2) Definir lag máximo (p.ej. 30 días = 24*30) max_lag &lt;- 24 * 30 # 3) Calcular ACF y PACF sin graficar acf_obj &lt;- acf(serie_vec, lag.max = max_lag, plot = FALSE) pacf_obj &lt;- pacf(serie_vec, lag.max = max_lag, plot = FALSE) # 4) Pasar a data frame (ojo: ambos traen valores en $acf) acf_df &lt;- data.frame( lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf) ) pacf_df &lt;- data.frame( lag = as.numeric(pacf_obj$lag), # lags desde 1 normalmente pacf = as.numeric(pacf_obj$acf) # valores de PACF están en $acf ) # 5) Bandas de confianza 95% n_eff &lt;- length(serie_vec) ci &lt;- 1.96 / sqrt(n_eff) # 6) Graficar con ggplot2 # --- ACF --- ggplot(acf_df, aes(x = lag, y = acf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;ACF - Autocorrelación de la serie horaria&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal(base_size = 12) El gráfico ACF muestra la correlación de la serie de potencia horaria consigo misma a diferentes rezagos (lags), medidos en horas. En el rezago 0 la autocorrelación es 1, cada punto está completamente correlacionado consigo mismo. Se observa una autocorrelación muy alta y sostenida en casi todos los rezagos, con valores cercanos a 0.75–0.80 hasta aproximadamente 700 horas (~30 días). Esta persistencia indica que la serie mantiene una dependencia temporal fuerte, es decir, los valores pasados tienen gran influencia sobre los futuros. Se aprecian picos regulares (aprox. cada 24, 168 y 720 rezagos), lo que evidencia patrones estacionales diarios, semanales y mensuales. Las bandas rojas horizontales representan los límites de significancia al 95% (±0.006). Todos los valores de la ACF están muy por encima de esas bandas, lo que confirma que la autocorrelación es estadísticamente significativa en todos los horizontes analizados. La serie presenta una estructura fuertemente autocorrelacionada, con periodicidad marcada y ciclos regulares. Esto indica que no es una serie puramente aleatoria, sino que está dominada por una estacionalidad sistemática de carácter diario y semanal. # --- PACF --- ggplot(pacf_df, aes(x = lag, y = pacf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;PACF - Autocorrelación parcial&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal(base_size = 12) El gráfico PACF muestra la correlación entre la serie y sus rezagos una vez eliminada la influencia de los rezagos intermedios. Se observa un pico alto en el primer rezago (lag = 1), lo que indica una fuerte dependencia inmediata (efecto de la hora anterior). Después del primer rezago, los valores de la PACF caen rápidamente y se mantienen cerca de cero, salvo algunos picos débiles en rezagos aproximadamente iguales a 24, 168 y 720 horas, que corresponden a efectos estacionales. Estos picos secundarios son pequeños pero significativos, lo que sugiere una estacionalidad múltiple (día, semana, mes). La PACF confirma que el comportamiento actual de la potencia depende principalmente de su valor en la hora anterior (AR(1)), junto con componentes estacionales de largo plazo. 3.9 Estacionalidad (gráficos y descomposición) Para descomponer, usamos un objeto ts regular con frecuencia diaria (24), semanal (24*7) o anual (24*365). Utilizamos la serie imputada val_impu para evitar huecos. # Construir ts con frecuencia diaria (24 por ciclo) start_time &lt;- min(df_impu[[time_col]], na.rm = TRUE) Indice.ts.diaria &lt;- ts(df_impu$val_impu, start = c(year(start_time), hour(start_time) + 1), frequency = 24) # Gráficos estacionales (por hora del día y por mes) autoplot(Indice.ts.diaria) + ggtitle(&quot;Serie ts (freq=24)&quot;) Serie ts (freq = 24) La serie presenta alta variabilidad (cada día cambia mucho), con rupturas o cambios estructurales en determinados años. Esto indica que el sistema de potencia tiene patrones por periodos largos más que una estacionalidad estricta diaria. # STL y gráficos estacionales fit_stl &lt;- stl(Indice.ts.diaria, s.window = &quot;periodic&quot;) plot(fit_stl, main = &quot;Descomposición STL (frecuencia diaria)&quot;) Decomposición STL frecuencia diaria * data: Muestra la potencia total observada con todas sus fluctuaciones. * seasonal: Se observa una banda negra uniforme, porque la variabilidad de la serie es mucho mayor que la amplitud de la estacionalidad. * trend: Se observan periodos con incrementos o descensos sostenidos de potencia * remainder: Presenta la variabilidad de corto plazo, los picos, fallos de medición y valores atípicos # Define un inicio dinámico (o fija una fecha) ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) slice &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(slice$val_impu), frequency = 24) fit_zoom &lt;- stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE) plot(fit_zoom, range.bars = FALSE, main = &quot;STL en ventana (4 semanas)&quot;) Decomposición STL en una ventana de 4 semanas data: Se observan oscilaciones regulares de subida y bajada cada 24 horas, lo cual refleja el patrón de potencia diario. Hay algunos huecos o caídas abruptas que corresponden a datos faltantes o interrupciones de registro de los datos. La serie se mueve alrededor de una media aproximada de 5000–6000 KW, con variaciones diarias de alrededor de ±1000 – 1500 KW. seasonal: Se observa una forma de onda repetitiva tipo sinusoinal, con un ciclo por día. La serie tiene una estacionalidad clara diaria: la potencia sube en ciertas horas (probablemente durante el día laboral) y baja en otras (probablemente por la noche). La amplitud del patrón se mantiene bastante constante, lo que sugiere que la estacionalidad diaria no cambia mucho entre semanas. trend: Se observan ondas de mayor periodo que podrían corresponder a variaciones semanales. La tendencia muestra subidas y bajadas lentas, lo que indica variabilidad estructural o cambios progresivos en el nivel medio de potencia. La escala vertical está alrededor de los 5000–7000 KW. remainder: Los picos hacia arriba o abajo representan anomalías, errores o eventos inusuales. Se observan algunos picos negativos fuertes, que podrían deberse a interrupciones o registros incorrectos de potencia (NA o 0). El resto del residuo oscila cerca de cero, lo cual es deseable (significa que la mayor parte de la variabilidad fue capturada por tendencia + estacionalidad). En resumen, la serie de potencia tiene una estacionalidad diaria fuerte, una tendencia suave semanal, y ruido moderado. 3.10 Indicadores resumidos # Completitud global comp_global &lt;- 1 - mean(is.na(df_full[[y_col]])) # Completitud por año comp_anio &lt;- df_full %&gt;% dplyr::group_by(anio = lubridate::year(.data[[time_col]])) %&gt;% dplyr::summarise( comp = 1 - mean(is.na(.data[[y_col]])), n_obs = dplyr::n(), .groups = &quot;drop&quot; ) comp_global ## [1] 0.9948587 comp_anio ## # A tibble: 8 × 3 ## anio comp n_obs ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2018 0.996 38330 ## 2 2019 0.979 15639 ## 3 2020 0.997 17424 ## 4 2021 0.994 11444 ## 5 2022 1 9793 ## 6 2023 1 9893 ## 7 2024 1 9712 ## 8 2025 1 6412 Año Completitud Observaciones 2018 99.6% Muy buena cobertura 2019 97.9% Ligera pérdida de datos 2020 99.7% Excelente 2021 99.4% Alta 2022–2025 100% Sin huecos 3.11 Conclusiones La serie de potencia es altamente estacionaria y cíclica. Existen ciclos claros de 24 y 168 horas, reflejando comportamientos diarios y semanales. No se detectan tendencias de crecimiento, lo que indica estabilidad en la operación. Los promedios móviles confirman consistencia estructural. La descomposición STL y la ACF refuerzan la idea de una estacionalidad regular y predecible. La calidad del registro (99.5%) garantiza confiabilidad para análisis predictivos. "],["Preprocesamiento.html", "4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen 4.2 Carga de librerías 4.3 Carga de datos y visualización 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación 4.5 ACF y PACF (original y diferenciada) 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico 4.8 Puntos de cambio y visualización 4.9 Outliers y verificación de supuestos del ARIMA 4.10 Transformación logarítmica para estabilizar la varianza 4.11 Ajuste del modelo ARIMA en escala logarítmica 4.12 Verificación de supuestos del nuevo modelo 4.13 Pronóstico con el modelo mejorado (escala logarítmica) 4.14 Conclusiones", " 4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen Este cápitulo presenta una interpretación detallada de los resultados de Preprocesamiento y visualización de la serie temporal horaria de potencia. Se describen los patrones de tendencia y estacionalidad a distintas escalas (diaria, semanal, mensual y anual), la verificación/inducción de estacionariedad (diferenciación), el análisis ACF/PACF, la descomposición STL/MSTL, la detección de puntos de cambio, la identificación de outliers, el ajuste SARIMA (auto.arima) y el pronóstico. 4.2 Carga de librerías library(readr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(scales) library(zoo) library(forecast) library(tseries) library(changepoint) 4.3 Carga de datos y visualización csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot;; y_col &lt;- &quot;VALOR_IMPUTADO&quot; df &lt;- tryCatch(readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE)) # Parseo robusto de fecha-hora y valor df[[time_col]] &lt;- parse_date_time(df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ) df[[y_col]] &lt;- suppressWarnings(as.numeric(df[[y_col]])) # Malla horaria completa para marcar NA (sin imputar) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% arrange(.data[[time_col]]) %&gt;% select(!!time_col, !!y_col) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) # Serie imputada (para métodos que exigen regularidad) tm(&quot;Imputación (na.interp)&quot;, { df_impu &lt;&lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) }) # Vista rápida: primer tramo ggplot(df_full, aes(x = .data[[time_col]], y = .data[[y_col]])) + geom_line(na.rm = TRUE) + labs(title = &quot;Serie horaria de potencia (con huecos)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() Se observa la secuencia temporal de los valores de potencia con discontinuidades. 4.3.1 Bandas para huecos (NA) y vistas multiescala na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } agg_by &lt;- function(data, unit, label, time_col, y_col) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% mutate(freq = label) } na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) diaria &lt;- agg_by(df_full, &quot;day&quot;, &quot;Diaria&quot;, time_col, y_col) semanal &lt;- agg_by(df_full, &quot;week&quot;, &quot;Semanal&quot;, time_col, y_col) mensual &lt;- agg_by(df_full, &quot;month&quot;, &quot;Mensual&quot;, time_col, y_col) anual &lt;- agg_by(df_full, &quot;year&quot;, &quot;Anual&quot;, time_col, y_col) plot_df &lt;- bind_rows(diaria, semanal, mensual, anual) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;, &quot;Semanal&quot;, &quot;Mensual&quot;, &quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.3) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.6, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + labs(title = &quot;Potencia — vistas diaria, semanal, mensual y anual&quot;, subtitle = &quot;Bandas rojas: periodos con NA en la serie original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Las discontinuidades se indicaron con franjas de color rojo. Estos huecos fueron imputados usando forecast::na.interp, método lineal-local que mantiene la coherencia temporal. La imputación es obligatoria para construir una serie regular (necesaria para ARIMA, STL y MSTL). Si no se hace, los modelos no convergen ni generan predicciones confiables. La potencia muestra una variabilidad cíclica, con fluctuaciones más suaves en las escalas semanales y mensuales. Las bandas rojas señalan períodos con datos ausentes; su distribución ayuda a evaluar si hay estacionalidad interrumpida. El análisis multiescala permite identificar tendencias de largo plazo y patrones repetitivos en diferentes horizontes. 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación # Vector numérico imputado serie_vec &lt;- as.numeric(df_impu$val_impu) # ADF en serie original adf_raw &lt;- tseries::adf.test(serie_vec, k = 24) adf_raw ## ## Augmented Dickey-Fuller Test ## ## data: serie_vec ## Dickey-Fuller = -24.434, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria en media. # Diferenciación sugerida y gráfico d_sugerido &lt;- forecast::ndiffs(serie_vec) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 “ndiffs” sugiere una diferenciación (d = 1) para estabilizar tendencia y variabilidad. serie_diff &lt;- if (d_sugerido &gt; 0) diff(serie_vec, differences = d_sugerido) else serie_vec df_diff &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]])[seq_along(serie_vec)], Original = as.numeric(serie_vec), Diferenciada = c(rep(NA, d_sugerido), as.numeric(serie_diff)) ) |&gt; tidyr::pivot_longer(cols = c(Original, Diferenciada), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) ggplot(df_diff, aes(time, Valor, color = Serie)) + geom_line(linewidth = 0.6, alpha = 0.9, na.rm = TRUE) + scale_color_manual(values = c(Original = &quot;#6B7280&quot;, Diferenciada = &quot;#1F77B4&quot;)) + labs(title = &quot;Serie original vs. diferenciada&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia / ΔPotencia&quot;, color = &quot;Serie&quot;) + theme_minimal(base_size = 12) La serie original presenta tendencia ascendente y picos altos. La serie diferenciada elimina la tendencia de la serie original, centrando la media alrededor de cero y reduciendo varianza. # ADF nuevamente si se diferenció if (d_sugerido &gt; 0) { cat(&quot;\\nRe-prueba ADF en la serie diferenciada (d =&quot;, d_sugerido, &quot;):\\n&quot;) print(tseries::adf.test(serie_diff, k = 24)) } ## ## Re-prueba ADF en la serie diferenciada (d = 1 ): ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff ## Dickey-Fuller = -91.566, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) para la serie diferenciada indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria. En modelos ARIMA se necesita estacionariedad. La diferenciación controla la no estacionariedad estructural sin alterar la forma estacional de corto plazo. 4.5 ACF y PACF (original y diferenciada) # ============================================================ # 6. ACF y PACF (original y diferenciada) # ============================================================ # --- Calcular ACF/PACF de la serie original --- t0 &lt;- Sys.time() acf_obj &lt;- try(acf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_obj &lt;- try(pacf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (original)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_obj, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) # --- Graficar ACF/PACF de la serie original --- if (!inherits(acf_obj, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_obj, &quot;try-error&quot;)) { acf_df &lt;- data.frame(lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf)) pacf_df &lt;- data.frame(lag = as.numeric(pacf_obj$lag), pacf = as.numeric(pacf_obj$acf)) ci &lt;- 1.96 / sqrt(length(serie_vec)) p1 &lt;- ggplot(acf_df, aes(lag, acf)) + geom_col(fill = &quot;#1f77b4&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p2 &lt;- ggplot(pacf_df, aes(lag, pacf)) + geom_col(fill = &quot;#ff7f0e&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p1); print(p2) } else { cat(&quot;Error al calcular ACF/PACF de la serie original.\\n&quot;) } # --- Serie diferenciada --- if (exists(&quot;serie_diff&quot;) &amp;&amp; length(serie_diff) &gt; 10 &amp;&amp; !identical(serie_diff, serie_vec)) { t0 &lt;- Sys.time() acf_d &lt;- try(acf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_d &lt;- try(pacf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (diferenciada)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_d, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) if (!inherits(acf_d, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_d, &quot;try-error&quot;)) { acf_df_d &lt;- data.frame(lag = as.numeric(acf_d$lag), acf = as.numeric(acf_d$acf)) pacf_df_d &lt;- data.frame(lag = as.numeric(pacf_d$lag), pacf = as.numeric(pacf_d$acf)) ci_d &lt;- 1.96 / sqrt(length(serie_diff)) p3 &lt;- ggplot(acf_df_d, aes(lag, acf)) + geom_col(fill = &quot;#17becf&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p4 &lt;- ggplot(pacf_df_d, aes(lag, pacf)) + geom_col(fill = &quot;#2ca02c&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p3); print(p4) } else { cat(&quot;Error al calcular ACF/PACF diferenciada.\\n&quot;) } } La ACF de la serie original muestra valores muy altos (cercanos a 1) en los primeros rezagos y una disminución muy lenta a medida que aumenta el lag (hasta aproximadamente 168 horas, es decir, 7 días). La curva no cruza la banda de significancia (líneas rojas), lo cual indica una persistencia fuerte. La alta autocorrelación inicial y su decaimiento lento son señales claras de no estacionariedad. Este patrón implica que los valores pasados influyen fuertemente en los futuros, y que la serie tiene una tendencia o un ciclo estacional persistente. La leve oscilación alrededor de los rezagos 24, 48, 72, etc., sugiere la presencia de una estacionalidad diaria (24 horas). En conjunto, la ACF indica que la serie no tiene media constante y no fluctúa alrededor de un equilibrio estable. La serie original no es estacionaria y requiere una transformación (diferenciación) para eliminar la tendencia y permitir el uso de modelos ARIMA. La PACF de la serie original presenta un pico muy pronunciado en el lag 1 y luego una rápida caída hacia valores pequeños alrededor de cero. El gran valor en el primer rezago indica un componente autoregresivo fuerte de orden 1 (AR(1)). La rápida caída posterior confirma que la mayor parte de la dependencia directa se concentra en los primeros rezagos. Los valores bajos pero persistentes en rezagos múltiples reflejan todavía efectos indirectos acumulados, producto de la tendencia no estacionaria detectada. La PACF confirma un componente autoregresivo significativo en la estructura de la serie original, aunque su interpretación precisa se distorsiona por la presencia de tendencia y estacionalidad. La ACF de la serie diferenciada muestra una autocorrelación fuerte únicamente en el rezago 1, pero el resto de las barras caen rápidamente dentro del intervalo de confianza (líneas rojas). La diferenciación ha eliminado con éxito la tendencia y la dependencia a largo plazo. Los valores cercanos a cero en los rezagos mayores indican que la serie ya no tiene memoria prolongada, es decir, es estacionaria en media. El ligero pico negativo en los primeros rezagos podría sugerir un componente MA (Media Móvil) de bajo orden. Tras la diferenciación, la ACF evidencia una serie estacionaria y más estable, con correlación significativa sólo a corto plazo. En la PACF de la serie diferenciada se observa un primer pico negativo (ligeramente pronunciado) y luego valores pequeños oscilando alrededor de cero, sin superar el umbral de significancia. Este patrón es típico de una serie con componente MA (q) después de la diferenciación. La ausencia de picos claros más allá del primer rezago indica que no existen dependencias autoregresivas persistentes. La PACF de la serie diferenciada confirma que el proceso se estabilizó tras la diferenciación, y que la estructura autoregresiva se redujo sustancialmente, favoreciendo modelos ARIMA sencillos con un componente de media móvil dominante. 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else if (&quot;VALOR_IMPUTADO&quot; %in% names(df_impu)) &quot;VALOR_IMPUTADO&quot; else stop(&quot;No encuentro columna de valores: usa &#39;val_impu&#39; o &#39;VALOR_IMPUTADO&#39;.&quot;) # Utilidad para detectar columna estacional por periodo (acepta &#39;Seasonal-24&#39;, &#39;Seasonal 24&#39;, etc.) find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) if (!any(is_seas)) return(NULL) seas_nm &lt;- nm[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # ========== A) df_seas24: Estacionalidad diaria (24h) desde SERIE HORARIA ========== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_m_hour &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_h &lt;- as.data.frame(fit_m_hour) col_s24 &lt;- find_seasonal_col(comp_h, 24) if (is.null(col_s24)) { # fallback: primera &#39;Seasonal&#39; si no se pudo detectar 24 específicamente cand &lt;- grep(&quot;^Seasonal&quot;, names(comp_h), ignore.case = TRUE, value = TRUE) col_s24 &lt;- cand[1] } df_seas24 &lt;- tibble( time = time_hr, Componente = &quot;Estacionalidad diaria (24h)&quot;, Valor = comp_h[[col_s24]] ) # ========== B) df_seas12: Estacionalidad mensual (12) desde SERIE MENSUAL ========== monthly &lt;- df_impu %&gt;% mutate(mes = floor_date(.data[[time_col]], &quot;month&quot;)) %&gt;% summarise(.by = mes, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(mes) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(year(min(monthly$mes)), month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # detectar columna estacional (nombre puede ser &quot;seasonal&quot;/&quot;Seasonal&quot;) seas_col_m &lt;- names(comp_m)[grepl(&quot;season&quot;, names(comp_m), ignore.case = TRUE)][1] if (is.na(seas_col_m)) stop(&quot;No se encontró columna estacional en STL mensual.&quot;) df_seas12 &lt;- tibble( time = as.POSIXct(monthly$mes), # unificamos a POSIXct Componente = &quot;Estacionalidad mensual (12)&quot;, Valor = comp_m[[seas_col_m]] ) # ========== C) df_day_panel: Observada, Tendencia, Semanal(7d), Anual(365d), Residuo (SERIE DIARIA) ========== daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% summarise(.by = day, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(day) ts_day &lt;- forecast::msts(daily$y, seasonal.periods = c(7, 365)) fit_m_day &lt;- forecast::mstl(ts_day, robust = TRUE) comp_d &lt;- as.data.frame(fit_m_day) # Normalizamos nombres para &#39;Trend&#39; y &#39;Remainder&#39; nmd &lt;- names(comp_d) nmd &lt;- sub(&quot;^trend$&quot;, &quot;Trend&quot;, nmd, ignore.case = TRUE) nmd &lt;- sub(&quot;^remainder$&quot;, &quot;Remainder&quot;, nmd, ignore.case = TRUE) names(comp_d) &lt;- nmd # Detectar columnas estacionales 7 y 365 is_seas &lt;- grepl(&quot;^Seasonal&quot;, names(comp_d), ignore.case = TRUE) seas_nms &lt;- names(comp_d)[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } seas_p &lt;- vapply(seas_nms, getp, integer(1)) idx7 &lt;- which(seas_p == 7) idx365 &lt;- which(seas_p == 365) seas7 &lt;- if (length(idx7)) comp_d[[seas_nms[idx7[1]]]] else NULL seas365 &lt;- if (length(idx365)) comp_d[[seas_nms[idx365[1]]]] else NULL df_day_panel &lt;- tibble( time = as.POSIXct(daily$day), Observada = daily$y, Tendencia = if (&quot;Trend&quot; %in% names(comp_d)) comp_d$Trend else NA_real_, Residuo = if (&quot;Remainder&quot; %in% names(comp_d)) comp_d$Remainder else NA_real_ ) if (!is.null(seas7)) df_day_panel[[&quot;Estacionalidad semanal (7d)&quot;]] &lt;- seas7 if (!is.null(seas365)) df_day_panel[[&quot;Estacionalidad anual (365d)&quot;]] &lt;- seas365 df_day_panel &lt;- df_day_panel |&gt; pivot_longer(-time, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) # ========== D) Panel combinado ========== panel_all &lt;- bind_rows( df_day_panel, # Observada/Tendencia/Residuo + 7d/365d si existen df_seas24, # Estacionalidad diaria (24h) desde HORAS df_seas12 # Estacionalidad mensual (12) desde MESES ) %&gt;% mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;, &quot;Tendencia&quot;, &quot;Estacionalidad diaria (24h)&quot;, &quot;Estacionalidad semanal (7d)&quot;, &quot;Estacionalidad mensual (12)&quot;, &quot;Estacionalidad anual (365d)&quot;, &quot;Residuo&quot;) ) ) # ========== E) Gráfico ========== ggplot(panel_all, aes(x = time, y = Valor)) + geom_line(linewidth = 0.45, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;, drop = FALSE) + scale_x_datetime(date_breaks = &quot;6 months&quot;, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) + labs( title = &quot;Descomposición combinada de la serie completa&quot;, subtitle = &quot;Tendencia + Estacionalidades diaria (24h), semanal (7d), mensual (12) y anual (365d) + Residuo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) 4.6.1 Descomposición de la serie por estacionalidades # ============================================================ # Descomposición óptima de la serie: # - Diaria (24h) → serie horaria (MSTL, seasonal.periods=24) # - Semanal (7d) → serie horaria (MSTL, seasonal.periods=168) # - Mensual (12) → serie mensual (STL, frequency=12) # - Anual (365d) → serie diaria (STL, frequency=365) # Gráficos en orden: Observada → Tendencia → Estacionalidad → Residuo # ============================================================ # ==== 0) Utilidades ==== val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else &quot;VALOR_IMPUTADO&quot; # Detecta, dentro de un data.frame de mstl/stl, la columna estacional de un periodo dado find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) # posibles nombres: &quot;Seasonal-24&quot;, &quot;Seasonal 24&quot;, &quot;seasonal24&quot;, etc. is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) seas_nm &lt;- nm[is_seas] if (!length(seas_nm)) return(NULL) getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # Devuelve nombres (o NA) para Trend y Remainder segun el objeto mstl/stl find_trend_remainder &lt;- function(df_comp) { nm &lt;- names(df_comp) trend &lt;- nm[grepl(&quot;^Trend$&quot;, nm, ignore.case = TRUE)] remainder &lt;- nm[grepl(&quot;^Remainder$&quot;, nm, ignore.case = TRUE)] list(trend = if (length(trend)) trend[1] else NA_character_, remainder = if (length(remainder)) remainder[1] else NA_character_) } # Constructor genérico de gráfico con orden fijo de facetas plot_decomp &lt;- function(df_wide, time_col_name = &quot;time&quot;, title_txt = &quot;&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) { df_long &lt;- df_wide |&gt; tidyr::pivot_longer(-dplyr::all_of(time_col_name), names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) |&gt; dplyr::mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;,&quot;Tendencia&quot;,&quot;Estacionalidad&quot;,&quot;Residuo&quot;) ) ) p &lt;- ggplot(df_long, aes(x = .data[[time_col_name]], y = Valor)) + geom_line(linewidth = 0.6, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;) + labs(title = title_txt, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) if (x_is_date) { p &lt;- p + scale_x_date(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } else { p &lt;- p + scale_x_datetime(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } p } # ==== 1) Serie HORARIA → diaria(24h) y semanal(168h) con MSTL ==== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_mstl_hr &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_hr &lt;- as.data.frame(fit_mstl_hr) # columnas clave cols_hr &lt;- find_trend_remainder(comp_hr) col_trend_hr &lt;- cols_hr$trend col_rem_hr &lt;- cols_hr$remainder col_s24 &lt;- find_seasonal_col(comp_hr, 24) col_s168 &lt;- find_seasonal_col(comp_hr, 168) # --- A) Diaria (24h) sobre la serie horaria --- df_day24 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s24)) comp_hr[[col_s24]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_day24 &lt;- plot_decomp(df_day24, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición DIARIA (24h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) # --- B) Semanal (7d=168h) sobre la serie horaria --- df_week168 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s168)) comp_hr[[col_s168]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_week168 &lt;- plot_decomp(df_week168, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición SEMANAL (7d = 168h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;6 months&quot;) # ==== 2) Serie MENSUAL → mensual(12) con STL ==== monthly &lt;- df_impu |&gt; dplyr::mutate(mes = lubridate::floor_date(.data[[time_col]], &quot;month&quot;)) |&gt; dplyr::group_by(mes) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(lubridate::year(min(monthly$mes)), lubridate::month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # seasonal, trend, remainder # nombres estandar names(comp_m) &lt;- tolower(names(comp_m)) df_month12 &lt;- dplyr::tibble( time = as.Date(monthly$mes), Observada = as.numeric(ts_month), Tendencia = comp_m$trend, Estacionalidad= comp_m$seasonal, Residuo = comp_m$remainder ) p_month12 &lt;- plot_decomp(df_month12, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición MENSUAL (12) — serie mensual&quot;, x_is_date = TRUE, date_breaks_main = &quot;6 months&quot;) # ==== 3) Serie DIARIA → anual(365) con STL ==== daily &lt;- df_impu |&gt; dplyr::mutate(day = lubridate::floor_date(.data[[time_col]], &quot;day&quot;)) |&gt; dplyr::group_by(day) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(daily) &gt;= 365) # ideal ≥ 2*365 para patrón robusto ts_year &lt;- stats::ts( daily$y, frequency = 365, start = c(lubridate::year(min(daily$day)), as.integer(format(min(daily$day), &quot;%j&quot;))) ) fit_stl_y &lt;- stats::stl(ts_year, s.window = &quot;periodic&quot;, robust = TRUE) comp_y &lt;- as.data.frame(fit_stl_y$time.series) names(comp_y) &lt;- tolower(names(comp_y)) df_year365 &lt;- dplyr::tibble( time = as.POSIXct(daily$day), Observada = as.numeric(ts_year), Tendencia = comp_y$trend, Estacionalidad= comp_y$seasonal, Residuo = comp_y$remainder ) p_year365 &lt;- plot_decomp(df_year365, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición ANUAL (365d) — serie diaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;1 year&quot;) # ==== 4) Mostrar los 4 gráficos ==== p_day24 p_week168 p_month12 p_year365 Tendencia: suaviza el comportamiento global; muestra una evolución sostenida de la potencia en el tiempo. Estacionalidades: 24 h: patrón diario con repeticiones claras (potencia eléctrica según horas). 7 d: variación semanal con máximos en ciertos días. 12 m: ciclo anual ligado a estaciones o periodos de consumo. 365 d: refina oscilaciones de largo plazo. Residuo: oscilaciones aleatorias sin patrón sistemático. La descomposición MSTL permite aislar múltiples estacionalidades y verificar si cada componente explica variaciones específicas. No requiere transformaciones adicionales al trabajar sobre serie imputada y diferenciada. 4.6.2 Descomposición de la serie en una ventana de 4 semanas t0 &lt;- Sys.time() ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) seg_4w &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(seg_4w$val_impu), frequency = 24) fit_stl &lt;- try(stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE), silent = TRUE) .timing[[&quot;STL (ventana 4 semanas)&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(fit_stl, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = if (inherits(fit_stl, &quot;try-error&quot;)) as.character(fit_stl) else &quot;&quot; ) if (!inherits(fit_stl, &quot;try-error&quot;)) { plot(fit_stl, range.bars = FALSE, main = &quot;STL (ventana de 4 semanas)&quot;) } else { cat(&quot;No se pudo calcular STL (ver mensaje en la tabla de tiempos).\\n&quot;) } Muestra el detalle de la estructura estacional de corto plazo: ciclos diarios consistentes. Permite comprobar estabilidad local de la tendencia y detectar posibles cambios abruptos. Analizar ventanas cortas sirve para validar la homogeneidad de los patrones estacionales dentro del año. 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico tm(&quot;Ajuste SARIMA + Pronóstico&quot;, { y_fit &lt;&lt;- ts(serie_vec, frequency = 24) m_auto &lt;&lt;- forecast::auto.arima( y_fit, d = d_sugerido, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx, max.p = 5, max.q = 5, max.P = 2, max.Q = 2 ) print(m_auto) h_days &lt;&lt;- horizon_days h &lt;&lt;- 24 * h_days fc &lt;&lt;- forecast::forecast(m_auto, h = h) print(autoplot(fc) + labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;)) }) ## Series: y_fit ## ARIMA(1,1,1)(0,0,2)[24] ## ## Coefficients: ## ar1 ma1 sma1 sma2 ## -0.8940 0.9736 0.0222 0.0110 ## s.e. 0.0023 0.0012 0.0029 0.0028 ## ## sigma^2 = 249612: log likelihood = -905595.9 ## AIC=1811202 AICc=1811202 BIC=1811250 auto.arima selecciona automáticamente (p, d, q) y (P, D, Q)[s] d = 1 (diferenciación no estacional) para eliminar tendencia. [24] como periodicidad diaria. MA/AR estacionales que capturan los picos en ACF/PACF. El modelo incluye diferenciación (d = 1) y componente estacional de 24 h; por tanto, controla la tendencia y la variabilidad residual detectadas en etapas anteriores. SARIMA es apropiado cuando existe estructura autoregresiva + estacionalidad fija. La diferenciación previa y la evidencia ACF/PACF respaldan esta elección. 4.7.1 Zoom al Pronóstico # ==== ZOOM FINAL AL PRONÓSTICO ==== history_days &lt;- 21 h_days &lt;- horizon_days %||% 7 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) h &lt;- length(fc$mean) f_times &lt;- seq(from = t_max + hours(1), by = &quot;1 hour&quot;, length.out = h) fc_df &lt;- tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[,&quot;80%&quot;]), hi80 = as.numeric(fc$upper[,&quot;80%&quot;]), lo95 = as.numeric(fc$lower[,&quot;95%&quot;]), hi95 = as.numeric(fc$upper[,&quot;95%&quot;]) ) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.4, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, # ← espaciado más grande date_labels = &quot;%d-%b&quot;) + # ← formato sin hora coord_cartesian(ylim = c(0, 10000)) + # recorta sin descartar filas labs(title = paste0(&quot;Zoom final del Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1) # ← evita solapamiento ) Línea negra: representa los últimos 21 días de la serie observada, durante este período, la potencia muestra una variabilidad marcada con picos altos (entre 7000 y 10000 unidades) y caídas bruscas hacia valores bajos. Línea azul: corresponde a la predicción puntual generada por el modelo SARIMA para los siguientes 7 días. Esta predicción se mantiene estable y suavizada en comparación con la serie observada, lo que indica que el modelo estima que la potencia tenderá a estabilizarse alrededor de un valor medio cercano a los 4500–5000 unidades. Franjas azules (bandas de confianza): La franja más oscura representa el intervalo de confianza al 80 % y la franja más clara, el intervalo al 95 %. Estas bandas muestran la incertidumbre asociada a la predicción: a medida que el horizonte temporal avanza, las bandas se ensanchan, lo que significa que el modelo tiene menos certeza sobre los valores futuros. El ensanchamiento pronunciado indica que la volatilidad pasada influye fuertemente en la incertidumbre del pronóstico. El modelo sugiere una tendencia de estabilización en los valores de potencia para la semana siguiente. No se anticipan picos extremos ni caídas abruptas. Dado que las bandas de confianza se mantienen dentro del rango esperado (0 – 10000), el ajuste es razonable y coherente con la magnitud de los datos históricos. Las bandas amplias implican que, aunque el modelo capta bien la tendencia general, la precisión puntual es limitada. Esto es común en series con ruido y estacionalidades múltiples. 4.8 Puntos de cambio y visualización daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% group_by(day) %&gt;% summarise(y = mean(val_impu), .groups = &quot;drop&quot;) tm(&quot;Changepoint (media diaria, PELT)&quot;, { cp &lt;&lt;- cpt.mean(daily$y, method = &quot;PELT&quot;, penalty = &quot;SIC&quot;) }) head (cp@cpts,100) # índices de cambio ## [1] 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ## [19] 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 66 ## [37] 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ## [55] 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## [73] 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 ## [91] 121 123 124 125 126 127 128 129 130 131 # Overlay en la curva diaria ggplot(daily, aes(day, y)) + geom_line() + geom_vline(xintercept = daily$day[cp@cpts], linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Media diaria con puntos de cambio (cpt.mean)&quot;, x = &quot;Día&quot;, y = &quot;Potencia media diaria&quot;) + theme_minimal() El método utilizado (cpt.mean del paquete changepoint) permite identificar momentos en el tiempo donde la media del proceso cambia significativamente, lo cual es muy útil para detectar rupturas, transiciones o alteraciones del régimen de la serie. Líneas negras, corresponden a la serie diaria suavizada. Es decir, los valores promedio por día de la potencia, eliminando la variación horaria interna. Líneas horizontales rojas (puntos de cambio), indican los momentos en que el algoritmo PELT (Pruned Exact Linear Time) identificó cambios estadísticamente significativos en la media. Cada línea roja marca una ruptura: un punto donde el nivel promedio de la serie cambia de forma abrupta o sostenida. La gran cantidad de líneas rojas indica múltiples cambios en la media a lo largo de la serie. Esto sugiere que la potencia no sigue un comportamiento estacionario estable, sino que ha tenido varios periodos con medias distintas —lo cual puede corresponder a modificaciones en la demanda, mantenimiento de equipos, cambios operativos o condiciones externas. Periodo 2018–2020: Los valores son relativamente bajos y estables, con algunos incrementos graduales. Los puntos de cambio aquí podrían asociarse a una transición hacia niveles más altos de consumo o potencia. Periodo 2020–2021: Se observa una mayor volatilidad, con picos y caídas pronunciadas. Es probable que los puntos de cambio detecten episodios transitorios de aumento o reducción drástica. 2022 en adelante: La serie aumenta en nivel medio y muestra mayor dispersión, con valores que alcanzan niveles altos de potencia (&gt;6000). Las múltiples líneas rojas en esta etapa indican fluctuaciones más frecuentes, reflejando un sistema con variabilidad estructural más alta o cambios en los patrones de uso. La serie de potencia no es homogénea en el tiempo: exhibe múltiples cambios estructurales en su comportamiento medio. Estos cambios pueden ser interpretados como etapas operativas o periodos de régimen distinto, lo que justifica la necesidad de aplicar modelos con parámetros variables o segmentados.. La alta frecuencia de cambios después de 2022 podría indicar mayor inestabilidad del sistema o sensibilidad a factores externos, lo cual también se relaciona con la amplia incertidumbre observada en las bandas del pronóstico SARIMA. 4.9 Outliers y verificación de supuestos del ARIMA # Outliers to &lt;- tryCatch(forecast::tsoutliers(ts(serie_vec, frequency = 24)), error = function(e) NULL) if (!is.null(to)) { #print(to) idx &lt;- to$index df_ol &lt;- tibble(time = as.POSIXct(df_impu[[time_col]])[idx], y = serie_vec[idx]) ggplot(tibble(time = as.POSIXct(df_impu[[time_col]]), y = serie_vec), aes(time, y)) + geom_line(alpha = 0.6) + geom_point(data = df_ol, aes(time, y), color = &quot;red&quot;, size = 1.4) + labs(title = &quot;Outliers detectados (forecast::tsoutliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() } El análisis de valores atípicos (outliers) identifica puntos que se desvían significativamente del patrón esperado de la serie, considerando su tendencia, estacionalidad y variabilidad histórica. Línea gris: Muestra la serie temporal original de potencia, donde se pueden observar los patrones de oscilación, los aumentos progresivos y los periodos de mayor variabilidad. Puntos rojos: Señalan los outliers detectados automáticamente por el algoritmo de tsoutliers.Estos puntos representan valores que el modelo considera anómalos, es decir, que se alejan más de lo esperado de acuerdo con la estructura de tendencia y estacionalidad estimada. 2018–2019: Pocos outliers, mayormente en valores bajos, lo que sugiere una etapa relativamente estable. 2020–2021: Aumenta la cantidad de outliers tanto por exceso como por defecto (picos y caídas abruptas).Esto puede estar asociado con eventos externos (fallos eléctricos, cambios en la demanda o mantenimiento del sistema) o ajustes en la infraestructura que alteraron momentáneamente los registros. 2022–2025: Se observa una alta concentración de outliers en la parte superior de la serie, especialmente en los valores más altos de potencia (por encima de 7500). Esto indica un incremento de la variabilidad o posiblemente una saturación del sistema, donde las mediciones superan los niveles esperados con frecuencia.También podría sugerir la presencia de nuevas condiciones operativas no captadas por el modelo (por ejemplo, aumento de la capacidad instalada o un cambio en los hábitos de consumo). Los outliers más extremos se presentan en valores cercanos a 0 y por encima de 9000, indicando errores o comportamientos anómalos graves. En los periodos intermedios (2019–2020 y 2023–2024), los picos son muy frecuentes, lo que puede afectar la estimación de parámetros del modelo si no se tratan adecuadamente. La presencia de tantos outliers sugiere que la serie presenta eventos atípicos recurrentes, los cuales rompen la suposición de normalidad y homocedasticidad requerida por muchos modelos de series temporales. Es recomendable tratar o ajustar estos valores antes del modelado. # Supuestos del modelo ARIMA (residuales) checkresiduals(m_auto) # ACF de residuales, Ljung-Box, histograma, qq-plot ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,1)(0,0,2)[24] ## Q* = 3889, df = 44, p-value &lt; 2.2e-16 ## ## Model df: 4. Total lags used: 48 Ljung-Box test La prueba de Ljung–Box aplicada a los residuales del modelo ARIMA(1,1,1)(0,0,2)[24], se realiza para evaluar la independencia (no autocorrelación) de los residuos en un modelo de series temporales. El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, los residuos presentan autocorrelación, el modelo no explica completamente la dependencia temporal. Los residuos NO son ruido blanco, es decir, conservan autocorrelación significativa a lo largo del tiempo. Diagnósticos residuales del modelo ARIMA(1,1,1)(0,0,2)[24] Estas tres gráficas es evaluar si los residuos del modelo cumplen los supuestos de un buen ajuste estadístico: independencia, homocedasticidad y normalidad. La primera gráfica representa los residuos en el tiempo (diferencia entre los valores observados y los predichos por el modelo ARIMA). Cada punto corresponde al error de predicción en una hora. Los residuos oscilan alrededor de 0, lo cual es un signo deseable. Sin embargo, la amplitud de las oscilaciones aumenta considerablemente con el tiempo (desde 2020 en adelante). Esto evidencia heterocedasticidad, la varianza de los errores no es constante a lo largo del tiempo. Hay picos extremos, tanto positivos como negativos (superiores a ±10.000), lo que sugiere la presencia de outliers o errores sistemáticos del modelo en determinados periodos. Las secciones con mayor densidad de oscilaciones indican que el modelo no logra seguir bien los cambios de nivel o tendencia en esas etapas (por ejemplo, entre 2022 y 2025, coincidiendo con tus resultados de cambio estructural). Los residuos no son homogéneos ni estacionarios en varianza. Esto implica que el modelo ARIMA(1,1,1)(0,0,2)[24] no captura completamente la dinámica temporal ni la variabilidad creciente de la serie. ACF (Función de Autocorrelación de los residuos), mide la dependencia serial entre los residuos en diferentes rezagos (lags). Las líneas azules representan los límites de confianza (±1.96/√n), dentro de los cuales las autocorrelaciones deberían estar si los residuos fueran puro ruido blanco. En los primeros rezagos (1–10), se aprecian barras que superan los límites de confianza, indicando autocorrelación significativa. A partir del lag 24 (una periodicidad diaria), todavía se observa un patrón repetitivo leve, lo que sugiere persistencia estacional no explicada. El resto de los lags muestran valores cercanos a 0, pero el exceso inicial es suficiente para rechazar la hipótesis de independencia. Los residuos no son completamente independientes, existen dependencias a corto plazo (y posiblemente estacionales) que el modelo no eliminó. Esto coincide con el resultado del test de Ljung–Box, que arrojó un p-valor &lt; 2.2e-16, confirmando la autocorrelación residual. Histograma y densidad de los residuos, muestra la distribución de los errores del modelo comparada con una curva normal teórica (línea roja). La distribución está altamente concentrada en torno a 0, pero con colas muy largas y picos extremos. Es decir, los residuos no siguen una distribución normal (hay asimetría y curtosis alta). Existen muchos valores extremos tanto positivos como negativos, coherentes con los outliers detectados. La curva teórica normal (en rojo) es mucho más estrecha que la real, lo que confirma la no normalidad de los residuos. Los residuos no son normales, presentando colas pesadas y picos excesivos.Esto sugiere que el modelo no solo deja autocorrelación, sino también errores estructurados y variabilidad anómala. Las tres gráficas indican que el modelo ARIMA(1,1,1)(0,0,2)[24] no logra capturar completamente la estructura de la serie temporal. Los residuos conservan autocorrelación, varianza no constante y outliers, por lo que no pueden considerarse ruido blanco. 4.9.1 Q–Q Plot de los residuos del modelo ARIMA # 1) Extraer residuos del modelo ajustado residuales &lt;- residuals(m_auto) # 2) Q-Q Plot base (comparación con distribución normal) qqnorm(residuales, main = &quot;Q–Q Plot de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24]&quot;, xlab = &quot;Cuantiles teóricos (Normal)&quot;, ylab = &quot;Cuantiles de los residuos&quot;, pch = 19, col = &quot;#1f77b4&quot;, cex = 0.8) qqline(residuales, col = &quot;red&quot;, lwd = 2) El Q–Q Plot (Quantile–Quantile Plot) de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24], una herramienta fundamental para evaluar la normalidad de los errores del modelo. En el eje X (horizontal) se representan los cuantiles teóricos de una distribución normal estándar. En el eje Y (vertical) se muestran los cuantiles observados de los residuos del modelo. La línea roja representa la situación ideal, si los residuos fueran perfectamente normales, los puntos azules se alinearían a lo largo de esa línea. Los puntos se desvían fuertemente de la línea roja, formando una curva escalonada y asimétrica. En las colas (extremos izquierdo y derecho) se observan valores alejados de la recta, indicando colas pesadas o valores extremos. En la zona central (cercana a 0), los puntos permanecen relativamente agrupados, pero el patrón general muestra una marcada asimetría vertical, con una diferencia notable entre los residuos negativos (abajo) y positivos (arriba). La forma escalonada del gráfico indica que los residuos no siguen una distribución normal. Los valores extremos (outliers) son responsables de la curvatura al inicio y al final del gráfico. 4.10 Transformación logarítmica para estabilizar la varianza # ============================================================ # Transformación logarítmica de la serie de potencia # ============================================================ # Evitar log(0) o negativos df_log &lt;- df_impu %&gt;% mutate(val_log = log1p(val_impu)) # log(1 + x) evita infinitos # Crear serie temporal log-transformada ts_log &lt;- ts(df_log$val_log, frequency = 24) # frecuencia diaria (24 horas) # Visualización básica autoplot(ts_log) + labs(title = &quot;Serie transformada logarítmicamente (log1p)&quot;, y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal() La transformación logarítmica se aplicó para reducir la heterocedasticidad (variabilidad creciente con el nivel de la serie), atenuar los valores extremos (outliers), especialmente los picos de alta potencia y aproximar la distribución de los datos a la normalidad, facilitando la aplicación del modelo ARIMA. En otras palabras, se busca estabilizar la varianza y mejorar el cumplimiento de los supuestos del modelo. En la gráfica se observa un comportamiento estructural similar al de la serie original, pero con amplitud comprimida; los picos muy altos (de más de 10.000 en escala original) se reducen a valores entre 7 y 9 en log(1+x); las fluctuaciones bruscas entre periodos de alta y baja potencia se suavizan notablemente; aun cuando existen saltos entre periodos (régimenes distintos), la variabilidad interna dentro de cada tramo es mucho más homogénea. La serie transformada conserva la estructura temporal fundamental (tendencia y estacionalidad) pero elimina gran parte del ruido que dificulta el modelado. 4.11 Ajuste del modelo ARIMA en escala logarítmica # ============================================================ # Ajuste automático ARIMA sobre serie log-transformada # ============================================================ tm(&quot;Ajuste SARIMA TS log-transformada&quot;, { m_log &lt;&lt;- auto.arima(ts_log, seasonal = TRUE, stepwise = FALSE, approximation = arima_approx, trace = TRUE) summary(m_log) }) ## ## Fitting models using approximations to speed things up... ## ## ARIMA(0,1,0) : 114852.4 ## ARIMA(0,1,0) with drift : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] with drift : 114856.4 ## ARIMA(0,1,0)(0,0,2)[24] : 114855.9 ## ARIMA(0,1,0)(0,0,2)[24] with drift : 114857.9 ## ARIMA(0,1,0)(1,0,0)[24] : 114878.2 ## ARIMA(0,1,0)(1,0,0)[24] with drift : 114880.2 ## ARIMA(0,1,0)(1,0,1)[24] : Inf ## ARIMA(0,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(1,0,2)[24] : Inf ## ARIMA(0,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,0)[24] : 114903.7 ## ARIMA(0,1,0)(2,0,0)[24] with drift : 114905.7 ## ARIMA(0,1,0)(2,0,1)[24] : Inf ## ARIMA(0,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,2)[24] : 114907.7 ## ARIMA(0,1,0)(2,0,2)[24] with drift : 114909.7 ## ARIMA(0,1,1) : 114849.4 ## ARIMA(0,1,1) with drift : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] with drift : 114853.4 ## ARIMA(0,1,1)(0,0,2)[24] : 114853 ## ARIMA(0,1,1)(0,0,2)[24] with drift : 114854.9 ## ARIMA(0,1,1)(1,0,0)[24] : 114875.2 ## ARIMA(0,1,1)(1,0,0)[24] with drift : 114877.2 ## ARIMA(0,1,1)(1,0,1)[24] : Inf ## ARIMA(0,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(1,0,2)[24] : Inf ## ARIMA(0,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,0)[24] : 114900.7 ## ARIMA(0,1,1)(2,0,0)[24] with drift : 114902.7 ## ARIMA(0,1,1)(2,0,1)[24] : Inf ## ARIMA(0,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,2)[24] : 114904.7 ## ARIMA(0,1,1)(2,0,2)[24] with drift : 114906.7 ## ARIMA(0,1,2) : 114534.4 ## ARIMA(0,1,2) with drift : 114536.4 ## ARIMA(0,1,2)(0,0,1)[24] : 114536.2 ## ARIMA(0,1,2)(0,0,1)[24] with drift : 114538.2 ## ARIMA(0,1,2)(0,0,2)[24] : 114537.7 ## ARIMA(0,1,2)(0,0,2)[24] with drift : 114539.7 ## ARIMA(0,1,2)(1,0,0)[24] : 114560.1 ## ARIMA(0,1,2)(1,0,0)[24] with drift : 114562.1 ## ARIMA(0,1,2)(1,0,1)[24] : Inf ## ARIMA(0,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,2)(1,0,2)[24] : Inf ## ARIMA(0,1,2)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,2)(2,0,0)[24] : 114585.5 ## ARIMA(0,1,2)(2,0,0)[24] with drift : 114587.5 ## ARIMA(0,1,2)(2,0,1)[24] : Inf ## ARIMA(0,1,2)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,3) : 114522.7 ## ARIMA(0,1,3) with drift : 114524.6 ## ARIMA(0,1,3)(0,0,1)[24] : 114524.4 ## ARIMA(0,1,3)(0,0,1)[24] with drift : 114526.4 ## ARIMA(0,1,3)(0,0,2)[24] : 114526 ## ARIMA(0,1,3)(0,0,2)[24] with drift : 114528 ## ARIMA(0,1,3)(1,0,0)[24] : 114548.3 ## ARIMA(0,1,3)(1,0,0)[24] with drift : 114550.3 ## ARIMA(0,1,3)(1,0,1)[24] : Inf ## ARIMA(0,1,3)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,3)(2,0,0)[24] : 114573.7 ## ARIMA(0,1,3)(2,0,0)[24] with drift : 114575.7 ## ARIMA(0,1,4) : 104511.7 ## ARIMA(0,1,4) with drift : 104513.7 ## ARIMA(0,1,4)(0,0,1)[24] : 104481.2 ## ARIMA(0,1,4)(0,0,1)[24] with drift : 104483.2 ## ARIMA(0,1,4)(1,0,0)[24] : 104504.9 ## ARIMA(0,1,4)(1,0,0)[24] with drift : 104506.9 ## ARIMA(0,1,5) : 104454.2 ## ARIMA(0,1,5) with drift : 104456.2 ## ARIMA(1,1,0) : 114850.7 ## ARIMA(1,1,0) with drift : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] with drift : 114854.7 ## ARIMA(1,1,0)(0,0,2)[24] : 114854.3 ## ARIMA(1,1,0)(0,0,2)[24] with drift : 114856.3 ## ARIMA(1,1,0)(1,0,0)[24] : 114876.6 ## ARIMA(1,1,0)(1,0,0)[24] with drift : 114878.6 ## ARIMA(1,1,0)(1,0,1)[24] : Inf ## ARIMA(1,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(1,0,2)[24] : Inf ## ARIMA(1,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,0)[24] : 114902.1 ## ARIMA(1,1,0)(2,0,0)[24] with drift : 114904.1 ## ARIMA(1,1,0)(2,0,1)[24] : Inf ## ARIMA(1,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,2)[24] : 114906.1 ## ARIMA(1,1,0)(2,0,2)[24] with drift : 114908.1 ## ARIMA(1,1,1) : 111225.1 ## ARIMA(1,1,1) with drift : 111227.1 ## ARIMA(1,1,1)(0,0,1)[24] : 111226.3 ## ARIMA(1,1,1)(0,0,1)[24] with drift : 111228.3 ## ARIMA(1,1,1)(0,0,2)[24] : 111226.8 ## ARIMA(1,1,1)(0,0,2)[24] with drift : 111228.8 ## ARIMA(1,1,1)(1,0,0)[24] : 111250.2 ## ARIMA(1,1,1)(1,0,0)[24] with drift : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] with drift : 111254.2 ## ARIMA(1,1,1)(1,0,2)[24] : Inf ## ARIMA(1,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,1)(2,0,0)[24] : 111274.5 ## ARIMA(1,1,1)(2,0,0)[24] with drift : 111276.5 ## ARIMA(1,1,1)(2,0,1)[24] : Inf ## ARIMA(1,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,2) : 107610.3 ## ARIMA(1,1,2) with drift : 107612 ## ARIMA(1,1,2)(0,0,1)[24] : 107611.4 ## ARIMA(1,1,2)(0,0,1)[24] with drift : 107613.1 ## ARIMA(1,1,2)(0,0,2)[24] : 107612.9 ## ARIMA(1,1,2)(0,0,2)[24] with drift : 107614.5 ## ARIMA(1,1,2)(1,0,0)[24] : 107635.3 ## ARIMA(1,1,2)(1,0,0)[24] with drift : 107637 ## ARIMA(1,1,2)(1,0,1)[24] : 107637.3 ## ARIMA(1,1,2)(1,0,1)[24] with drift : 107639 ## ARIMA(1,1,2)(2,0,0)[24] : 107660.6 ## ARIMA(1,1,2)(2,0,0)[24] with drift : 107662.3 ## ARIMA(1,1,3) : 107440.7 ## ARIMA(1,1,3) with drift : 107442.4 ## ARIMA(1,1,3)(0,0,1)[24] : 107442.1 ## ARIMA(1,1,3)(0,0,1)[24] with drift : 107443.7 ## ARIMA(1,1,3)(1,0,0)[24] : 107466 ## ARIMA(1,1,3)(1,0,0)[24] with drift : 107467.7 ## ARIMA(1,1,4) : 104357.1 ## ARIMA(1,1,4) with drift : 104359.1 ## ARIMA(2,1,0) : 114693.2 ## ARIMA(2,1,0) with drift : 114695.2 ## ARIMA(2,1,0)(0,0,1)[24] : 114695.1 ## ARIMA(2,1,0)(0,0,1)[24] with drift : 114697.1 ## ARIMA(2,1,0)(0,0,2)[24] : 114696.6 ## ARIMA(2,1,0)(0,0,2)[24] with drift : 114698.6 ## ARIMA(2,1,0)(1,0,0)[24] : 114718.9 ## ARIMA(2,1,0)(1,0,0)[24] with drift : 114720.9 ## ARIMA(2,1,0)(1,0,1)[24] : Inf ## ARIMA(2,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,0)(1,0,2)[24] : Inf ## ARIMA(2,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(2,1,0)(2,0,0)[24] : 114744.4 ## ARIMA(2,1,0)(2,0,0)[24] with drift : 114746.4 ## ARIMA(2,1,0)(2,0,1)[24] : Inf ## ARIMA(2,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(2,1,1) : 107556.5 ## ARIMA(2,1,1) with drift : 107558.1 ## ARIMA(2,1,1)(0,0,1)[24] : 107557.7 ## ARIMA(2,1,1)(0,0,1)[24] with drift : 107559.4 ## ARIMA(2,1,1)(0,0,2)[24] : 107559.3 ## ARIMA(2,1,1)(0,0,2)[24] with drift : 107561 ## ARIMA(2,1,1)(1,0,0)[24] : 107581.6 ## ARIMA(2,1,1)(1,0,0)[24] with drift : 107583.2 ## ARIMA(2,1,1)(1,0,1)[24] : 107583.6 ## ARIMA(2,1,1)(1,0,1)[24] with drift : 107585.2 ## ARIMA(2,1,1)(2,0,0)[24] : 107606.9 ## ARIMA(2,1,1)(2,0,0)[24] with drift : 107608.6 ## ARIMA(2,1,2) : 104088.8 ## ARIMA(2,1,2) with drift : 104090.5 ## ARIMA(2,1,2)(0,0,1)[24] : 104087.4 ## ARIMA(2,1,2)(0,0,1)[24] with drift : 104089 ## ARIMA(2,1,2)(1,0,0)[24] : 104111.2 ## ARIMA(2,1,2)(1,0,0)[24] with drift : 104112.9 ## ARIMA(2,1,3) : 104080.4 ## ARIMA(2,1,3) with drift : 104082.1 ## ARIMA(3,1,0) : 114683 ## ARIMA(3,1,0) with drift : 114685 ## ARIMA(3,1,0)(0,0,1)[24] : 114684.9 ## ARIMA(3,1,0)(0,0,1)[24] with drift : 114686.9 ## ARIMA(3,1,0)(0,0,2)[24] : 114686.5 ## ARIMA(3,1,0)(0,0,2)[24] with drift : 114688.5 ## ARIMA(3,1,0)(1,0,0)[24] : 114708.8 ## ARIMA(3,1,0)(1,0,0)[24] with drift : 114710.8 ## ARIMA(3,1,0)(1,0,1)[24] : Inf ## ARIMA(3,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(3,1,0)(2,0,0)[24] : 114734.2 ## ARIMA(3,1,0)(2,0,0)[24] with drift : 114736.2 ## ARIMA(3,1,1) : 107367.9 ## ARIMA(3,1,1) with drift : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] with drift : 107371.3 ## ARIMA(3,1,1)(1,0,0)[24] : 107393.5 ## ARIMA(3,1,1)(1,0,0)[24] with drift : 107395.2 ## ARIMA(3,1,2) : 104077.9 ## ARIMA(3,1,2) with drift : 104079.5 ## ARIMA(4,1,0) : 107261.2 ## ARIMA(4,1,0) with drift : 107263.2 ## ARIMA(4,1,0)(0,0,1)[24] : 107260.4 ## ARIMA(4,1,0)(0,0,1)[24] with drift : 107262.4 ## ARIMA(4,1,0)(1,0,0)[24] : 107284.3 ## ARIMA(4,1,0)(1,0,0)[24] with drift : 107286.3 ## ARIMA(4,1,1) : 107262.6 ## ARIMA(4,1,1) with drift : 107264.6 ## ARIMA(5,1,0) : 107263.9 ## ARIMA(5,1,0) with drift : 107265.9 ## ## Now re-fitting the best model(s) without approximations... ## ## ## ## ## Best model: ARIMA(3,1,2) El mejor modelo ARIMA(3,1,2) tiene: Tres términos autorregresivos (AR), la serie depende de los tres valores anteriores de sí misma. Diferenciación (d=1), se toma la primera diferencia para estabilizar la tendencia. Dos términos de media móvil (MA) presentaron el menor AICc (Akaike Information Criterion corregido), por tanto, el mejor equilibrio entre ajuste y simplicidad. ARIMA(3,1,2) describe una dinámica compleja pero estable, donde tanto la inercia de los valores pasados como los errores anteriores influyen en la predicción actual. 4.12 Verificación de supuestos del nuevo modelo # ============================================================ # Diagnóstico de los residuos del modelo ARIMA (log) # ============================================================ checkresiduals(m_log) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,1,2) ## Q* = 3151.5, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, existe autocorrelación significativa en los errores a ciertos rezagos. El modelo ARIMA(3,1,2), aunque mejora respecto al anterior, no captura toda la estructura dependiente de la serie. Diagnósticos residuales del modelo ARIMA(3,1,2) Los residuos son en general estacionarios, pero aún presentan fluctuaciones en la varianza y algunos picos pronunciados que podrían afectar la normalidad. El modelo logra reducir significativamente la autocorrelación, aunque persisten correlaciones menores en rezagos cortos, coherentes con el resultado del test de Ljung–Box La distribución de los residuos se aproxima a la normalidad, aunque no perfectamente. La transformación logarítmica ayudó a estabilizar la varianza, pero persisten valores extremos. 4.13 Pronóstico con el modelo mejorado (escala logarítmica) # ============================================================ # Pronóstico en escala logarítmica # ============================================================ h &lt;- 24 * horizon_days # pronóstico a 7 días (horas) fc_log &lt;- forecast(m_log, h = h) autoplot(fc_log) + labs(title = paste0(&quot;Pronóstico log-transformado con ARIMA (&quot;, horizon_days, &quot; días)&quot;), y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal(base_size = 12) 4.13.1 Reconversión a escala original (exponencial inversa) # ============================================================ # Transformar el pronóstico a escala original # ============================================================ fc_exp &lt;- expm1(fc_log$mean) # inversa de log1p fc_exp80 &lt;- expm1(fc_log$lower[,&quot;80%&quot;]) fc_exp95 &lt;- expm1(fc_log$upper[,&quot;95%&quot;]) # Crear data frame para visualización f_times &lt;- seq(from = max(df_impu[[time_col]]) + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) fc_plot &lt;- tibble( time = f_times, mean = fc_exp, lo80 = fc_exp80, hi80 = fc_exp95 ) # Graficar pronóstico en escala original ggplot(fc_plot, aes(x = time, y = mean)) + geom_ribbon(aes(ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25) + geom_line(color = &quot;#1f77b4&quot;, linewidth = 1.1) + labs(title = &quot;Pronóstico ARIMA (log-transformado, 7 días)&quot;, subtitle = &quot;Transformación log(1 + x) revertida a escala original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia estimada&quot;) + theme_minimal(base_size = 12) El modelo proyecta una potencia promedio estable a lo largo del horizonte de 7 días, con un leve crecimiento progresivo. Este patrón indica que no se esperan cambios abruptos ni tendencia marcada en el corto plazo, lo cual concuerda con una serie que, tras la transformación y diferenciación, se comporta de manera estacionaria. Las bandas de confianza se ensanchán conforme avanza el tiempo, lo que es normal en modelos ARIMA: la incertidumbre aumenta al alejarnos de la última observación disponible. La transformación log1p() redujo la asimetría de la serie, estabilizó la varianza y permitió que el modelo ARIMA se ajustara mejor. Al revertir la transformación (exp(x) - 1), los valores pronosticados se amplifican exponencialmente, por lo que incluso pequeñas variaciones en los residuos logarítmicos se traducen en grandes rangos de incertidumbre en la escala original. 4.14 Conclusiones El análisis realizado sobre la serie temporal de potencia permitió evaluar y comparar el desempeño del modelo ARIMA bajo dos enfoques: primero, utilizando la serie en su escala original, y posteriormente aplicando una transformación logarítmica (log1p) para estabilizar la varianza y mejorar la capacidad predictiva del modelo. Modelo con la serie original El ajuste inicial con el modelo ARIMA(1,1,1)(0,0,2)[24] mostró limitaciones en los residuos: El test de Ljung–Box (Q = 3889, p &lt; 0.05)* reveló autocorrelación significativa, indicando que el modelo no capturó completamente la estructura temporal de los datos. Los gráficos diagnósticos evidenciaron heterocedasticidad y valores atípicos, lo cual afectó la normalidad de los residuos. En consecuencia, aunque el modelo reprodujo la tendencia general, su precisión predictiva fue limitada y las bandas de confianza del pronóstico resultaron amplias e inestables. Modelo con la serie log-transformada Para mejorar el comportamiento del modelo, se aplicó una transformación logarítmica que redujo la variabilidad extrema y permitió una distribución más simétrica. El modelo seleccionado automáticamente fue ARIMA(3,1,2), que presentó un AIC significativamente menor (≈ 104 080 frente a &gt;111 000 en la serie original), reflejando un mejor ajuste global. Los residuos del modelo se centraron alrededor de cero, con autocorrelación mínima y distribución casi normal. El test de Ljung–Box (Q = 3151, p &lt; 0.05)* indicó todavía cierta dependencia remanente, aunque en menor grado que el modelo previo. El pronóstico a 7 días, una vez revertida la transformación (exp(x) - 1), mostró una tendencia estable y coherente con el comportamiento reciente de la serie, con bandas de confianza más razonables que en el caso anterior, aunque naturalmente amplias por la incertidumbre acumulada. En conclusión, el modelo ARIMA aplicado sobre la serie original permitió identificar la tendencia general, pero su desempeño predictivo se vio afectado por la alta varianza y la presencia de valores atípicos. En contraste, la aplicación de la transformación logarítmica mejoró la calidad del ajuste, redujo la dispersión y generó un modelo ARIMA(3,1,2) más parsimonioso y estable, con predicciones más coherentes y bandas de confianza razonables. En términos prácticos, se evidencia que la transformación logarítmica es una estrategia efectiva para estabilizar la varianza y mejorar la capacidad de predicción de modelos ARIMA en series con gran amplitud y comportamiento no estacionario. Por tanto, se recomienda utilizar la versión log-transformada para futuras predicciones y análisis, dado que ofrece un mejor equilibrio entre ajuste, estabilidad y capacidad interpretativa, reflejando de manera más realista la evolución de la potencia en el tiempo. Se recomienda analizar los valores de potencia de la serie de tiempo de forma independiente para cada uno de los tres circuitos eléctricos que conforman la potencia de salida de la subestación. Asimismo, se sugiere generar predicciones individuales por circuito y consolidarlas posteriormente. Esta estrategia permite evitar problemas de valores faltantes y atípicos, además de reducir la variabilidad de los datos. 4.14.1 Resumen de tiempos de ejecución del código tabla_tiempos &lt;- report_timing_table() if (!is.null(tabla_tiempos)) { knitr::kable(tabla_tiempos, caption = &quot;Resumen de tiempos por bloque&quot;) } else { cat(&quot;No se registraron bloques cronometrados.\\n&quot;) } Table 4.1: Resumen de tiempos por bloque Bloque Tiempo Unidad Estado Mensaje Imputación (na.interp) 0.037 s OK ACF/PACF (original) 0.119 s OK ACF/PACF (diferenciada) 0.120 s OK STL (ventana 4 semanas) 0.020 s OK Ajuste SARIMA + Pronóstico 204.106 s OK Changepoint (media diaria, PELT) 0.019 s OK Ajuste SARIMA TS log-transformada 372.197 s OK "],["Modelización.html", "5 Modelos de pronóstico - Metodología Holt – Winter 5.1 Resumen 5.2 Cambio de la serie de tiempo a circuito de potencia - Preprocesamiento y visualización 5.3 Preprocesamiento de la serie de datos para Holt–Winters 5.4 División de los datos entre TRAIN/TEST 5.5 Ajuste Holt–Winters aditivo y multiplicativo (usando TRAIN y h definidos) 5.6 Gráfica comparativa: TRAIN/TEST + pronósticos HW (aditivo vs. multiplicativo) 5.7 Evaluación en TEST (MAPE y RMSE) 5.8 Comparación con un ARIMA simple 5.9 Holt Winter en Box–Cox (ajuste + pronóstico en BC + reconversión a escala original) 5.10 Gráfica comparativa (TRAIN/TEST en original) + HW Box–Cox reconvertido 5.11 Zoom al pronóstico Holt Winter Box–Cox en original 5.12 Métricas en TEST comparando en escala original (Holt Winter y Box–Cox) 5.13 Resumen final de métricas (RMSE / MAPE) 5.14 Gráficas de predicción por modelo 5.15 Resumen de tiempos de ejecución del código", " 5 Modelos de pronóstico - Metodología Holt – Winter 5.1 Resumen Los métodos de suavizamiento desempeñan un papel fundamental, ya que permiten reducir el ruido en los datos, resaltando la estructura subyacente de la serie. Entre ellos, destacan el promedio móvil, el suavizamiento exponencial simple y el modelo de Holt-Winters, que constituye una extensión más completa capaz de captar tanto la tendencia como la estacionalidad. En este capítulo se aplica el método de Holt-Winters como herramienta de predicción para series con comportamiento no estacionario. Sin embargo, la serie de datos analizada en el capitulo anterior presenta alta variabilidad en los datos debido a que corresponde a la sumatoria de tres series de datos asociados a los circuitos de salida de la subestación eléctrica, de las cuales, una serie presenta faltantes aproximadamente en el 50% del horizonte de tiempo, objeto de este estudio; otra serie presente aproximadamente un 25% de faltantes, sumada a una alta variabilidad en las media de la potencia, generando un gran porcentaje de outliers probablemente incorrectos. Razón por la cual, para continuar con el análisis de la serie de tiempo, seleccionamos solo un circuito de salida que tiene la tendencia más estable con un bajo porcentaje de datos faltantes. 5.2 Cambio de la serie de tiempo a circuito de potencia - Preprocesamiento y visualización 5.2.1 Carga de librerías library(readr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(scales) library(zoo) library(forecast) library(tseries) library(changepoint) 5.2.2 Carga de datos y visualización csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot;; y_col &lt;- &quot;VALOR_IMPUTADO&quot; df &lt;- tryCatch(readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE)) # Parseo robusto de fecha-hora y valor df[[time_col]] &lt;- parse_date_time(df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ) df[[y_col]] &lt;- suppressWarnings(as.numeric(df[[y_col]])) # Malla horaria completa para marcar NA (sin imputar) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% arrange(.data[[time_col]]) %&gt;% select(!!time_col, !!y_col) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) # Serie imputada (para métodos que exigen regularidad) tm(&quot;Imputación (na.interp)&quot;, { df_impu &lt;&lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) }) # Vista rápida # ggplot(df_full, aes(x = .data[[time_col]], y = .data[[y_col]])) + # geom_line(na.rm = TRUE) + # labs(title = &quot;Serie horaria de potencia (con huecos)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal() na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } agg_by &lt;- function(data, unit, label, time_col, y_col) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% mutate(freq = label) } na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) diaria &lt;- agg_by(df_full, &quot;day&quot;, &quot;Diaria&quot;, time_col, y_col) semanal &lt;- agg_by(df_full, &quot;week&quot;, &quot;Semanal&quot;, time_col, y_col) mensual &lt;- agg_by(df_full, &quot;month&quot;, &quot;Mensual&quot;, time_col, y_col) anual &lt;- agg_by(df_full, &quot;year&quot;, &quot;Anual&quot;, time_col, y_col) plot_df &lt;- bind_rows(diaria, semanal, mensual, anual) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;, &quot;Semanal&quot;, &quot;Mensual&quot;, &quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.3) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.6, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + labs(title = &quot;Potencia — vistas diaria, semanal, mensual y anual&quot;, subtitle = &quot;Bandas rojas: periodos con NA en la serie original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) La serie presenta coherencia temporal y crecimiento moderado en todas las escalas. Existen períodos con datos faltantes y posible ruido o outliers en la frecuencia diaria, que en las gráficas semanal, mensual y anual se atenúan. Esta exploración multiescala sugiere que la serie es adecuada para modelar con métodos como Holt–Winters o ARIMA, siempre y cuando antes se aplique imputación de valores faltantes, detección y corrección de outliers, y estabilización de la varianza. 5.2.3 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación # Vector numérico imputado serie_vec &lt;- as.numeric(df_impu$val_impu) # ADF en serie original adf_raw &lt;- tseries::adf.test(serie_vec, k = 24) adf_raw ## ## Augmented Dickey-Fuller Test ## ## data: serie_vec ## Dickey-Fuller = -37.721, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria en media. # Diferenciación sugerida y gráfico d_sugerido &lt;- forecast::ndiffs(serie_vec) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 “ndiffs” sugiere una diferenciación (d = 1) para estabilizar tendencia y variabilidad. serie_diff &lt;- if (d_sugerido &gt; 0) diff(serie_vec, differences = d_sugerido) else serie_vec df_diff &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]])[seq_along(serie_vec)], Original = as.numeric(serie_vec), Diferenciada = c(rep(NA, d_sugerido), as.numeric(serie_diff)) ) |&gt; tidyr::pivot_longer(cols = c(Original, Diferenciada), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) ggplot(df_diff, aes(time, Valor, color = Serie)) + geom_line(linewidth = 0.6, alpha = 0.9, na.rm = TRUE) + scale_color_manual(values = c(Original = &quot;#6B7280&quot;, Diferenciada = &quot;#1F77B4&quot;)) + labs(title = &quot;Serie original vs. diferenciada&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia / ΔPotencia&quot;, color = &quot;Serie&quot;) + theme_minimal(base_size = 12) La serie diferenciada muestra valores centrados alrededor de cero, eliminando la tendencia de largo plazo. La dispersión es más estable y simétrica, lo que indica que la varianza se ha homogenizado. La diferenciación logró transformar la serie en estacionaria, condición necesaria para aplicar modelos como ARIMA. Aún se observan algunos picos esporádicos (outliers) que podrían representar eventos atípicos o ruido extremo. # ADF nuevamente si se diferenció if (d_sugerido &gt; 0) { cat(&quot;\\nRe-prueba ADF en la serie diferenciada (d =&quot;, d_sugerido, &quot;):\\n&quot;) print(tseries::adf.test(serie_diff, k = 24)) } ## ## Re-prueba ADF en la serie diferenciada (d = 1 ): ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff ## Dickey-Fuller = -91.466, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) para la serie diferenciada indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria. La serie diferenciada (d = 1) cumple con el requisito de estacionariedad, condición indispensable para la modelación ARIMA. No se requieren más diferenciaciones. 5.2.4 ACF y PACF (original y diferenciada) # ============================================================ # 6. ACF y PACF (original y diferenciada) # ============================================================ # --- Calcular ACF/PACF de la serie original --- t0 &lt;- Sys.time() acf_obj &lt;- try(acf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_obj &lt;- try(pacf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (original)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_obj, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) # --- Graficar ACF/PACF de la serie original --- if (!inherits(acf_obj, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_obj, &quot;try-error&quot;)) { acf_df &lt;- data.frame(lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf)) pacf_df &lt;- data.frame(lag = as.numeric(pacf_obj$lag), pacf = as.numeric(pacf_obj$acf)) ci &lt;- 1.96 / sqrt(length(serie_vec)) p1 &lt;- ggplot(acf_df, aes(lag, acf)) + geom_col(fill = &quot;#1f77b4&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p2 &lt;- ggplot(pacf_df, aes(lag, pacf)) + geom_col(fill = &quot;#ff7f0e&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p1); print(p2) } else { cat(&quot;Error al calcular ACF/PACF de la serie original.\\n&quot;) } # --- Serie diferenciada --- if (exists(&quot;serie_diff&quot;) &amp;&amp; length(serie_diff) &gt; 10 &amp;&amp; !identical(serie_diff, serie_vec)) { t0 &lt;- Sys.time() acf_d &lt;- try(acf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_d &lt;- try(pacf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (diferenciada)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_d, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) if (!inherits(acf_d, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_d, &quot;try-error&quot;)) { acf_df_d &lt;- data.frame(lag = as.numeric(acf_d$lag), acf = as.numeric(acf_d$acf)) pacf_df_d &lt;- data.frame(lag = as.numeric(pacf_d$lag), pacf = as.numeric(pacf_d$acf)) ci_d &lt;- 1.96 / sqrt(length(serie_diff)) p3 &lt;- ggplot(acf_df_d, aes(lag, acf)) + geom_col(fill = &quot;#17becf&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p4 &lt;- ggplot(pacf_df_d, aes(lag, pacf)) + geom_col(fill = &quot;#2ca02c&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p3); print(p4) } else { cat(&quot;Error al calcular ACF/PACF diferenciada.\\n&quot;) } } La ACF de la serie original presenta una decadencia lenta y oscilante, sin cortar bruscamente, lo que indica que la serie no es estacionaria. Se observan picos significativos en rezagos cercanos a 24, 48, 72, 96 y 120 horas (múltiplos de 24), lo cual sugiere una estacionalidad diaria (ciclos de 24 h). El patrón sinusoidal de la ACF evidencia repetición de ciclos de comportamiento, probablemente relacionados con el uso o generación de potencia a lo largo del día. La PACF de la serie original muestra un pico muy fuerte en el primer rezago (lag 1) y luego decae rápidamente a valores cercanos a cer, esto indica alta autocorrelación inmediata, es decir, el valor actual depende fuertemente del valor anterior. El resto de los rezagos no son significativos, lo que refuerza la presencia de una tendencia o componente autorregresiva dominante. La serie original no es estacionaria, presenta tendencia y una fuerte estacionalidad diaria. Esto confirma la necesidad de diferenciar la serie antes del modelado ARIMA. La ACF de la serie diferenciada muestra que los valores caen a cero rápidamente, salvo en algunos rezagos aislados. La pérdida de la estructura oscilante confirma que la tendencia fue eliminada y que la serie se ha vuelto más estacionaria. Persisten algunos picos moderados en múltiplos de 24 horas, indicando que aún hay componente estacional residual (ciclo diario). En la PACF de la serie diferenciada muestra solo unos pocos rezagos significativos (lag 1 y algunos alrededor de 24), suguiriendo que podría haber un componente AR de bajo orden (p ≈ 1) y posiblemente un componente estacional AR o MA en los múltiplos de 24. La diferenciación logró estacionarizar la serie, eliminando la tendencia. 5.2.5 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else if (&quot;VALOR_IMPUTADO&quot; %in% names(df_impu)) &quot;VALOR_IMPUTADO&quot; else stop(&quot;No encuentro columna de valores: usa &#39;val_impu&#39; o &#39;VALOR_IMPUTADO&#39;.&quot;) # Utilidad para detectar columna estacional por periodo (acepta &#39;Seasonal-24&#39;, &#39;Seasonal 24&#39;, etc.) find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) if (!any(is_seas)) return(NULL) seas_nm &lt;- nm[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # ========== A) df_seas24: Estacionalidad diaria (24h) desde SERIE HORARIA ========== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_m_hour &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_h &lt;- as.data.frame(fit_m_hour) col_s24 &lt;- find_seasonal_col(comp_h, 24) if (is.null(col_s24)) { # fallback: primera &#39;Seasonal&#39; si no se pudo detectar 24 específicamente cand &lt;- grep(&quot;^Seasonal&quot;, names(comp_h), ignore.case = TRUE, value = TRUE) col_s24 &lt;- cand[1] } df_seas24 &lt;- tibble( time = time_hr, Componente = &quot;Estacionalidad diaria (24h)&quot;, Valor = comp_h[[col_s24]] ) # ========== B) df_seas12: Estacionalidad mensual (12) desde SERIE MENSUAL ========== monthly &lt;- df_impu %&gt;% mutate(mes = floor_date(.data[[time_col]], &quot;month&quot;)) %&gt;% summarise(.by = mes, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(mes) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(year(min(monthly$mes)), month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # detectar columna estacional (nombre puede ser &quot;seasonal&quot;/&quot;Seasonal&quot;) seas_col_m &lt;- names(comp_m)[grepl(&quot;season&quot;, names(comp_m), ignore.case = TRUE)][1] if (is.na(seas_col_m)) stop(&quot;No se encontró columna estacional en STL mensual.&quot;) df_seas12 &lt;- tibble( time = as.POSIXct(monthly$mes), # unificamos a POSIXct Componente = &quot;Estacionalidad mensual (12)&quot;, Valor = comp_m[[seas_col_m]] ) # ========== C) df_day_panel: Observada, Tendencia, Semanal(7d), Anual(365d), Residuo (SERIE DIARIA) ========== daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% summarise(.by = day, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(day) ts_day &lt;- forecast::msts(daily$y, seasonal.periods = c(7, 365)) fit_m_day &lt;- forecast::mstl(ts_day, robust = TRUE) comp_d &lt;- as.data.frame(fit_m_day) # Normalizamos nombres para &#39;Trend&#39; y &#39;Remainder&#39; nmd &lt;- names(comp_d) nmd &lt;- sub(&quot;^trend$&quot;, &quot;Trend&quot;, nmd, ignore.case = TRUE) nmd &lt;- sub(&quot;^remainder$&quot;, &quot;Remainder&quot;, nmd, ignore.case = TRUE) names(comp_d) &lt;- nmd # Detectar columnas estacionales 7 y 365 is_seas &lt;- grepl(&quot;^Seasonal&quot;, names(comp_d), ignore.case = TRUE) seas_nms &lt;- names(comp_d)[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } seas_p &lt;- vapply(seas_nms, getp, integer(1)) idx7 &lt;- which(seas_p == 7) idx365 &lt;- which(seas_p == 365) seas7 &lt;- if (length(idx7)) comp_d[[seas_nms[idx7[1]]]] else NULL seas365 &lt;- if (length(idx365)) comp_d[[seas_nms[idx365[1]]]] else NULL df_day_panel &lt;- tibble( time = as.POSIXct(daily$day), Observada = daily$y, Tendencia = if (&quot;Trend&quot; %in% names(comp_d)) comp_d$Trend else NA_real_, Residuo = if (&quot;Remainder&quot; %in% names(comp_d)) comp_d$Remainder else NA_real_ ) if (!is.null(seas7)) df_day_panel[[&quot;Estacionalidad semanal (7d)&quot;]] &lt;- seas7 if (!is.null(seas365)) df_day_panel[[&quot;Estacionalidad anual (365d)&quot;]] &lt;- seas365 df_day_panel &lt;- df_day_panel |&gt; pivot_longer(-time, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) # ========== D) Panel combinado ========== panel_all &lt;- bind_rows( df_day_panel, # Observada/Tendencia/Residuo + 7d/365d si existen df_seas24, # Estacionalidad diaria (24h) desde HORAS df_seas12 # Estacionalidad mensual (12) desde MESES ) %&gt;% mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;, &quot;Tendencia&quot;, &quot;Estacionalidad diaria (24h)&quot;, &quot;Estacionalidad semanal (7d)&quot;, &quot;Estacionalidad mensual (12)&quot;, &quot;Estacionalidad anual (365d)&quot;, &quot;Residuo&quot;) ) ) # ========== E) Gráfico ========== ggplot(panel_all, aes(x = time, y = Valor)) + geom_line(linewidth = 0.45, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;, drop = FALSE) + scale_x_datetime(date_breaks = &quot;6 months&quot;, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) + labs( title = &quot;Descomposición combinada de la serie completa&quot;, subtitle = &quot;Tendencia + Estacionalidades diaria (24h), semanal (7d), mensual (12) y anual (365d) + Residuo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) La descomposición evidencia que la serie de potencia es altamente estructurada, con una tendencia creciente de largo plazo, ciclos estacionales fuertes en las escalas diaria y semanal, modulaciones mensuales y anuales de menor intensidad y un residuo controlado, con algunos eventos atípicos aislados. 5.2.6 Promedios móviles (24h, 168h, 720h) df_ma &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]]), Original = as.numeric(df_impu$val_impu), MA_24 = as.numeric(zoo::rollmean(df_impu$val_impu, 24, align = &quot;right&quot;, fill = NA)), MA_168 = as.numeric(zoo::rollmean(df_impu$val_impu, 168, align = &quot;right&quot;, fill = NA)), MA_720 = as.numeric(zoo::rollmean(df_impu$val_impu, 720, align = &quot;right&quot;, fill = NA)) ) ggplot(df_ma, aes(x = time)) + geom_line(aes(y = Original), color = &quot;grey70&quot;, linewidth = 0.3, alpha = 0.6, na.rm = TRUE) + # Halo para la verde geom_line(aes(y = MA_168), color = &quot;white&quot;, linewidth = 1.8, alpha = 0.9, na.rm = TRUE) + # Mapear color con etiquetas literales -&gt; leyenda geom_line(aes(y = MA_24, color = &quot;MA 24h&quot;), linewidth = 1.0, alpha = 0.95, na.rm = TRUE) + geom_line(aes(y = MA_168, color = &quot;MA 168h&quot;), linewidth = 1.0, alpha = 1.00, na.rm = TRUE) + geom_line(aes(y = MA_720, color = &quot;MA 720h&quot;), linewidth = 1.0, alpha = 0.95, na.rm = TRUE) + scale_color_manual( values = c(&quot;MA 24h&quot; = &quot;#1f77b4&quot;, &quot;MA 168h&quot; = &quot;#00B050&quot;, &quot;MA 720h&quot; = &quot;#D62728&quot;), name = &quot;Serie&quot;, breaks = c(&quot;MA 24h&quot;, &quot;MA 168h&quot;, &quot;MA 720h&quot;), labels = c(&quot;MA 24h (1 día)&quot;, &quot;MA 168h (1 semana)&quot;, &quot;MA 720h (1 mes)&quot;) ) + labs(title = &quot;Promedios móviles (24h, 168h, 720h)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), legend.position = &quot;right&quot;, panel.grid.minor = element_blank()) Las tres curvas muestran consistencia ascendente: la serie tiende a crecer lentamente con el tiempo. Las diferencias de amplitud entre los promedios móviles demuestran que la serie presenta alta volatilidad horaria, pero un comportamiento más estable a mediano y largo plazo. Los picos muy marcados, especialmente entre 2019 y 2024, pueden deberse a eventos excepcionales o registros atípicos, sin afectar la tendencia general. El análisis de promedios móviles evidencia una serie con fuerte variabilidad de corto plazo, pero con una tendencia creciente sostenida en el largo plazo. 5.2.7 Selección del modelo eficiente (auto.arima) y Pronóstico tm(&quot;Ajuste SARIMA + Pronóstico&quot;, { y_fit &lt;&lt;- ts(serie_vec, frequency = 24) m_auto &lt;&lt;- forecast::auto.arima( y_fit, d = d_sugerido, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx, max.p = 5, max.q = 5, max.P = 2, max.Q = 2 ) print(m_auto) h_days &lt;&lt;- horizon_days h &lt;&lt;- 24 * h_days fc &lt;&lt;- forecast::forecast(m_auto, h = h) print(autoplot(fc) + labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;)) }) ## Series: y_fit ## ARIMA(1,1,1)(2,0,1)[24] with drift ## ## Coefficients: ## ar1 ma1 sar1 sar2 sma1 drift ## 0.3106 -0.2732 0.5660 0.1735 -0.5697 0.0069 ## s.e. 0.0315 0.0319 0.0197 0.0047 0.0205 0.2816 ## ## sigma^2 = 3105: log likelihood = -645389 ## AIC=1290792 AICc=1290792 BIC=1290860 5.2.7.1 Zoom al pronóstico del modelo eficiente (auto.arima) # ==== ZOOM FINAL AL PRONÓSTICO ==== history_days &lt;- 21 h_days &lt;- horizon_days %||% 7 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) h &lt;- length(fc$mean) f_times &lt;- seq(from = t_max + hours(1), by = &quot;1 hour&quot;, length.out = h) fc_df &lt;- tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[,&quot;80%&quot;]), hi80 = as.numeric(fc$upper[,&quot;80%&quot;]), lo95 = as.numeric(fc$lower[,&quot;95%&quot;]), hi95 = as.numeric(fc$upper[,&quot;95%&quot;]) ) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.4, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, # ← espaciado más grande date_labels = &quot;%d-%b&quot;) + # ← formato sin hora coord_cartesian(ylim = c(0, 2000)) + # recorta sin descartar filas labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1) # ← evita solapamiento ) El modelo captura una estructura diaria muy fuerte y una persistencia corta; la tendencia ya fue removida con d = 1; el “drift” es irrelevante. En la gráfica general el pronóstico es casi invisible por el rango y la alta variabilidad histórica (picos/outliers). En la gráfica de pronóstico, la línea azul se mantiene alrededor de 850–950 (un nivel cercano al observado justo antes del corte), con ondulación diaria y ciclos de 24 h. El SARIMA escogido capta el patrón diario y da una proyección estable a 7 días, pero la incertidumbre es alta por la variabilidad de la serie. Las bandas amplias avisan que, en escala original, la serie es muy heterocedástica y contiene outliers. 5.2.8 Puntos de cambio y visualización daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% group_by(day) %&gt;% summarise(y = mean(val_impu), .groups = &quot;drop&quot;) tm(&quot;Changepoint&quot;, { cp &lt;&lt;- cpt.mean(daily$y, method = &quot;PELT&quot;, penalty = &quot;SIC&quot;) }) head (cp@cpts,100) # índices de cambio ## [1] 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ## [19] 48 49 50 51 52 53 54 55 57 58 59 60 61 62 63 64 66 67 ## [37] 68 69 70 71 72 73 74 75 76 77 79 80 81 82 83 84 85 86 ## [55] 87 88 89 90 91 92 93 94 95 97 98 99 100 101 102 103 104 105 ## [73] 106 107 109 110 111 112 113 114 115 116 117 118 119 120 121 123 124 125 ## [91] 126 127 128 129 130 131 132 134 136 137 # Overlay en la curva diaria ggplot(daily, aes(day, y)) + geom_line() + geom_vline(xintercept = daily$day[cp@cpts], linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Media diaria con puntos de cambio (cpt.mean)&quot;, x = &quot;Día&quot;, y = &quot;Potencia media diaria&quot;) + theme_minimal() Líneas rojas horizontales indican los puntos de cambio detectados en la media de la serie. Cada uno de ellos marca un momento en el que el nivel promedio de la potencia cambió de manera estadísticamente significativa. Se observa en la gráfica: Alta frecuencia de puntos de cambio (bandas rojas), sugiriendo que la serie es altamente inestable o no estacionaria a lo largo del tiempo. Cambios localizados por períodos, entre 2018 y 2020, la serie muestra mayor variabilidad y frecuentes saltos reflejando volátilidad o errores de registro. Entre 2021 y 2024, los cambios son menos abruptos, aunque todavía se observan alteraciones cíclicas en los promedios diarios. Entre 2024–2025, la media parece estabilizarse en un rango más constante, pero aún con picos esporádicos (outliers). La media diaria parece mostrar una tendencia leve al alza, con algunos descensos temporales; los puntos de cambio ayudan a identificar momentos clave donde la serie cambió de nivel promedio. La gráfica evidencia que la potencia media diaria ha experimentado múltiples rupturas estructurales en su comportamiento a lo largo de los años. Estas discontinuidades confirman que la serie no es estacionaria en media y requiere preprocesamiento o modelado segmentado. 5.2.9 Outliers y verificación de supuestos del ARIMA # Outliers to &lt;- tryCatch(forecast::tsoutliers(ts(serie_vec, frequency = 24)), error = function(e) NULL) if (!is.null(to)) { #print(to) idx &lt;- to$index df_ol &lt;- tibble(time = as.POSIXct(df_impu[[time_col]])[idx], y = serie_vec[idx]) ggplot(tibble(time = as.POSIXct(df_impu[[time_col]]), y = serie_vec), aes(time, y)) + geom_line(alpha = 0.6) + geom_point(data = df_ol, aes(time, y), color = &quot;red&quot;, size = 1.4) + labs(title = &quot;Outliers detectados (forecast::tsoutliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() } La gráfica revela que la serie de potencia presenta numerosos valores atípicos, distribuidos a lo largo de todo el periodo y de ambos signos. Esto confirma que la serie es altamente irregular y heterocedástica, por lo que requiere una etapa robusta de limpieza y preprocesamiento antes de aplicar cualquier modelo predictivo. # Supuestos del modelo ARIMA (residuales) checkresiduals(m_auto) # ACF de residuales, Ljung-Box, histograma, qq-plot ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,1)(2,0,1)[24] with drift ## Q* = 4269.1, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test p-value &lt; 2.2e-16, se rechaza H₀ (los residuos son ruido blanco), los residuos aún tienen correlación significativa. Diagnósticos residuales del modelo ARIMA Los residuos oscilan alrededor de 0, sin embargo, hay picos grandes (±2000), lo que sugiere valores atípicos o episodios de alta volatilidad no explicados por el modelo. La amplitud es variable (heterocedasticidad leve). ACF (Función de Autocorrelación de los residuos), los residuos aún presentan correlación, el modelo no captura por completo la estructura temporal. Las barras deben estar dentro de las bandas azules. Histograma y densidad de los residuos, es muy concentrado en torno a 0, pero con colas largas y picos extremos, indicando distribución leptocúrtica (no normal). Los residuos no son normales, lo que afecta la validez de los intervalos de predicción si se asume normalidad. El modelo no cumple totalmente los supuestos de ruido blanco, aunque capta bien la tendencia general, persisten correlaciones estacionales y algunos outliers o periodos anómalos. 5.2.10 Transformación logarítmica para estabilizar la varianza # ============================================================ # Transformación logarítmica de la serie de potencia # ============================================================ # Evitar log(0) o negativos df_log &lt;- df_impu %&gt;% mutate(val_log = log1p(val_impu)) # log(1 + x) evita infinitos # Crear serie temporal log-transformada ts_log &lt;- ts(df_log$val_log, frequency = 24) # frecuencia diaria (24 horas) # Visualización básica autoplot(ts_log) + labs(title = &quot;Serie transformada logarítmicamente (log1p)&quot;, y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal() La transformación logarítmica logró reducir la variabilidad y estabilizar la escala de la serie, mejorando su comportamiento estadístico. Sin embargo, persisten caídas bruscas que deben tratarse (por imputación o filtrado). La serie transformada es más regular y apta para modelado estadístico, pero sigue reflejando irregularidades de medición o interrupciones que conviene revisar antes de la predicción final. La serie log-transformada presenta una varianza más controlada, conserva la estructura temporal esencial y mitiga la influencia de outliers. 5.2.11 Ajuste del modelo ARIMA en escala logarítmica # ============================================================ # Ajuste automático ARIMA sobre serie log-transformada # ============================================================ tm(&quot;Ajuste SARIMA TS log-transformada&quot;, { m_log &lt;&lt;- auto.arima(ts_log, seasonal = TRUE, stepwise = FALSE, approximation = arima_approx, trace = TRUE) summary(m_log) }) ## ## Fitting models using approximations to speed things up... ## ## ARIMA(0,1,0) : -24007.62 ## ARIMA(0,1,0) with drift : -24005.63 ## ARIMA(0,1,0)(0,0,1)[24] : -24049.82 ## ARIMA(0,1,0)(0,0,1)[24] with drift : -24047.82 ## ARIMA(0,1,0)(0,0,2)[24] : -24115.74 ## ARIMA(0,1,0)(0,0,2)[24] with drift : -24113.74 ## ARIMA(0,1,0)(1,0,0)[24] : -24027.94 ## ARIMA(0,1,0)(1,0,0)[24] with drift : -24025.95 ## ARIMA(0,1,0)(1,0,1)[24] : Inf ## ARIMA(0,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(1,0,2)[24] : Inf ## ARIMA(0,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,0)[24] : -24068.68 ## ARIMA(0,1,0)(2,0,0)[24] with drift : -24066.69 ## ARIMA(0,1,0)(2,0,1)[24] : Inf ## ARIMA(0,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,2)[24] : Inf ## ARIMA(0,1,0)(2,0,2)[24] with drift : Inf ## ARIMA(0,1,1) : -24077 ## ARIMA(0,1,1) with drift : -24075.01 ## ARIMA(0,1,1)(0,0,1)[24] : -24120.59 ## ARIMA(0,1,1)(0,0,1)[24] with drift : -24118.6 ## ARIMA(0,1,1)(0,0,2)[24] : -24185.2 ## ARIMA(0,1,1)(0,0,2)[24] with drift : -24183.21 ## ARIMA(0,1,1)(1,0,0)[24] : -24098.76 ## ARIMA(0,1,1)(1,0,0)[24] with drift : -24096.77 ## ARIMA(0,1,1)(1,0,1)[24] : Inf ## ARIMA(0,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(1,0,2)[24] : Inf ## ARIMA(0,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,0)[24] : -24138.11 ## ARIMA(0,1,1)(2,0,0)[24] with drift : -24136.12 ## ARIMA(0,1,1)(2,0,1)[24] : Inf ## ARIMA(0,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,2)[24] : Inf ## ARIMA(0,1,1)(2,0,2)[24] with drift : Inf ## ARIMA(0,1,2) : -24111 ## ARIMA(0,1,2) with drift : -24109 ## ARIMA(0,1,2)(0,0,1)[24] : -24157.22 ## ARIMA(0,1,2)(0,0,1)[24] with drift : -24155.23 ## ARIMA(0,1,2)(0,0,2)[24] : -24225.37 ## ARIMA(0,1,2)(0,0,2)[24] with drift : -24223.37 ## ARIMA(0,1,2)(1,0,0)[24] : -24135.58 ## ARIMA(0,1,2)(1,0,0)[24] with drift : -24133.59 ## ARIMA(0,1,2)(1,0,1)[24] : Inf ## ARIMA(0,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,2)(1,0,2)[24] : Inf ## ARIMA(0,1,2)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,2)(2,0,0)[24] : -24178.38 ## ARIMA(0,1,2)(2,0,0)[24] with drift : -24176.39 ## ARIMA(0,1,2)(2,0,1)[24] : Inf ## ARIMA(0,1,2)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,3) : -24243.98 ## ARIMA(0,1,3) with drift : -24241.99 ## ARIMA(0,1,3)(0,0,1)[24] : -24290.47 ## ARIMA(0,1,3)(0,0,1)[24] with drift : -24288.48 ## ARIMA(0,1,3)(0,0,2)[24] : -24358.36 ## ARIMA(0,1,3)(0,0,2)[24] with drift : -24356.37 ## ARIMA(0,1,3)(1,0,0)[24] : -24268.83 ## ARIMA(0,1,3)(1,0,0)[24] with drift : -24266.84 ## ARIMA(0,1,3)(1,0,1)[24] : Inf ## ARIMA(0,1,3)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,3)(2,0,0)[24] : -24311.37 ## ARIMA(0,1,3)(2,0,0)[24] with drift : -24309.38 ## ARIMA(0,1,4) : -24977.57 ## ARIMA(0,1,4) with drift : -24975.58 ## ARIMA(0,1,4)(0,0,1)[24] : -25041.9 ## ARIMA(0,1,4)(0,0,1)[24] with drift : -25039.92 ## ARIMA(0,1,4)(1,0,0)[24] : -25021.29 ## ARIMA(0,1,4)(1,0,0)[24] with drift : -25019.3 ## ARIMA(0,1,5) : -25118.13 ## ARIMA(0,1,5) with drift : -25116.14 ## ARIMA(1,1,0) : -24073.54 ## ARIMA(1,1,0) with drift : -24071.55 ## ARIMA(1,1,0)(0,0,1)[24] : -24117.01 ## ARIMA(1,1,0)(0,0,1)[24] with drift : -24115.01 ## ARIMA(1,1,0)(0,0,2)[24] : -24181.56 ## ARIMA(1,1,0)(0,0,2)[24] with drift : -24179.57 ## ARIMA(1,1,0)(1,0,0)[24] : -24095.17 ## ARIMA(1,1,0)(1,0,0)[24] with drift : -24093.18 ## ARIMA(1,1,0)(1,0,1)[24] : Inf ## ARIMA(1,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(1,0,2)[24] : Inf ## ARIMA(1,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,0)[24] : -24134.47 ## ARIMA(1,1,0)(2,0,0)[24] with drift : -24132.48 ## ARIMA(1,1,0)(2,0,1)[24] : Inf ## ARIMA(1,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,2)[24] : Inf ## ARIMA(1,1,0)(2,0,2)[24] with drift : Inf ## ARIMA(1,1,1) : -24087.78 ## ARIMA(1,1,1) with drift : -24338.51 ## ARIMA(1,1,1)(0,0,1)[24] : -24131.77 ## ARIMA(1,1,1)(0,0,1)[24] with drift : -24369.11 ## ARIMA(1,1,1)(0,0,2)[24] : -24441.8 ## ARIMA(1,1,1)(0,0,2)[24] with drift : -24439.81 ## ARIMA(1,1,1)(1,0,0)[24] : -24348.78 ## ARIMA(1,1,1)(1,0,0)[24] with drift : -24107.14 ## ARIMA(1,1,1)(1,0,1)[24] : Inf ## ARIMA(1,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,1)(1,0,2)[24] : Inf ## ARIMA(1,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,1)(2,0,0)[24] : -24395.2 ## ARIMA(1,1,1)(2,0,0)[24] with drift : -24393.21 ## ARIMA(1,1,1)(2,0,1)[24] : Inf ## ARIMA(1,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,2) : -27833.16 ## ARIMA(1,1,2) with drift : -27831.51 ## ARIMA(1,1,2)(0,0,1)[24] : -27855.34 ## ARIMA(1,1,2)(0,0,1)[24] with drift : -27853.67 ## ARIMA(1,1,2)(0,0,2)[24] : -27931.72 ## ARIMA(1,1,2)(0,0,2)[24] with drift : -27930.08 ## ARIMA(1,1,2)(1,0,0)[24] : -27832.62 ## ARIMA(1,1,2)(1,0,0)[24] with drift : -27830.95 ## ARIMA(1,1,2)(1,0,1)[24] : Inf ## ARIMA(1,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,2)(2,0,0)[24] : -27885.64 ## ARIMA(1,1,2)(2,0,0)[24] with drift : -27883.99 ## ARIMA(1,1,3) : -27930.89 ## ARIMA(1,1,3) with drift : -27929.2 ## ARIMA(1,1,3)(0,0,1)[24] : -27951.36 ## ARIMA(1,1,3)(0,0,1)[24] with drift : -27950.19 ## ARIMA(1,1,3)(1,0,0)[24] : -27929.02 ## ARIMA(1,1,3)(1,0,0)[24] with drift : -27927.34 ## ARIMA(1,1,4) : -27971.44 ## ARIMA(1,1,4) with drift : -27969.72 ## ARIMA(2,1,0) : -24110.19 ## ARIMA(2,1,0) with drift : -24108.2 ## ARIMA(2,1,0)(0,0,1)[24] : -24156.26 ## ARIMA(2,1,0)(0,0,1)[24] with drift : -24154.27 ## ARIMA(2,1,0)(0,0,2)[24] : -24224.06 ## ARIMA(2,1,0)(0,0,2)[24] with drift : -24222.07 ## ARIMA(2,1,0)(1,0,0)[24] : -24134.6 ## ARIMA(2,1,0)(1,0,0)[24] with drift : -24132.61 ## ARIMA(2,1,0)(1,0,1)[24] : Inf ## ARIMA(2,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,0)(1,0,2)[24] : Inf ## ARIMA(2,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(2,1,0)(2,0,0)[24] : -24177.06 ## ARIMA(2,1,0)(2,0,0)[24] with drift : -24175.07 ## ARIMA(2,1,0)(2,0,1)[24] : Inf ## ARIMA(2,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(2,1,1) : -27860.19 ## ARIMA(2,1,1) with drift : -27858.51 ## ARIMA(2,1,1)(0,0,1)[24] : -27882.52 ## ARIMA(2,1,1)(0,0,1)[24] with drift : -27880.84 ## ARIMA(2,1,1)(0,0,2)[24] : -27957.02 ## ARIMA(2,1,1)(0,0,2)[24] with drift : -27955.35 ## ARIMA(2,1,1)(1,0,0)[24] : -27859.79 ## ARIMA(2,1,1)(1,0,0)[24] with drift : -27858.11 ## ARIMA(2,1,1)(1,0,1)[24] : Inf ## ARIMA(2,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,1)(2,0,0)[24] : -27910.86 ## ARIMA(2,1,1)(2,0,0)[24] with drift : -27909.2 ## ARIMA(2,1,2) : Inf ## ARIMA(2,1,2) with drift : Inf ## ARIMA(2,1,2)(0,0,1)[24] : -27959.77 ## ARIMA(2,1,2)(0,0,1)[24] with drift : -27957.64 ## ARIMA(2,1,2)(1,0,0)[24] : -27936.99 ## ARIMA(2,1,2)(1,0,0)[24] with drift : -27932.55 ## ARIMA(2,1,3) : -27941.17 ## ARIMA(2,1,3) with drift : -27942.36 ## ARIMA(3,1,0) : -24237.58 ## ARIMA(3,1,0) with drift : -24235.58 ## ARIMA(3,1,0)(0,0,1)[24] : -24283.51 ## ARIMA(3,1,0)(0,0,1)[24] with drift : -24281.52 ## ARIMA(3,1,0)(0,0,2)[24] : -24350.28 ## ARIMA(3,1,0)(0,0,2)[24] with drift : -24348.29 ## ARIMA(3,1,0)(1,0,0)[24] : -24261.83 ## ARIMA(3,1,0)(1,0,0)[24] with drift : -24259.84 ## ARIMA(3,1,0)(1,0,1)[24] : Inf ## ARIMA(3,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(3,1,0)(2,0,0)[24] : -24303.26 ## ARIMA(3,1,0)(2,0,0)[24] with drift : -24301.27 ## ARIMA(3,1,1) : -27938.18 ## ARIMA(3,1,1) with drift : -27936.48 ## ARIMA(3,1,1)(0,0,1)[24] : -27959.55 ## ARIMA(3,1,1)(0,0,1)[24] with drift : -27957.84 ## ARIMA(3,1,1)(1,0,0)[24] : -27936.7 ## ARIMA(3,1,1)(1,0,0)[24] with drift : -27934.99 ## ARIMA(3,1,2) : -27940.85 ## ARIMA(3,1,2) with drift : -27936.15 ## ARIMA(4,1,0) : -24785.01 ## ARIMA(4,1,0) with drift : -24783.02 ## ARIMA(4,1,0)(0,0,1)[24] : -24842.02 ## ARIMA(4,1,0)(0,0,1)[24] with drift : -24840.03 ## ARIMA(4,1,0)(1,0,0)[24] : -24820.95 ## ARIMA(4,1,0)(1,0,0)[24] with drift : -24818.96 ## ARIMA(4,1,1) : -27951.79 ## ARIMA(4,1,1) with drift : -27950.08 ## ARIMA(5,1,0) : -24836.46 ## ARIMA(5,1,0) with drift : -24834.47 ## ## Now re-fitting the best model(s) without approximations... ## ## ## ## ## Best model: ARIMA(1,1,4) 5.2.12 Verificación de supuestos del nuevo modelo ARIMA en escala logarítmica # ============================================================ # Diagnóstico de los residuos del modelo ARIMA (log) # ============================================================ checkresiduals(m_log) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,4) ## Q* = 647.2, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test El p-valor &lt; 0.05, se rechaza la hipótesis nula (los residuos no son completamente ruido blanco). Esto sugiere que el modelo no captura toda la dinámica temporal, aún quedan patrones correlacionados sin explicar. Diagnósticos residuales del modelo ARIMA En el gráfico de residuales los residuos oscilan alrededor de cero, lo que es esperable para un modelo bien ajustado. Sin embargo, se observan picos frecuentes (positivos y negativos) que indican fluctuaciones abruptas en la varianza o la presencia de valores atípicos. Hay periodos donde la variabilidad de los residuos aumenta, lo que sugiere heterocedasticidad (la varianza no es constante en el tiempo). El modelo logra eliminar la tendencia, pero no estabiliza completamente la varianza; aún hay ruido estructurado. En el gráfico de ACF de los residuos la mayoría de los rezagos se mantienen dentro de las bandas azules de confianza, lo cual indica autocorrelación residual débil o casi nula. Sin embargo, algunos picos (alrededor de los rezagos 24 y 48) exceden ligeramente las bandas, lo que sugiere que todavía puede haber estructura estacional residual leve o dependencias menores no capturadas. El modelo ARIMA(1,1,4) mejora la independencia de los residuos respecto a modelos anteriores, pero no elimina completamente la autocorrelación. En el gráfico de densidad de residuos la forma general es centrada en cero. Sin embargo, se observan colas delgadas pero extendidas, lo que sugiere no normalidad. El pico muy concentrado en torno a 0 confirma que los errores pequeños son frecuentes, pero los grandes (positivos o negativos) aún aparecen ocasionalmente. En general, se cumple parcialmente la normalidad, aunque la serie sigue afectada por outliers o por una distribución más leptocúrtica que la normal. El modelo ARIMA(1,1,4) representa una mejora respecto a versiones más simples (captura parcialmente la dinámica temporal), pero aún no cumple plenamente los supuestos de ruido blanco y homocedasticidad. 5.2.13 Pronóstico con el modelo mejorado (escala logarítmica) # ============================================================ # Pronóstico en escala logarítmica # ============================================================ h &lt;- 24 * horizon_days # pronóstico a 7 días (horas) fc_log &lt;- forecast(m_log, h = h) autoplot(fc_log) + labs(title = paste0(&quot;Pronóstico log-transformado con ARIMA (&quot;, horizon_days, &quot; días)&quot;), y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal(base_size = 12) Se observa que la mayor parte de la serie se mantiene entre valores logarítmicos de 6 a 7, pero hay muchas caídas bruscas hacia valores bajos (0–2). Esos saltos representan puntos donde la potencia real cayó casi a cero, y al aplicar la transformación logarítmica, visualmente se reducen las diferencias. La serie sigue mostrando alta variabilidad y picos anómalos, aunque en menor medida que en la escala original. Esto sugiere que la varianza aún no está completamente estabilizada o que hay eventos atípicos muy fuertes. 5.2.13.1 Reconversión a escala original (exponencial inversa) # ============================================================ # Transformar el pronóstico a escala original # ============================================================ fc_exp &lt;- expm1(fc_log$mean) # inversa de log1p fc_exp80 &lt;- expm1(fc_log$lower[,&quot;80%&quot;]) fc_exp95 &lt;- expm1(fc_log$upper[,&quot;95%&quot;]) # Crear data frame para visualización f_times &lt;- seq(from = max(df_impu[[time_col]]) + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) fc_plot &lt;- tibble( time = f_times, mean = fc_exp, lo80 = fc_exp80, hi80 = fc_exp95 ) # Graficar pronóstico en escala original ggplot(fc_plot, aes(x = time, y = mean)) + geom_ribbon(aes(ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25) + geom_line(color = &quot;#1f77b4&quot;, linewidth = 1.1) + labs(title = &quot;Pronóstico ARIMA (log-transformado, 7 días)&quot;, subtitle = &quot;Transformación log(1 + x) revertida a escala original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia estimada&quot;) + theme_minimal(base_size = 12) La línea azul muestra el pronóstico esperado: prácticamente plano y ligeramente creciente. Las bandas de confianza son amplias, lo cual significa alta incertidumbre en las predicciones. El modelo ARIMA no logra capturar del todo la estacionalidad o los cambios estructurales. Existen valores extremos en la serie original. En este caso, el modelo está promediando el comportamiento reciente, sin detectar tendencia fuerte ni patrón estacional marcado, por eso proyecta una línea casi recta. La transformación logarítmica ayudó a suavizar la serie, pero aún hay alta volatilidad. El modelo ARIMA produce pronósticos conservadores (casi planos) cuando no detecta tendencia o ciclo claro. Las bandas amplias muestran que el modelo no confía demasiado en su predicción a 7 días, posiblemente por residuos no estacionarios o valores atípicos persistentes. 5.3 Preprocesamiento de la serie de datos para Holt–Winters Para la aplicación de Holt–Winter se imputa faltantes, detecta/sustituye outliers y estabiliza la varianza (Box–Cox con inversa guardada) # ============================================================ # Preprocesamiento para Holt–Winters: # - Regulariza a malla horaria (si no existe) # - Imputa NAs # - Detecta y sustituye outliers # - Estabiliza varianza con Box–Cox (guarda lambda e inversa) # Expone: ts_hw_full (limpia, positiva), y_hw_bc, lambda_hw, inv_boxcox() # ============================================================ # 0) Cronometría t0 &lt;- Sys.time() # 1) Asegurar malla horaria y ordenar stopifnot(exists(&quot;df_full&quot;), exists(&quot;time_col&quot;), exists(&quot;y_col&quot;)) df_hw &lt;- df_full %&gt;% dplyr::arrange(.data[[time_col]]) %&gt;% dplyr::select(!!time_col, !!y_col) # 2) Asegurar positividad mínima (HW multiplicativo exige &gt; 0) # Si hay valores &lt;= 0, desplazamos toda la serie por un epsilon. y_raw &lt;- suppressWarnings(as.numeric(df_hw[[y_col]])) eps &lt;- 1e-6 shift &lt;- ifelse(is.finite(min(y_raw, na.rm = TRUE)) &amp;&amp; min(y_raw, na.rm = TRUE) &lt;= 0, abs(min(y_raw, na.rm = TRUE)) + eps, 0) y_pos &lt;- y_raw + shift # 3) Construir ts horaria (freq = 24) con el rango completo t_min &lt;- min(df_hw[[time_col]], na.rm = TRUE) t_max &lt;- max(df_hw[[time_col]], na.rm = TRUE) n_obs &lt;- length(y_pos) ts_hw &lt;- stats::ts(y_pos, frequency = 24) # asume datos ya a paso horario # 4) Conteo de NAs antes n_na_before &lt;- sum(is.na(y_pos)) # 5) Limpieza integrada: imputación + sustitución de outliers # tsclean usa STL internamente para suavizar y reemplazar ts_clean &lt;- forecast::tsclean(ts_hw, replace.missing = TRUE) ts_clean[ts_clean &lt; 10] &lt;- median(ts_clean, na.rm = TRUE) #############!!!!!!!! # 6) Detección explícita de outliers (solo para reporte) to_hw &lt;- try(forecast::tsoutliers(ts_hw), silent = TRUE) n_out &lt;- if (inherits(to_hw, &quot;try-error&quot;)) NA_integer_ else length(to_hw$index) # 7) Serie definitiva para HW (positiva, sin NA/outliers) ts_hw_full &lt;- ts_clean # 8) Estabilización de varianza (Box–Cox de Guerrero recomendado para estacionalidad) # Requiere positividad: ya garantizada por y_pos + tsclean lambda_hw &lt;- forecast::BoxCox.lambda(ts_hw_full, method = &quot;guerrero&quot;) y_hw_bc &lt;- forecast::BoxCox(ts_hw_full, lambda_hw) # Inversa de Box–Cox inv_boxcox &lt;- function(z, lambda) { if (isTRUE(all.equal(lambda, 0))) exp(z) else (lambda * z + 1)^(1/lambda) } # 9) Resumen y diagnóstico n_na_after &lt;- sum(is.na(as.numeric(ts_hw_full))) cat(&quot;Preprocesamiento HW — resumen\\n&quot;, &quot;- Observaciones: &quot;, length(ts_hw_full), &quot;\\n&quot;, &quot;- NAs antes: &quot;, n_na_before, &quot;\\n&quot;, &quot;- NAs después: &quot;, n_na_after, &quot;\\n&quot;, &quot;- Outliers (det.):&quot;, ifelse(is.na(n_out), &quot;no evaluado&quot;, n_out), &quot;\\n&quot;, &quot;- Shift aplicado: &quot;, signif(shift, 6), &quot; (para asegurar positividad)\\n&quot;, &quot;- Box–Cox lambda: &quot;, round(lambda_hw, 4), &quot;\\n&quot;, sep = &quot;&quot;) ## Preprocesamiento HW — resumen ## - Observaciones: 118653 ## - NAs antes: 620 ## - NAs después: 0 ## - Outliers (det.):2485 ## - Shift aplicado: 1e-06 (para asegurar positividad) ## - Box–Cox lambda: 0.9455 # 10) Gráfico diagnóstico: Original vs Limpia (+ Box–Cox en panel) df_diag_wide &lt;- tibble::tibble( time = as.POSIXct(df_hw[[time_col]], tz = TZ)[seq_along(ts_hw_full)], Original = y_pos[seq_along(ts_hw_full)], BoxCox = as.numeric(y_hw_bc), Limpia = as.numeric(ts_hw_full) ) ggplot2::ggplot(mapping = ggplot2::aes(x = time)) + # Fondo: serie original (gris, delgada y transparente) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = Original, color = &quot;Original&quot;), linewidth = 0.35, alpha = 0.45, na.rm = TRUE) + # Medio: Box-Cox (naranja, grosor medio) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = BoxCox, color = &quot;BoxCox&quot;), linewidth = 0.6, alpha = 0.85, na.rm = TRUE) + # Frente: serie limpia (azul, más gruesa) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = Limpia, color = &quot;Limpia&quot;), linewidth = 0.9, alpha = 0.95, na.rm = TRUE) + ggplot2::scale_color_manual( name = &quot;Serie&quot;, breaks = c(&quot;Original&quot;,&quot;BoxCox&quot;,&quot;Limpia&quot;), labels = c(&quot;Original (fondo)&quot;,&quot;Box–Cox&quot;,&quot;Limpia (frente)&quot;), values = c(Original = &quot;#9CA3AF&quot;, BoxCox = &quot;#ff7f0e&quot;, Limpia = &quot;#1f77b4&quot;) ) + ggplot2::labs( title = &quot;Preprocesamiento para Holt–Winters&quot;, subtitle = &quot;Fondo: Original | Medio: Box–Cox | Frente: Serie limpia (imputación + outliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme( plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank() ) # 11) Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Preprocesamiento&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } La serie fue limpiada, ya no tiene huecos ni valores extremos, y su escala fue estabilizada para un modelado robusto con Holt–Winters. En la gráfica el Gris claro corresponde a la Serie original con ruido, picos y alta dispersión. el Naranja corresponde la serie transformada con varianza más homogénea, suavizando los extremos. y la curva Azul es la serie final tras imputación y reemplazo de outliers; muestra comportamiento más regular y continuo. Los picos de potencia extrema (&gt;3000) fueron suavizados; la serie azul es más compacta y uniforme. Se mantienen los ciclos anuales y semanales, lo que garantiza que no se perdió información relevante. El Box–Cox (naranja) actúa como paso intermedio: reduce la amplitud sin eliminar fluctuaciones naturales. La serie limpia (azul) se ajusta mejor a los supuestos del modelo HW, evitando el sesgo causado por valores extremos o huecos. 5.4 División de los datos entre TRAIN/TEST # ============================================================ # Split TRAIN/TEST para Holt–Winters y ARIMA # Usa: ts_hw_full (serie limpia/positiva) y y_hw_bc (Box–Cox) # Expone: h, n_test, y_train, y_test, y_train_bc, y_test_bc, # time_train, time_test (para gráficas y métricas) # ============================================================ # Cronometría t0 &lt;- Sys.time() # 0) Utilidades `%||%` &lt;- function(a, b) if (!is.null(a)) a else b # 1) Horizonte en horas (24 * días) h &lt;- 24 * (horizon_days %||% 7) # 2) Longitudes y validaciones stopifnot(exists(&quot;ts_hw_full&quot;)) n &lt;- length(ts_hw_full) # Si el horizonte es mayor que la serie, lo acotamos y avisamos if (h &gt;= n) { message(sprintf(&quot;Horizonte (%d) &gt;= longitud de la serie (%d). Se ajusta a h = %d.&quot;, h, n, max(1L, floor(n/5)))) h &lt;- max(1L, floor(n/5)) } # 3) Definimos tamaño de TEST como el horizonte (común para evaluación) n_test &lt;- h n_train &lt;- n - n_test stopifnot(n_train &gt;= 24 * 7) # al menos ~1 semana para estimar estacionalidad # 4) Particiones en escala original (limpia, positiva) y_train &lt;- stats::ts(ts_hw_full[1:n_train], frequency = 24) y_test &lt;- stats::ts(ts_hw_full[(n_train+1):n], frequency = 24) # 5) Particiones en escala Box–Cox (para modelos aditivos en varianza estable) stopifnot(exists(&quot;y_hw_bc&quot;)) y_train_bc &lt;- stats::ts(y_hw_bc[1:n_train], frequency = 24) y_test_bc &lt;- stats::ts(y_hw_bc[(n_train+1):n], frequency = 24) # 6) Vectores de tiempo (útil para gráficas de comparación) stopifnot(exists(&quot;df_full&quot;), exists(&quot;time_col&quot;)) time_all &lt;- as.POSIXct(df_full[[time_col]]) time_train &lt;- time_all[1:n_train] time_test &lt;- time_all[(n_train+1):n] # 7) Métricas (si no existen) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } # 8) Resumen y chequeo visual rápido cat(&quot;Split TRAIN/TEST\\n&quot;, &quot;- Observaciones totales: &quot;, n, &quot;\\n&quot;, &quot;- TRAIN: &quot;, n_train, &quot; (&quot;, round(100*n_train/n,1),&quot;%)\\n&quot;, &quot;- TEST: &quot;, n_test, &quot; (&quot;, round(100*n_test/n,1),&quot;%)\\n&quot;, &quot;- Horizonte h (horas): &quot;, h, &quot;\\n&quot;, &quot;- Freq ts: &quot;, frequency(y_train), &quot;\\n&quot;, sep = &quot;&quot;) ## Split TRAIN/TEST ## - Observaciones totales: 118653 ## - TRAIN: 118485 (99.9%) ## - TEST: 168 (0.1%) ## - Horizonte h (horas): 168 ## - Freq ts: 24 # Gráfico base para verificar el split df_split &lt;- dplyr::bind_rows( tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;), tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) ) ggplot2::ggplot(df_split, ggplot2::aes(time, y, color = conj)) + ggplot2::geom_line(linewidth = 0.5, alpha = 0.9) + ggplot2::scale_color_manual(values = c(TRAIN = &quot;#1f77b4&quot;, TEST = &quot;#d62728&quot;)) + ggplot2::labs(title = &quot;Split de la serie: TRAIN vs TEST&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Conjunto&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank()) # 9) Cronometría (si la usas) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Split TRAIN/TEST&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), # trivial aquí status = &quot;OK&quot;, message = &quot;&quot; ) } Se dividio la serie de tiempo en dos partes, TRAIN (azul): casi toda la serie, usada para ajustar el modelo y TEST (rojo): los últimos 7 días, usados para evaluar la capacidad predictiva (este tramo es muy corto respecto al conjunto total, lo cual indica que el modelo se entrenará con casi toda la información disponible y se evaluará únicamente en una ventana reciente de 7 días). La serie muestra una alta variabilidad en la potencia a lo largo del tiempo, con fluctuaciones intensas dentro de cada año (posible patrón diario/semanal) e incremento gradual de los valores máximos a partir de 2020 (~tendencia leve al alza). Se observa ruido considerable y presencia de picos y caídas abruptas, lo que sugiere procesos operativos irregulares o mediciones con eventos extremos. 5.5 Ajuste Holt–Winters aditivo y multiplicativo (usando TRAIN y h definidos) # ========================================= # Holt–Winters: ajustes aditivo y multiplicativo (consistentes con 0 y 1) # Usa: y_train (escala original positiva), h # Deja: fc_hw_add, fc_hw_mul (objetos &#39;forecast&#39;) # ========================================= # Cronometría t0 &lt;- Sys.time() # Carga autoplot para objetos &#39;forecast&#39; if (!&quot;ggfortify&quot; %in% .packages()) suppressPackageStartupMessages(library(ggfortify)) # --- Aditivo (siempre válido en escala original) --- fc_hw_add &lt;- forecast::hw(y_train, seasonal = &quot;additive&quot;, h = h) # --- Multiplicativo (requiere todos &gt; 0) --- if (all(as.numeric(y_train) &gt; 0, na.rm = TRUE)) { fc_hw_mul &lt;- forecast::hw(y_train, seasonal = &quot;multiplicative&quot;, h = h) } else { message(&quot;HW multiplicativo omitido: la serie TRAIN contiene ceros o valores ≤ 0.&quot;) fc_hw_mul &lt;- NULL } # # Vista rápida # autoplot(fc_hw_add) + # labs(title = &quot;Pronóstico Holt–Winters (Aditivo)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal(base_size = 12) # # if (!is.null(fc_hw_mul)) { # autoplot(fc_hw_mul) + # labs(title = &quot;Pronóstico Holt–Winters (Multiplicativo)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal(base_size = 12) # } # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Aditivo y multiplicativo&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } 5.6 Gráfica comparativa: TRAIN/TEST + pronósticos HW (aditivo vs. multiplicativo) # ========================================= # Gráfica comparativa con eje temporal real # Usa: time_train, time_test, y_train, y_test, h, fc_hw_add, fc_hw_mul, TZ # ========================================= stopifnot(exists(&quot;time_train&quot;), exists(&quot;time_test&quot;)) stopifnot(exists(&quot;TZ&quot;)) # DATAFRAME histórico df_train &lt;- tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;) df_test &lt;- tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) # Instantes de pronóstico a partir del final de TRAIN t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) # Pasar objetos forecast a data frame (si existen) as_fc_df &lt;- function(fc, nombre) { if (is.null(fc)) return(NULL) tibble::tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[, &quot;80%&quot;]), hi80 = as.numeric(fc$upper[, &quot;80%&quot;]), lo95 = as.numeric(fc$lower[, &quot;95%&quot;]), hi95 = as.numeric(fc$upper[, &quot;95%&quot;]), modelo = nombre ) } df_add &lt;- as_fc_df(fc_hw_add, &quot;HW Aditivo&quot;) df_mul &lt;- as_fc_df(fc_hw_mul, &quot;HW Multiplicativo&quot;) df_fc &lt;- dplyr::bind_rows(df_add, df_mul) # # Plot # ggplot2::ggplot() + # ggplot2::geom_line(data = df_train, ggplot2::aes(time, y), color = &quot;grey65&quot;, linewidth = 0.45) + # ggplot2::geom_line(data = df_test, ggplot2::aes(time, y), color = &quot;black&quot;, linewidth = 0.6) + # ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95, fill = modelo), # alpha = 0.12, show.legend = FALSE) + # ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80, fill = modelo), # alpha = 0.22, show.legend = FALSE) + # ggplot2::geom_line(data = df_fc, ggplot2::aes(x = time, y = mean, color = modelo), linewidth = 1.0) + # ggplot2::scale_color_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + # ggplot2::scale_fill_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + # ggplot2::labs(title = &quot;Pronóstico Holt–Winters — comparación&quot;, # subtitle = &quot;Gris: TRAIN | Negro: TEST | Colores: pronóstico&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Modelo&quot;) + # ggplot2::theme_minimal(base_size = 12) + # ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), # panel.grid.minor = ggplot2::element_blank()) stopifnot(exists(&quot;time_train&quot;), exists(&quot;y_train&quot;), exists(&quot;h&quot;), exists(&quot;TZ&quot;)) # ========================================= # ZOOM: últimos 21 días + predicción HW # Requiere: time_train, y_train, h, fc_hw_add / fc_hw_mul, TZ # ========================================= # 1) Instantes clave t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) # 2) Histórico (solo últimos 21 días de TRAIN) history_days &lt;- 21 t_zoom_ini &lt;- t_train_end - lubridate::days(history_days) df_hist &lt;- tibble::tibble( time = time_train, y = as.numeric(y_train) ) %&gt;% dplyr::filter(time &gt;= t_zoom_ini) # 3) Utilidad para llevar objetos forecast a data frame as_fc_df &lt;- function(fc, nombre) { if (is.null(fc)) return(NULL) tibble::tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[, &quot;80%&quot;]), hi80 = as.numeric(fc$upper[, &quot;80%&quot;]), lo95 = as.numeric(fc$lower[, &quot;95%&quot;]), hi95 = as.numeric(fc$upper[, &quot;95%&quot;]), modelo = nombre ) } df_add &lt;- as_fc_df(if (exists(&quot;fc_hw_add&quot;)) fc_hw_add else NULL, &quot;HW Aditivo&quot;) df_mul &lt;- as_fc_df(if (exists(&quot;fc_hw_mul&quot;)) fc_hw_mul else NULL, &quot;HW Multiplicativo&quot;) df_fc &lt;- dplyr::bind_rows(df_add, df_mul) # 4) Límite superior del eje X hasta el fin de la predicción t_fin &lt;- max(f_times, na.rm = TRUE) # 5) Gráfico: historia (21d) + pronóstico ggplot2::ggplot() + # Historia (fondo) ggplot2::geom_line(data = df_hist, ggplot2::aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.5, alpha = 0.9, na.rm = TRUE) + # Bandas 95% y 80% ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95, fill = modelo), alpha = 0.12, show.legend = FALSE, na.rm = TRUE) + ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80, fill = modelo), alpha = 0.22, show.legend = FALSE, na.rm = TRUE) + # Media pronosticada ggplot2::geom_line(data = df_fc, ggplot2::aes(x = time, y = mean, color = modelo), linewidth = 1.0, na.rm = TRUE) + # Escalas y estilo ggplot2::scale_color_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + ggplot2::scale_x_datetime(limits = c(t_zoom_ini, t_fin), date_breaks = &quot;3 days&quot;, date_labels = &quot;%d-%b&quot;) + ggplot2::guides(x = ggplot2::guide_axis(n.dodge = 2)) + ggplot2::labs( title = &quot;Últimos 21 días + predicción Holt–Winters&quot;, subtitle = &quot;Historia (gris) y media pronosticada con bandas de confianza (80% y 95%)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Modelo&quot; ) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme( plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank(), axis.text.x = ggplot2::element_text(angle = 35, hjust = 1) ) En la gráfica el Color gris representa los valores reales de la serie (últimos 21 días antes del pronóstico). Las líneas de color (azul y rojo): media del pronóstico para cada modelo (Azul: Holt–Winters aditivo / Rojo: Holt–Winters multiplicativo). Y las sombras corresponden a las bandas de confianza del 80% (más oscuras) y 95% (más claras), que indican la incertidumbre del pronóstico. Se observan oscilaciones regulares y cíclicas con picos diarios, lo cual indica una fuerte estacionalidad intradía (24h). La amplitud de los ciclos es relativamente estable, sin tendencia ascendente ni descendente marcada, confirmando que la serie es altamente estacional y estacionaria en media. Ambos modelos (aditivo y multiplicativo) mantienen el patrón periódico observado en los datos reales, lo que demuestra una buena captura de la estacionalidad. Las predicciones oscilan con amplitudes muy similares a las observadas, tanto el modelo multiplicativo (rojo) como el modelo aditivo (azul) mantienen una amplitud constante en el periodo predicción, sin embargo, el modelo aditivo tiene una mayor amplitud con respecto al modelo multiplicativo. Las bandas del 80% y 95% crecen gradualmente hacia el futuro, reflejando el aumento de la incertidumbre a medida que se pronostica más lejos. La superposición de las zonas azul y roja indica que ambos modelos ofrecen pronósticos muy próximos, lo cual sugiere que la serie no tiene una varianza fuertemente dependiente del nivel. El modelo Holt–Winters reproduce con éxito el comportamiento estacional de la serie en sus últimas semanas. Ambas versiones (aditiva y multiplicativa) generan pronósticos coherentes, capturando el patrón de ciclos diarios sin desviaciones abruptas. 5.7 Evaluación en TEST (MAPE y RMSE) # ========================================= # Evaluación (MAPE y RMSE) sobre TEST # Usa: y_test, h, fc_hw_add, fc_hw_mul, rmse(), mape() # ========================================= stopifnot(exists(&quot;y_test&quot;), exists(&quot;h&quot;)) # Longitud efectiva para comparar k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] pred_add &lt;- if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k) pred_mul &lt;- if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k) # Métricas auxiliares (por si no existen) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tab_hw &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;), RMSE = c(rmse(y_test_vec, pred_add), rmse(y_test_vec, pred_mul)), MAPE = c(mape(y_test_vec, pred_add), mape(y_test_vec, pred_mul)) ) knitr::kable(tab_hw, digits = 3, caption = &quot;Evaluación en TEST (MAPE y RMSE) — Holt–Winters&quot;) Table 5.1: Evaluación en TEST (MAPE y RMSE) — Holt–Winters Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 El modelo multiplicativo tiene un RMSE un 15.8% menor que el aditivo. Esto significa que, en promedio, las desviaciones entre los valores reales y pronosticados son menores en magnitud. El modelo aditivo aún predice bien, pero con mayor dispersión en torno a los valores reales. El Holt–Winters multiplicativo reduce los errores absolutos y genera pronósticos más estables. El MAPE de 31.1% para el modelo multiplicativo indica que, en promedio, las predicciones se desvían un 31% del valor real. En comparación, el modelo aditivo presenta 37.1%, es decir, un error relativo un poco mayor. Aunque ambos valores se ubican en el rango “moderadamente precisos”, el modelo multiplicativo es claramente superior. La diferencia entre ambos modelos refleja cómo cada versión maneja la relación entre nivel y variabilidad de la serie, en el modelo aditivo, la amplitud de las fluctuaciones es constante mientras que en el modelo multiplicativo, la amplitud crece o disminuye proporcionalmente al nivel de la serie. Dado que la serie de potencia muestra cierta variación en su amplitud (es decir, cuando la potencia aumenta, las oscilaciones también son mayores), el modelo multiplicativo se adapta mejor a esa estructura heterocedástica. El modelo Holt–Winters multiplicativo ofrece mejor precisión (MAPE 31.1%) y menor error absoluto (RMSE 394.6) que el aditivo. Esto confirma que la serie presenta fluctuaciones proporcionales a su nivel, y que el enfoque multiplicativo se ajusta mejor al comportamiento real de la potencia, proporcionando pronósticos más consistentes y confiables. 5.8 Comparación con un ARIMA simple # ========================================= # Comparación con ARIMA simple (auto.arima) # Usa: y_train, y_test, h, arima_approx, rmse(), mape() # ========================================= # Cronometría t0 &lt;- Sys.time() fit_arima_simple &lt;- forecast::auto.arima( y_train, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx ) fc_arima_simple &lt;- forecast::forecast(fit_arima_simple, h = h) # Comparar en TEST k &lt;- min(length(y_test), h) pred_arima &lt;- as.numeric(fc_arima_simple$mean)[seq_len(k)] y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] tab_cmp &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;, &quot;ARIMA simple&quot;), RMSE = c( rmse(y_test_vec, if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k)), rmse(y_test_vec, if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k)), rmse(y_test_vec, pred_arima) ), MAPE = c( mape(y_test_vec, if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k)), mape(y_test_vec, if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k)), mape(y_test_vec, pred_arima) ) ) knitr::kable(tab_cmp, digits = 3, caption = &quot;Comparación en TEST — Holt–Winters vs. ARIMA simple&quot;) Table 5.2: Comparación en TEST — Holt–Winters vs. ARIMA simple Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 ARIMA simple 325.303 27.377 # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - ARIMA simple&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } El modelo ARIMA simple logra el mejor desempeño predictivo, con un RMSE de 325.3 y un MAPE de 27.4%, superando significativamente a las versiones de Holt–Winters. Esto indica que la serie presenta autocorrelaciones y fluctuaciones no perfectamente estacionales, las cuales ARIMA logra capturar mejor. Los modelos Holt–Winters siguen siendo útiles como referencia y ofrecen pronósticos razonables, pero suponen una estructura estacional más rígida, lo que limita su precisión frente al ARIMA. El nivel de error obtenido (MAPE &lt; 30%) es aceptable y operativo, mostrando que los pronósticos pueden emplearse con confianza en planificación o simulación de demanda energética. 5.9 Holt Winter en Box–Cox (ajuste + pronóstico en BC + reconversión a escala original) # ============================================================ # Holt–Winters sobre la serie Box–Cox (aditivo en varianza estabilizada) # Requiere: y_train_bc (ts), y_test_bc (ts), lambda_hw, inv_boxcox(), h # Expone: fc_hw_bc (forecast en BC) y df_hw_bc (pronóstico reconvertido) # ============================================================ # Cronometría t0 &lt;- Sys.time() stopifnot(exists(&quot;y_train_bc&quot;), exists(&quot;lambda_hw&quot;), exists(&quot;inv_boxcox&quot;)) if (!&quot;ggfortify&quot; %in% .packages()) suppressPackageStartupMessages(library(ggfortify)) # Ajuste HW aditivo en la escala Box–Cox fc_hw_bc &lt;- forecast::hw(y_train_bc, seasonal = &quot;additive&quot;, h = h) # Reconversión a escala original (aprox. aplicando inversa a banda y media) # NOTA: transformar límites por separado no preserva exactamente la cobertura, # pero es la práctica usual para visualización/comparación. bc_to_orig &lt;- function(x) inv_boxcox(x, lambda_hw) # Tiempos para el pronóstico: siguen el final de TRAIN real t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) df_hw_bc &lt;- tibble::tibble( time = f_times, mean = bc_to_orig(as.numeric(fc_hw_bc$mean)), lo80 = bc_to_orig(as.numeric(fc_hw_bc$lower[, &quot;80%&quot;])), hi80 = bc_to_orig(as.numeric(fc_hw_bc$upper[, &quot;80%&quot;])), lo95 = bc_to_orig(as.numeric(fc_hw_bc$lower[, &quot;95%&quot;])), hi95 = bc_to_orig(as.numeric(fc_hw_bc$upper[, &quot;95%&quot;])) ) # # Vista rápida del forecast en BC # autoplot(fc_hw_bc) + # labs(title = &quot;Pronóstico Holt–Winters (Box–Cox, escala BC)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Valor (Box–Cox)&quot;) + # theme_minimal(base_size = 12) # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Box-CoX&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } 5.10 Gráfica comparativa (TRAIN/TEST en original) + HW Box–Cox reconvertido # ============================================================ # Overlay en escala original: # - TRAIN (gris) y TEST (negro) # - Pronóstico HW Box–Cox reconvertido (azul) # Requiere: time_train, time_test, y_train (original), y_test (original), df_hw_bc # ============================================================ stopifnot(exists(&quot;df_hw_bc&quot;)) df_train &lt;- tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;) df_test &lt;- tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) ggplot2::ggplot() + ggplot2::geom_line(data = df_train, ggplot2::aes(time, y), color = &quot;grey65&quot;, linewidth = 0.45) + ggplot2::geom_line(data = df_test, ggplot2::aes(time, y), color = &quot;black&quot;, linewidth = 0.60) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.12) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.22) + ggplot2::geom_line(data = df_hw_bc, ggplot2::aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0) + ggplot2::labs(title = &quot;Pronóstico Holt–Winters (Box–Cox → escala original)&quot;, subtitle = &quot;Gris: TRAIN | Negro: TEST | Azul: pronóstico reconvertido&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank()) 5.11 Zoom al pronóstico Holt Winter Box–Cox en original # ============================================================ # Zoom al pronóstico HW Box–Cox reconvertido (últimos N días) # Requiere: df_hw_bc, df_impu, time_col, TZ # ============================================================ history_days &lt;- 21 hist_df &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) t_ini &lt;- t_max - lubridate::days(history_days) t_fin &lt;- max(df_hw_bc$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot2::ggplot() + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + ggplot2::geom_line(data = df_hw_bc, ggplot2::aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + ggplot2::geom_line(data = hist_zoom, ggplot2::aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.45, na.rm = TRUE) + ggplot2::scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, date_labels = &quot;%d-%b&quot;) + ggplot2::labs(title = paste0(&quot;Holt–Winters Box–Cox (&quot;, ceiling(h/24), &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días + pronóstico reconvertido&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank(), axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) El modelo Holt–Winters Box–Cox conserva la estacionalidad y la estructura de la serie, generando predicciones coherentes con la dinámica histórica. La transformación Box–Cox mejora la estabilidad del modelo y evita explosiones de varianza en los pronósticos. En los últimos 21 días históricos, se observa un patrón cíclico altamente repetitivo, con picos y valles diarios. A partir del punto de pronóstico (el último dato del conjunto de entrenamiento), el modelo mantiene el mismo patrón estacional, reproduciendo los picos y valles con amplitud similar, lo que demuestra que el componente estacional fue correctamente capturado. Las bandas de confianza se expanden gradualmente conforme avanza el horizonte temporal, lo que refleja un aumento natural de la incertidumbre en predicciones futuras. El modelo no muestra sesgos significativos: el promedio del pronóstico (línea azul) sigue de cerca el comportamiento central de los datos reales. El modelo logra una predicción estable, con un patrón estacional diario bien ajustado y sin desviaciones sistemáticas. Las bandas de confianza muestran incertidumbre controlada y coherente con la naturaleza estocástica de la serie. 5.12 Métricas en TEST comparando en escala original (Holt Winter y Box–Cox) # ============================================================ # Evaluación en TEST (RMSE y MAPE) en escala ORIGINAL # Añade HW Box–Cox (reconvertido) a la tabla de comparación # Requiere: y_test, h, df_hw_bc y (si existen) fc_hw_add/fc_hw_mul/ARIMA # ============================================================ stopifnot(exists(&quot;y_test&quot;)) k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # Predicciones de los modelos existentes (si existen) get_preds &lt;- function(obj, k) { if (is.null(obj)) return(rep(NA_real_, k)) as.numeric(obj)[seq_len(k)] } pred_add &lt;- if (exists(&quot;fc_hw_add&quot;)) get_preds(fc_hw_add$mean, k) else rep(NA_real_, k) pred_mul &lt;- if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) get_preds(fc_hw_mul$mean, k) else rep(NA_real_, k) pred_arima &lt;- if (exists(&quot;fc_arima_simple&quot;)) get_preds(fc_arima_simple$mean, k) else rep(NA_real_, k) pred_hwbc &lt;- get_preds(df_hw_bc$mean, k) # Métricas (si no están) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tab_cmp_all &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;, &quot;ARIMA simple&quot;, &quot;HW Box–Cox (aditivo)&quot;), RMSE = c(rmse(y_test_vec, pred_add), rmse(y_test_vec, pred_mul), rmse(y_test_vec, pred_arima), rmse(y_test_vec, pred_hwbc)), MAPE = c(mape(y_test_vec, pred_add), mape(y_test_vec, pred_mul), mape(y_test_vec, pred_arima), mape(y_test_vec, pred_hwbc)) ) knitr::kable(tab_cmp_all, digits = 3, caption = &quot;Evaluación en TEST (escala original) — HW Aditivo, HW Multiplicativo, ARIMA simple y HW Box–Cox&quot;) Table 5.3: Evaluación en TEST (escala original) — HW Aditivo, HW Multiplicativo, ARIMA simple y HW Box–Cox Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 ARIMA simple 325.303 27.377 HW Box–Cox (aditivo) 465.434 36.858 El Holt–Winters con Box–Cox (aditivo) no mejora de manera sustancial. La transformación Box–Cox estabiliza la varianza y suaviza valores extremos, pero al reconvertir a la escala original, el beneficio se diluye. Por eso sus métricas son casi idénticas a las del modelo aditivo original, aunque genera pronósticos más estables y visualmente más suaves. Holt–Winters con Box–Cox proporciona una alternativa robusta cuando hay heterocedasticidad o valores extremos, aunque no mejora de forma drástica la precisión. 5.13 Resumen final de métricas (RMSE / MAPE) # ============================================================ # RESUMEN FINAL DE MÉTRICAS (RMSE / MAPE) EN ESCALA ORIGINAL # Detecta y consolida: SARIMA (fc), ARIMA simple, HW (add/mult), # HW Box–Cox (reconvertido), y ARIMA (log) si existe. # Requiere: y_test, h, rmse(), mape() # ============================================================ suppressPackageStartupMessages({ library(dplyr); library(tibble); library(ggplot2) }) # --- 1) Validaciones y utilidades --- stopifnot(exists(&quot;y_test&quot;), exists(&quot;h&quot;)) # función segura para extraer primeras k predicciones de un objeto &quot;mean&quot; forecast get_fc_mean &lt;- function(obj, k) { if (is.null(obj)) return(rep(NA_real_, k)) as.numeric(obj)[seq_len(k)] } # --- 2) Longitud de comparación y vector TEST (escala original) --- k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # --- 3) Recolección de predicciones por modelo (si existen) --- preds &lt;- list() # SARIMA (auto.arima original) -&gt; objeto &#39;fc&#39; if (exists(&quot;fc&quot;)) { preds[[&quot;SARIMA (auto.arima)&quot;]] &lt;- get_fc_mean(fc$mean, k) } # ARIMA simple (train/test mismo split) -&gt; objeto &#39;fc_arima_simple&#39; if (exists(&quot;fc_arima_simple&quot;)) { preds[[&quot;ARIMA simple&quot;]] &lt;- get_fc_mean(fc_arima_simple$mean, k) } # Holt–Winters Aditivo -&gt; objeto &#39;fc_hw_add&#39; if (exists(&quot;fc_hw_add&quot;)) { preds[[&quot;HW Aditivo&quot;]] &lt;- get_fc_mean(fc_hw_add$mean, k) } # Holt–Winters Multiplicativo -&gt; objeto &#39;fc_hw_mul&#39; (puede ser NULL) if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { preds[[&quot;HW Multiplicativo&quot;]] &lt;- get_fc_mean(fc_hw_mul$mean, k) } # Holt–Winters Box–Cox (aditivo) -&gt; data.frame &#39;df_hw_bc&#39; (ya en original) if (exists(&quot;df_hw_bc&quot;)) { preds[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- as.numeric(df_hw_bc$mean)[seq_len(k)] } # ARIMA (log) -&gt; objeto &#39;fc_log&#39; (reconvertimos con expm1) if (exists(&quot;fc_log&quot;)) { preds[[&quot;ARIMA (log)&quot;]] &lt;- expm1(as.numeric(fc_log$mean))[seq_len(k)] } # Si no hay ningún modelo, avisar y salir if (!length(preds)) { cat(&quot;No se encontraron objetos de pronóstico para resumir.\\n&quot;) } else { # --- 4) Cálculo de métricas --- if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tabla &lt;- lapply(names(preds), function(nm) { pr &lt;- preds[[nm]] tibble::tibble( Modelo = nm, RMSE = rmse(y_test_vec, pr), MAPE = mape(y_test_vec, pr) ) }) |&gt; bind_rows() # Ranking por RMSE y % mejora respecto al peor tabla &lt;- tabla |&gt; arrange(RMSE) |&gt; mutate(Rank_RMSE = row_number(), Mejora_vs_Peor = 100 * (max(RMSE, na.rm = TRUE) - RMSE) / max(RMSE, na.rm = TRUE)) # --- 5) Mostrar tabla --- knitr::kable(tabla, digits = 3, caption = &quot;Resumen final de desempeño en TEST (escala original)&quot;) # --- 6) (Opcional) Gráfico de barras por RMSE --- ggplot(tabla, aes(x = reorder(Modelo, RMSE), y = RMSE)) + geom_col() + coord_flip() + geom_text(aes(label = sprintf(&quot;%.1f&quot;, RMSE)), hjust = -0.1, size = 3) + labs(title = &quot;Comparación de RMSE por modelo&quot;, x = &quot;Modelo&quot;, y = &quot;RMSE (menor es mejor)&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) + expand_limits(y = max(tabla$RMSE, na.rm = TRUE) * 1.1) } # --- Funciones de métricas (por si acaso) --- if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- is.finite(obs) &amp; is.finite(pred) &amp; obs != 0 if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } if (!exists(&quot;mae&quot;, mode = &quot;function&quot;)) { mae &lt;- function(obs, pred) mean(abs(obs - pred), na.rm = TRUE) } # --- Vector de verdad (TEST) acotado a k --- # (asumiendo que ya definiste y_test, h y k) k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # --- Construir lista de predicciones realmente disponibles --- preds &lt;- list() if (exists(&quot;fc_hw_add&quot;) &amp;&amp; !is.null(fc_hw_add)) { preds[[&quot;HW Aditivo&quot;]] &lt;- as.numeric(fc_hw_add$mean)[seq_len(k)] } if (exists(&quot;df_hw_bc&quot;) &amp;&amp; !is.null(df_hw_bc)) { preds[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- as.numeric(df_hw_bc$mean)[seq_len(k)] } if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { preds[[&quot;HW Multiplicativo&quot;]] &lt;- as.numeric(fc_hw_mul$mean)[seq_len(k)] } if (exists(&quot;fc_arima_simple&quot;) &amp;&amp; !is.null(fc_arima_simple)) { preds[[&quot;ARIMA simple&quot;]] &lt;- as.numeric(fc_arima_simple$mean)[seq_len(k)] } if (exists(&quot;fc&quot;) &amp;&amp; !is.null(fc)) { preds[[&quot;SARIMA (auto.arima)&quot;]] &lt;- as.numeric(fc$mean)[seq_len(k)] } # Si tienes otro modelo (p. ej. ARIMA log) añádelo así: if (exists(&quot;fc_exp&quot;) &amp;&amp; !is.null(fc_exp)) { # fc_exp debe ser un vector numérico en escala original preds[[&quot;ARIMA (log)&quot;]] &lt;- as.numeric(fc_exp)[seq_len(k)] } # --- Tabla final con list-column y métricas por fila --- library(tibble) library(dplyr) library(purrr) tabla &lt;- tibble( Modelo = names(preds), Pred = unname(preds) ) %&gt;% mutate( RMSE = map_dbl(Pred, ~ rmse(y_test_vec, .x)), MAPE = map_dbl(Pred, ~ mape(y_test_vec, .x)), MAE = map_dbl(Pred, ~ mae (y_test_vec, .x)) ) %&gt;% select(-Pred) knitr::kable(tabla, digits = 3, caption = &quot;Comparación en TEST — RMSE, MAPE y MAE (escala original)&quot;) Table 5.4: Comparación en TEST — RMSE, MAPE y MAE (escala original) Modelo RMSE MAPE MAE HW Aditivo 468.700 37.098 414.311 HW Box–Cox (aditivo) 465.434 36.858 411.644 HW Multiplicativo 394.586 31.117 348.839 ARIMA simple 325.303 27.377 302.346 SARIMA (auto.arima) 280.641 23.245 258.154 ARIMA (log) 149.209 12.046 131.731 El ARIMA (log) es el modelo más preciso y estable, su transformación logarítmica estabilizó la varianza y suavizó los picos extremos, redujo los errores de manera drástica (RMSE ≈ 149, MAPE ≈ 12%). Es el modelo más adecuado para pronósticos precisos y consistentes en contextos con alta variabilidad o ruido. El SARIMA (auto.arima) también muestra un excelente desempeño, incorpora componentes estacionales (periodicidad de 24 horas) que reflejan patrones horarios o diarios, su RMSE (280.6) y MAPE (23.2%) indican alta precisión sin requerir transformaciones adicionales. Es un modelo balanceado entre complejidad y exactitud. El ARIMA simple (sin estacionalidad explícita) sigue siendo competitivo, logra capturar buena parte de la estructura temporal con pocos parámetros, su rendimiento (RMSE = 325.3, MAPE = 27.4%) lo posiciona por encima de todos los Holt–Winters. Los modelos Holt–Winters (HW) presentan resultados claramente inferiores, aunque coherentes con su simplicidad: El HW aditivo es el más limitado, porque no ajusta amplitudes variables. El HW multiplicativo mejora sustancialmente, al modelar estacionalidad proporcional al nivel de la serie. El HW Box–Cox suaviza la varianza pero no alcanza mejoras sustanciales frente al HW clásico. Los modelos ARIMA y SARIMA superan ampliamente a los de Holt–Winters porque logran capturar dependencias dinámicas, estacionalidad compleja y no linealidades que los modelos de suavizamiento no pueden representar. El ARIMA log-transformado se consolida como el modelo óptimo para la serie, al combinar estabilidad de varianza, bajo error absoluto y porcentual, y una excelente capacidad de ajuste temporal. El SARIMA es una alternativa igualmente robusta para escenarios donde se desea mantener la serie en escala original y enfatizar la estacionalidad. Los modelos Holt–Winters, si bien más simples, son útiles para análisis exploratorios o pronósticos rápidos, pero no alcanzan la precisión de los modelos ARIMA. 5.14 Gráficas de predicción por modelo suppressPackageStartupMessages({ library(dplyr); library(tibble); library(ggplot2); library(lubridate) }) # -------- Utilidades -------- build_fc_df &lt;- function(fc_obj, t_start, label, from_log = FALSE) { # fc_obj: objeto forecast con $mean/$lower/$upper o data.frame ya listo # t_start: POSIXct fin del histórico (última observación) # label: nombre del modelo para título # from_log: si TRUE, aplica expm1 a medias/bandas if (is.null(fc_obj)) return(NULL) # Caso forecast::forecast if (all(c(&quot;mean&quot;,&quot;lower&quot;,&quot;upper&quot;) %in% names(fc_obj))) { h &lt;- length(fc_obj$mean) f_times &lt;- seq(from = t_start + hours(1), by = &quot;1 hour&quot;, length.out = h) mean_v &lt;- as.numeric(fc_obj$mean) lo80_v &lt;- as.numeric(fc_obj$lower[,&quot;80%&quot;]) hi80_v &lt;- as.numeric(fc_obj$upper[,&quot;80%&quot;]) lo95_v &lt;- as.numeric(fc_obj$lower[,&quot;95%&quot;]) hi95_v &lt;- as.numeric(fc_obj$upper[,&quot;95%&quot;]) if (isTRUE(from_log)) { mean_v &lt;- expm1(mean_v); lo80_v &lt;- expm1(lo80_v); hi80_v &lt;- expm1(hi80_v) lo95_v &lt;- expm1(lo95_v); hi95_v &lt;- expm1(hi95_v) } return(tibble( modelo = label, time = f_times, mean = mean_v, lo80 = lo80_v, hi80 = hi80_v, lo95 = lo95_v, hi95 = hi95_v )) } # Caso data.frame ya convertido (espera columnas: time, mean, lo80, hi80[, lo95, hi95]) req_cols &lt;- c(&quot;time&quot;,&quot;mean&quot;,&quot;lo80&quot;,&quot;hi80&quot;) if (is.data.frame(fc_obj) &amp;&amp; all(req_cols %in% names(fc_obj))) { out &lt;- as_tibble(fc_obj) out$modelo &lt;- label # Si trae columnas 95% las respetamos; si no, las estimamos como NA if (!(&quot;lo95&quot; %in% names(out))) out$lo95 &lt;- NA_real_ if (!(&quot;hi95&quot; %in% names(out))) out$hi95 &lt;- NA_real_ return(out[,c(&quot;modelo&quot;,&quot;time&quot;,&quot;mean&quot;,&quot;lo80&quot;,&quot;hi80&quot;,&quot;lo95&quot;,&quot;hi95&quot;)]) } return(NULL) } plot_zoom_model &lt;- function(hist_df, fc_df, title_txt, history_days = 21, y_limits = NULL, breaks_x = &quot;3 days&quot;, fmt_x = &quot;%d-%b&quot;) { if (is.null(fc_df) || nrow(fc_df) == 0) return(invisible(NULL)) t_max &lt;- max(hist_df$time, na.rm = TRUE) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time, na.rm = TRUE) hist_zoom &lt;- filter(hist_df, time &gt;= t_ini) p &lt;- ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.12, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.22, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.45, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = breaks_x, date_labels = fmt_x) + labs(title = title_txt, subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia (escala original)&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1)) if (!is.null(y_limits)) { p &lt;- p + coord_cartesian(ylim = y_limits) } print(p) } # -------- Datos históricos (últimos N días) -------- stopifnot(exists(&quot;df_impu&quot;), exists(&quot;time_col&quot;)) history_days &lt;- 21 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) # -------- Construir data frames de pronóstico por modelo (condicional) -------- fc_list &lt;- list() # SARIMA principal (auto.arima) -&gt; &#39;fc&#39; if (exists(&quot;fc&quot;)) { fc_list[[&quot;SARIMA (auto.arima)&quot;]] &lt;- build_fc_df(fc, t_max, &quot;SARIMA (auto.arima)&quot;) } # ARIMA simple -&gt; &#39;fc_arima_simple&#39; if (exists(&quot;fc_arima_simple&quot;)) { fc_list[[&quot;ARIMA simple&quot;]] &lt;- build_fc_df(fc_arima_simple, t_max, &quot;ARIMA simple&quot;) } # HW aditivo -&gt; &#39;fc_hw_add&#39; if (exists(&quot;fc_hw_add&quot;)) { fc_list[[&quot;HW Aditivo&quot;]] &lt;- build_fc_df(fc_hw_add, t_max, &quot;Holt–Winters (aditivo)&quot;) } # HW multiplicativo -&gt; &#39;fc_hw_mul&#39; if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { fc_list[[&quot;HW Multiplicativo&quot;]] &lt;- build_fc_df(fc_hw_mul, t_max, &quot;Holt–Winters (multiplicativo)&quot;) } # HW Box–Cox (aditivo) ya reconvertido (si preparaste df_hw_bc: time/mean/lo80/hi80[/lo95/hi95]) if (exists(&quot;df_hw_bc&quot;)) { fc_list[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- build_fc_df(df_hw_bc, t_max, &quot;Holt–Winters Box–Cox (aditivo)&quot;) } # ARIMA en log -&gt; &#39;fc_log&#39; (reconvertimos con expm1) if (exists(&quot;fc_log&quot;)) { fc_list[[&quot;ARIMA (log)&quot;]] &lt;- build_fc_df(fc_log, t_max, &quot;ARIMA (log → original)&quot;, from_log = TRUE) } # -------- Graficar uno por uno (solo los disponibles) -------- # Ajusta y_limits si quieres forzar un rango (p.ej. c(0, 10000)); déjalo NULL para automático y_limits &lt;- NULL for (nm in names(fc_list)) { plot_zoom_model(hist_df, fc_list[[nm]], title_txt = paste(&quot;Zoom final del pronóstico —&quot;, nm), history_days = history_days, y_limits = y_limits, breaks_x = &quot;3 days&quot;, fmt_x = &quot;%d-%b&quot;) } 5.15 Resumen de tiempos de ejecución del código tabla_tiempos &lt;- report_timing_table() if (!is.null(tabla_tiempos)) { knitr::kable(tabla_tiempos, caption = &quot;Resumen de tiempos por bloque&quot;) } else { cat(&quot;No se registraron bloques cronometrados.\\n&quot;) } Table 5.5: Resumen de tiempos por bloque Bloque Tiempo Unidad Estado Mensaje Imputación (na.interp) 0.020 s OK ACF/PACF (original) 0.117 s OK ACF/PACF (diferenciada) 0.132 s OK Ajuste SARIMA + Pronóstico 281.423 s OK Changepoint 0.023 s OK Ajuste SARIMA TS log-transformada 488.634 s OK HW - Preprocesamiento 16.211 s OK HW - Split TRAIN/TEST 1.064 s OK HW - Aditivo y multiplicativo 50.340 s OK HW - ARIMA simple 370.332 s OK HW - Box-CoX 24.743 s OK "],["Modelos_estacionarios_1.html", "6 Modelos estacionarios - Metodología Box-Jenkins 6.1 Introducción 6.2 Carga de datos 6.3 Limpieza e imputación de faltantes 6.4 Creación de la serie de tiempo 6.5 Exploración inicial 6.6 Estacionariedad (ADF) y ACF/PACF 6.7 Modelo ARIMA (Box–Jenkins) 6.8 Comparación de modelos (AIC/BIC) 6.9 Diagnóstico 6.10 Pronóstico 6.11 Conclusiones", " 6 Modelos estacionarios - Metodología Box-Jenkins 6.1 Introducción En esta actividad del Módulo 2, Unidad 2 aplicamos la metodología Box–Jenkins sobre una serie de tiempo horaria que contiene los datos potencia de salida de una subestación eléctrica con tres circuitos. El archivo tiene: FECHA: fecha–hora VALOR_IMPUTADO: valor numérico (con algunos NA) Antes de modelar, interpolaremos los NA para poder aplicar ADF, ACF/PACF y ARIMA sin errores. 6.2 Carga de datos # Ajusta esta ruta a tu PC csv_dir &lt;- &quot;C:/Users/Lenovo/PUJ Cali/OSCAR VELASQUEZ CHALA - Proyecto Aplicado - Proy. Demanda Electrica/2. Fuentes de Datos&quot; csv_name &lt;- &quot;suma_3.csv&quot; ruta_archivo &lt;- file.path(csv_dir, csv_name) datos_raw &lt;- read.csv(ruta_archivo, header = TRUE, sep = &quot;,&quot;, stringsAsFactors = FALSE) str(datos_raw) ## &#39;data.frame&#39;: 58448 obs. of 2 variables: ## $ FECHA : chr &quot;2019-01-01 00:00:00&quot; &quot;2019-01-01 01:00:00&quot; &quot;2019-01-01 02:00:00&quot; &quot;2019-01-01 03:00:00&quot; ... ## $ VALOR_IMPUTADO: num 778 766 765 735 731 ... head(datos_raw) ## FECHA VALOR_IMPUTADO ## 1 2019-01-01 00:00:00 778.2125 ## 2 2019-01-01 01:00:00 766.2975 ## 3 2019-01-01 02:00:00 764.6450 ## 4 2019-01-01 03:00:00 734.6750 ## 5 2019-01-01 04:00:00 731.0275 ## 6 2019-01-01 05:00:00 735.7500 6.3 Limpieza e imputación de faltantes datos &lt;- datos_raw %&gt;% janitor::clean_names() %&gt;% # fecha, valor_imputado mutate( fecha = lubridate::ymd_hms(fecha) ) %&gt;% arrange(fecha) # Comprobar NA en la serie cat(&quot;Cantidad de datos faltates, dataset original: &quot;, sum(is.na(datos$valor_imputado)),&quot;\\n&quot;) ## Cantidad de datos faltates, dataset original: 456 # Interpolar NA para no romper la serie horaria # (usa método de forecast, respeta patrones) serie_sin_na &lt;- forecast::na.interp(datos$valor_imputado) # Volvemos a pegar a los datos datos &lt;- datos %&gt;% mutate(valor_imputado = serie_sin_na) # Comprobar NA en la serie cat(&quot;Cantidad de datos faltates, despues de la imputación: &quot;, sum(is.na(datos$valor_imputado)),&quot;\\n&quot;) ## Cantidad de datos faltates, despues de la imputación: 0 cat(&quot;Resumen Serie de Datos - Potencia Subestación Electrica&quot;,&quot;\\n&quot;) ## Resumen Serie de Datos - Potencia Subestación Electrica summary(datos$valor_imputado) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0 2593 3194 3308 4068 6676 6.4 Creación de la serie de tiempo Es una serie horaria → usamos frecuencia 24 (24 obs = 1 día). serie_ts &lt;- ts(datos$valor_imputado, frequency = 24) head(serie_ts) ## Time Series: ## Start = c(1, 1) ## End = c(1, 6) ## Frequency = 24 ## [1] 778.2125 766.2975 764.6450 734.6750 731.0275 735.7500 6.5 Exploración inicial plot(serie_ts, main = &quot;Serie horaria - suma_3.csv&quot;, ylab = &quot;Valor imputado&quot;, xlab = &quot;Tiempo&quot;) summary(serie_ts) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0 2593 3194 3308 4068 6676 Se observa una tendencia creciente en los valores a lo largo del tiempo. Esto indica que, en promedio, los valores potencia aumentan progresivamente, sobre todo a partir de la mitad de la serie. Esto sugiere que la serie no es estacionaria en nivel, por lo que requerirá diferenciación (al menos una vez) para aplicar correctamente un modelo ARIMA. El valor medio es de ≈3308, pero hay una gran dispersión (de 0 a 6676). La asimetría positiva (cola hacia la derecha) se nota en que la media &gt; mediana, lo que indica presencia de valores atípicos altos. El rango intercuartílico (4068–2593 = 1475) sugiere variabilidad notable incluso entre valores centrales. La serie presenta fluctuaciones bruscas (picos y caídas intensas). Esto puede deberse a variaciones horarias (por ejemplo, demanda, flujo o carga) con ciclos diarios. Podría haber componentes estacionales (cada 24 horas o cada semana), visibles como “bandas” de oscilación repetitiva. Existen observaciones con valor cercano a 0, muy por debajo del comportamiento típico. Esto puede representar horas sin registro, fallas o eventos extremos. Los valores tienden a crecer con el tiempo, manteniendo una variabilidad considerable y ciclos repetitivos, lo que sugiere que la serie responde a un fenómeno con tendencia positiva y fluctuaciones horarias marcadas. 6.6 Estacionariedad (ADF) y ACF/PACF Verificamos estacionariedad de la serie aplicando el test de Dickey-Fuller aumentada. # prueba de Dickey-Fuller aumentada tseries::adf.test(serie_ts) ## ## Augmented Dickey-Fuller Test ## ## data: serie_ts ## Dickey-Fuller = -14.565, Lag order = 38, p-value = 0.01 ## alternative hypothesis: stationary par(mfrow = c(1,2)) Acf(serie_ts, main = &quot;ACF serie original&quot;) Pacf(serie_ts, main = &quot;PACF serie original&quot;) par(mfrow = c(1,1)) Interpretación prueba de Dickey–Fuller aumentada (ADF) Hipótesis nula (H₀): la serie no es estacionaria. Hipótesis alternativa (H₁): la serie es estacionaria. El p-valor = 0.01 &lt; 0.05, se rechaza la hipótesis nula (H₀), la serie es estacionaria. La serie de tiempo puede considerarse estacionaria en nivel (sin necesidad de diferenciación adicional). El resultado sugiere que la serie se mantiene estable en su media y varianza a lo largo del tiempo. Interpretación Autocorrelación (ACF) La ACF muestra valores muy altos y lentamente decrecientes, con un patrón oscilante y periódico (las barras suben y bajan en forma de ondas regulares). Esto indica la presencia de una fuerte estacionalidad y una posible autocorrelación prolongada entre observaciones separadas por intervalos fijos (lags). El patrón de repetición parece producirse cada 24 rezagos, lo cual coincide con la frecuencia horaria diaria establecida para esta serie (24 horas). La serie presenta una estructura cíclica o estacional de 24 horas, con una alta correlación entre valores próximos en el tiempo. La lentitud en el decaimiento confirma que la serie es altamente persistente y tiene una memoria larga. Interpretación Autocorrelación Parcial (PACF) En la grafica PACF se observa un pico muy alto en el primer rezago (lag = 1), seguido de valores que decrecen y fluctúan alrededor de cero. Esto sugiere que el comportamiento actual depende principalmente del valor inmediatamente anterior (autoregresión de orden 1), mientras que los efectos de rezagos posteriores se diluyen rápidamente. No obstante, se observan pequeños picos periódicos alrededor de los múltiplos de 24 (lag ≈ 24, 48), lo que refuerza la hipótesis de una componente estacional diaria. El corte brusco en el primer rezago (lag = 1) sugiere una componente autoregresiva (AR) de bajo orden, probablemente AR(1), mientras que los picos en múltiplos de 24 apuntan a un posible componente estacional AR(1) con periodo 24. Los gráficos orientan hacia modelos del tipo ARIMA(1,0,0)(1,0,0)[24], donde: p = 1 → autoregresivo de orden 1 (por PACF), d = 0 → la serie ya es estacionaria (por ADF), q = 0 → no se observa corte abrupto en la ACF, (P,D,Q)[24] → componente estacional con periodo 24 (por patrón repetitivo en ACF/PACF). Las funciones ACF y PACF de la serie de potencia eléctrica evidencian un comportamiento altamente correlacionado en el corto plazo y una fuerte estacionalidad diaria (cada 24 horas). Se recomienda probar modelos con componente autoregresiva simple (AR(1)) y término estacional (P=1, periodo=24), verificando su ajuste con criterios AIC/BIC y el análisis de residuos. d_sugerido &lt;- forecast::ndiffs(serie_ts) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 serie_diff1 &lt;- diff(serie_ts, differences = d_sugerido) tseries::adf.test(serie_diff1) ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff1 ## Dickey-Fuller = -55.722, Lag order = 38, p-value = 0.01 ## alternative hypothesis: stationary par(mfrow = c(1,2)) Acf(serie_diff1, main = &quot;ACF 1ra diferencia&quot;) Pacf(serie_diff1, main = &quot;PACF 1ra diferencia&quot;) par(mfrow = c(1,1)) Interpretación prueba de Dickey–Fuller aumentada (ADF) de la serie diferenciada Hipótesis nula (H₀): la serie no es estacionaria. Hipótesis alternativa (H₁): la serie es estacionaria. El p-valor = 0.01 &lt; 0.05, se rechaza la hipótesis nula (H₀), la serie es estacionaria. Interpretación Autocorrelación (ACF) de la serie diferenciada La ACF muestra que la mayoría de las barras están dentro de las bandas azules (intervalos de confianza), excepto algunos picos notables alrededor de los rezagos 24 y 48. Estos picos recurrentes cada 24 lags confirman una estacionalidad horaria diaria, incluso después de eliminar la tendencia con la primera diferencia. El resto de las autocorrelaciones son pequeñas y se disipan rápidamente, lo cual indica que la serie ya no tiene persistencia fuerte ni tendencia. La primera diferencia logró eliminar la tendencia y la autocorrelación prolongada, pero aún queda un componente estacional diario que podría modelarse con una parte estacional AR o MA con periodo 24. Interpretación Autocorrelación Parcial (PACF) de la serie diferenciada La PACF muestra un pico pequeño pero significativo en lag 1, y otro alrededor de lag 24, mientras los demás valores se mantienen cerca de cero. Este patrón sugiere que la serie diferenciada tiene un componente autoregresivo de corto plazo (AR(1)) y una componente estacional autoregresiva (AR(1) estacional). La estructura sugiere un modelo con un término AR(1) y un posible componente AR(1) estacional con periodo 24, lo que respalda la idea de un ARIMA(1,1,0)(1,0,0)[24] o similar. En conclusión, Luego de aplicar la primera diferencia, la serie se vuelve estacionaria, eliminando la tendencia observada en el nivel original. Sin embargo, persisten picos en múltiplos de 24, lo que indica una estacionalidad horaria. Por tanto, un modelo apropiado podría ser un ARIMA(1,1,0)(1,0,0)[24], donde: la primera diferencia (d=1) captura la tendencia, el término AR(1) modela la autocorrelación inmediata y el término AR(1) estacional modela los ciclos diarios. 6.7 Modelo ARIMA (Box–Jenkins) modelo_auto &lt;- forecast::auto.arima( serie_ts, seasonal = TRUE, # intenta estacionalidad diaria (24) stepwise = FALSE, approximation = TRUE ) modelo_auto ## Series: serie_ts ## ARIMA(3,0,0)(2,1,0)[24] ## ## Coefficients: ## ar1 ar2 ar3 sar1 sar2 ## 1.0357 -0.2212 0.0816 -0.6358 -0.3182 ## s.e. 0.0041 0.0059 0.0042 0.0039 0.0039 ## ## sigma^2 = 26493: log likelihood = -380417.2 ## AIC=760846.5 AICc=760846.5 BIC=760900.4 AIC(modelo_auto); BIC(modelo_auto) ## [1] 760846.5 ## [1] 760900.4 Interpretación resultado auto.arima El algoritmo auto.arima() escogió el siguiente modelo: ARIMA(3,0,0)(2,1,0)[24] Modelo AutoRegresivo Integrado de Media Móvil con: 3 términos autorregresivos no estacionales (AR(3)). El valor actual depende de los tres valores anteriores inmediatos. Captura la inercia o persistencia de corto plazo. 0 diferencias no estacionales (d = 0). No se necesitó diferencia no estacional, la serie es estacionaria en nivel, como confirmó la prueba ADF (p-value = 0.01). sin componente de media móvil (q = 0). 2 términos autorregresivos estacionales (P = 2). Se incorporaron dos términos AR estacionales (SAR1, SAR2) para modelar la estructura diaria. 1 diferencia estacional (D = 1). Se aplicó una diferenciación estacional (D=1) para eliminar los ciclos repetitivos. sin componenete de Media móvil estacional. Un periodo estacional de 24, es decir, un ciclo diario (horario → 24 horas). El modelo ARIMA(3,0,0)(2,1,0)[24] describe una serie con dependencia de corto plazo (cada valor depende de los 3 anteriores), con comportamiento estacional diario y con fluctuaciones moderadas alrededor de un nivel estable. El valor de potencia eléctrica en una hora depende fuertemente de las tres horas previas y también del comportamiento del mismo periodo en los dos días anteriores. 6.8 Comparación de modelos (AIC/BIC) # Modelo ARIMA según ACF/PACF, serie orginal --&gt; **ARIMA(1,0,0)(1,0,0)[24]** modelo_alt1 &lt;- forecast::Arima( serie_ts, order = c(1, 0, 0), # (p,d,q) no estacional seasonal = list( order = c(1, 0, 0), # (P,D,Q) estacional period = 24 # s = 24 ) ) # Modelo ARIMA según ACF/PACF, serie diferenciada --&gt; **ARIMA(1,1,0)(1,0,0)[24]** modelo_alt2 &lt;- forecast::Arima( serie_ts, order = c(1, 1, 0), # (p,d,q) no estacional seasonal = list( order = c(1, 0, 0), # (P,D,Q) estacional period = 24 # s = 24 ) ) tibble::tibble( modelo = c(&quot;auto.arima()=ARIMA(3,0,0)(2,1,0)[24]&quot;, &quot;ARIMA(1,0,0)(1,0,0)[24]&quot;, &quot;ARIMA(1,1,0)(1,0,0)[24]&quot;), AIC = c(AIC(modelo_auto), AIC(modelo_alt1), AIC(modelo_alt2)), BIC = c(BIC(modelo_auto), BIC(modelo_alt1), BIC(modelo_alt2)) ) ## # A tibble: 3 × 3 ## modelo AIC BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 auto.arima()=ARIMA(3,0,0)(2,1,0)[24] 760847. 760900. ## 2 ARIMA(1,0,0)(1,0,0)[24] 769852. 769888. ## 3 ARIMA(1,1,0)(1,0,0)[24] 769697. 769724. AIC (Akaike Information Criterion) Evalúa la calidad del modelo considerando el ajuste y el número de parámetros. Cuanto menor sea el AIC, mejor el equilibrio entre ajuste y complejidad. BIC (Bayesian Information Criterion) Evalúa la calidad del modelo considerando el ajuste y el número de parámetros, pero penaliza más la cantidad de parámetros. Cuanto menor sea el BIC, mejor, especialmente para modelos más simples y generalizables. El ARIMA(3,0,0)(2,1,0)[24] es el modelo más adecuado porque presenta los menores valores de AIC y BIC, lo que indica un mejor ajuste sin sobreparametrización. Los otros modelos (ARIMA(1,0,0)(1,0,0)[24] y ARIMA(1,1,0)(1,0,0)[24]) son más parsimoniosos, pero no logran capturar la complejidad temporal y estacional de la serie. La diferencia de casi 9000 unidades en AIC es muy grande, lo que refuerza que el modelo ganador tiene una capacidad predictiva muy superior. El modelo ARIMA(3,0,0)(2,1,0)[24] logra equilibrar correctamente la dependencia temporal a corto plazo (AR(3)), la estructura estacional diaria (SAR(2) con periodo 24) y la estabilidad lograda mediante una diferencia estacional (D=1). Sus criterios AIC y BIC significativamente más bajos indican que este modelo representa mejor el comportamiento real de la serie que las alternativas más simples. 6.9 Diagnóstico forecast::checkresiduals(modelo_auto) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,0,0)(2,1,0)[24] ## Q* = 1969.2, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test p-value &lt; 2.2e-16, se rechaza H₀ (los residuos son ruido blanco). Los residuos no son ruido blanco, aún contienen autocorrelación significativa no explicada por el modelo. El modelo no captura completamente la estructura temporal de la serie. Diagnósticos residuales del modelo ARIMA Se observa que los residuos oscilan alrededor de cero, lo cual es una buena señal: no hay tendencia sistemática ni acumulación de errores. Sin embargo, todavía hay picos grandes (outliers) que sobresalen en varios puntos, tanto positivos como negativos, indicando que hay algunos valores atípicos o eventos anómalos que el modelo no logra explicar del todo. Aun así, la varianza de los residuos se mantiene más o menos constante, tiene una homocedasticidad razonable. ACF (Función de Autocorrelación de los residuos) En el gráfico, la mayoría de los valores están dentro de las bandas azules, pero hay algunos picos leves en múltiplos de 24, lo que sugiere que todavía queda algo de correlación estacional residual. Si el modelo es adecuado, las barras de la ACF deben estar dentro de las bandas azules (intervalos de confianza), lo que indica falta de autocorrelación. Los residuos no son completamente ruido blanco: hay indicios de correlación estacional leve, posiblemente asociada a patrones diarios que el modelo no capturó totalmente. Histograma y densidad de los residuos La distribución de los residuos es centrada en cero. No obstante, la forma es muy aguda (leptocúrtica): la mayoría de los valores están cerca de 0, pero con colas largas (picos extremos en ±4000). Esto indica que los errores no siguen perfectamente una distribución normal, sino que presentan eventos raros de alta magnitud, coherente con los picos observados en la gráfica superior. Aunque el modelo explica bien la tendencia y estacionalidad, los residuos no son perfectamente normales y muestran valores extremos — posiblemente debidos a shocks o outliers estructurales. El modelo ARIMA(3,0,0)(2,1,0)[24] captura correctamente la tendencia y la estacionalidad principal, pero no elimina completamente la autocorrelación en los residuos. Persisten dependencias estacionales y algunos valores extremos. 6.10 Pronóstico h &lt;- 24 # 24 horas siguientes pronostico &lt;- forecast::forecast(modelo_auto, h = h) autoplot(pronostico) + ggplot2::labs(title = &quot;Pronóstico ARIMA sobre suma_3.csv&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;) 6.10.1 Zoom: últimos 7 días + pronóstico # 7 días en serie horaria = 7 * 24 n_dias &lt;- 7 n_obs_zoom &lt;- n_dias * 24 # Últimas 168 obs reales datos_zoom &lt;- tail(datos, n_obs_zoom) # Construir data frame del pronóstico con fecha-hora continua # última fecha observada: ultima_fecha &lt;- max(datos$fecha, na.rm = TRUE) # secuencia de horas posteriores para el forecast fechas_forecast &lt;- ultima_fecha + lubridate::hours(1:h) df_forecast &lt;- tibble::tibble( fecha = fechas_forecast, valor = as.numeric(pronostico$mean), tipo = &quot;Pronóstico&quot; ) df_hist &lt;- tibble::tibble( fecha = datos_zoom$fecha, valor = datos_zoom$valor_imputado, tipo = &quot;Observado&quot; ) df_plot &lt;- dplyr::bind_rows(df_hist, df_forecast) ggplot2::ggplot(df_plot, ggplot2::aes(x = fecha, y = valor, color = tipo)) + ggplot2::geom_line(linewidth = 0.7) + ggplot2::labs( title = &quot;Últimos 7 días + 24 horas pronosticadas&quot;, x = &quot;Fecha-hora&quot;, y = &quot;Valor&quot; ) + ggplot2::scale_color_manual(values = c(&quot;Observado&quot; = &quot;black&quot;, &quot;Pronóstico&quot; = &quot;red&quot;)) + ggplot2::theme_minimal() 6.10.2 Zoom: últimos 21 días + 7 días de pronóstico # 1. Parámetros dias_hist &lt;- 21 dias_forecast &lt;- 7 n_obs_hist &lt;- dias_hist * 24 h &lt;- dias_forecast * 24 # 7 días de pronóstico # 2. Pronóstico a 7 días pronostico_7d &lt;- forecast::forecast(modelo_auto, h = h) # 3. Últimos 21 días observados datos_zoom21 &lt;- tail(datos, n_obs_hist) # 4. Fechas para el pronóstico (continuando la última fecha observada) ultima_fecha &lt;- max(datos$fecha, na.rm = TRUE) fechas_forecast &lt;- ultima_fecha + lubridate::hours(1:h) # 5. Data frame del pronóstico con IC df_forecast &lt;- tibble::tibble( fecha = fechas_forecast, media = as.numeric(pronostico_7d$mean), lower80 = as.numeric(pronostico_7d$lower[,&quot;80%&quot;]), upper80 = as.numeric(pronostico_7d$upper[,&quot;80%&quot;]), lower95 = as.numeric(pronostico_7d$lower[,&quot;95%&quot;]), upper95 = as.numeric(pronostico_7d$upper[,&quot;95%&quot;]) ) # 6. Data frame histórico df_hist &lt;- tibble::tibble( fecha = datos_zoom21$fecha, valor = datos_zoom21$valor_imputado ) # 7. Gráfico ggplot2::ggplot() + # franjas 95% ggplot2::geom_ribbon( data = df_forecast, ggplot2::aes(x = fecha, ymin = lower95, ymax = upper95), fill = &quot;grey80&quot;, alpha = 0.5 ) + # franjas 80% ggplot2::geom_ribbon( data = df_forecast, ggplot2::aes(x = fecha, ymin = lower80, ymax = upper80), fill = &quot;grey60&quot;, alpha = 0.5 ) + # serie observada 21 días ggplot2::geom_line( data = df_hist, ggplot2::aes(x = fecha, y = valor), linewidth = 0.6, color = &quot;black&quot; ) + # media pronosticada ggplot2::geom_line( data = df_forecast, ggplot2::aes(x = fecha, y = media), linewidth = 0.7, color = &quot;red&quot; ) + ggplot2::labs( title = &quot;Últimos 21 días + 7 días pronosticados (con intervalos)&quot;, x = &quot;Fecha-hora&quot;, y = &quot;Valor&quot; ) + ggplot2::theme_minimal() 6.10.3 Zoom: últimos 6 meses + 3 meses de pronóstico library(lubridate) # 1. última fecha del dataset ultima_fecha &lt;- max(datos$fecha, na.rm = TRUE) # 2. fecha de corte para los últimos 6 meses fecha_corte_6m &lt;- ultima_fecha %m-% months(6) # 3. filtrar últimos 6 meses de datos observados datos_6m &lt;- datos %&gt;% dplyr::filter(fecha &gt;= fecha_corte_6m) %&gt;% dplyr::arrange(fecha) # 4. definir horizonte de 3 meses por horas fecha_fin_forecast &lt;- ultima_fecha %m+% months(3) # diferencia en horas entre última fecha y última + 3 meses h &lt;- as.numeric(difftime(fecha_fin_forecast, ultima_fecha, units = &quot;hours&quot;)) # por seguridad, si h es 0 (fechas raras), ponemos un mínimo if (h &lt; 1) h &lt;- 24 # 5. pronóstico a 3 meses (en horas) pronostico_3m &lt;- forecast::forecast(modelo_auto, h = h) # 6. construir data frame de fechas futuras fechas_forecast &lt;- ultima_fecha + hours(1:h) df_forecast &lt;- tibble::tibble( fecha = fechas_forecast, media = as.numeric(pronostico_3m$mean), lower80 = as.numeric(pronostico_3m$lower[,&quot;80%&quot;]), upper80 = as.numeric(pronostico_3m$upper[,&quot;80%&quot;]), lower95 = as.numeric(pronostico_3m$lower[,&quot;95%&quot;]), upper95 = as.numeric(pronostico_3m$upper[,&quot;95%&quot;]) ) # 7. data frame histórico (6 meses) df_hist &lt;- tibble::tibble( fecha = datos_6m$fecha, valor = datos_6m$valor_imputado ) # 8. gráfico ggplot2::ggplot() + # bandas 95 % ggplot2::geom_ribbon( data = df_forecast, ggplot2::aes(x = fecha, ymin = lower95, ymax = upper95), fill = &quot;grey85&quot;, alpha = 0.5 ) + # bandas 80 % ggplot2::geom_ribbon( data = df_forecast, ggplot2::aes(x = fecha, ymin = lower80, ymax = upper80), fill = &quot;grey65&quot;, alpha = 0.5 ) + # serie observada 6 meses ggplot2::geom_line( data = df_hist, ggplot2::aes(x = fecha, y = valor), color = &quot;black&quot;, linewidth = 0.5 ) + # media pronosticada 3 meses ggplot2::geom_line( data = df_forecast, ggplot2::aes(x = fecha, y = media), color = &quot;red&quot;, linewidth = 0.6 ) + ggplot2::labs( title = &quot;Últimos 6 meses + 3 meses de pronóstico (con intervalos)&quot;, x = &quot;Fecha-hora&quot;, y = &quot;Valor&quot; ) + ggplot2::theme_minimal() La línea negra (comportamiento observado de la serie) muestra un comportamiento cíclico con picos y valles marcados: aumento durante ciertas horas del día y disminución en otras, consistente con el patrón diario. La línea roja (pronóstico) proyecta este patrón manteniendo la forma estacional del ciclo, con una amplitud y nivel similares al histórico reciente. No se observan rupturas bruscas: el modelo continúa la dinámica natural del sistema eléctrico. Las bandas grises representan los intervalos de confianza (80% y 95%). Son estrechas en el corto plazo, lo que indica alta confianza en los pronósticos inmediatos, pero se amplían gradualmente a medida que aumenta el horizonte temporal. El modelo reproduce adecuadamente la variación intradiaria (24 horas) observada en los días anteriores. Las predicciones son coherentes con la secuencia de consumo reciente y reflejan la persistencia estacional identificada por la ACF/PACF. El modelo tiene buena capacidad predictiva a corto plazo (1–7 días), manteniendo la coherencia con el patrón estacional. Los intervalos de confianza se ensanchan progresivamente, reflejando la incertidumbre natural del pronóstico a mayor plazo. En el mediano plazo, el modelo predice una continuidad del patrón histórico, sin cambios estructurales, pero con incertidumbre creciente. Esto es esperable y refleja la naturaleza de los modelos ARIMA: confiables a corto y mediano plazo, pero menos precisos en horizontes largos. 6.11 Conclusiones ## El diagnóstico de residuos del modelo ARIMA(3,0,0)(2,1,0)[24] muestra que la mayoría de los errores se distribuyen alrededor de cero y con varianza estable, lo cual evidencia un ajuste razonable. ## No obstante, los picos extremos y el resultado significativo de la prueba de Ljung–Box (p &lt; 0.05) indican que los residuos aún presentan autocorrelación, especialmente en múltiplos del periodo estacional (24 horas). ## Esto sugiere que el modelo no explica completamente la dinámica diaria de la serie, por lo que podrían probarse variantes con términos adicionales de media móvil o componentes estacionales para mejorar la independencia de los residuos. ## ## El modelo ARIMA(3,0,0)(2,1,0)[24] genera pronósticos coherentes y estacionalmente consistentes con el comportamiento de la serie tiempo de la potencia eléctrica. ## Captura correctamente los ciclos horarios diarios y mantiene la estabilidad en el nivel medio. ## A corto plazo (1–7 días), los pronósticos son confiables y con baja incertidumbre, mientras que a largo plazo (3 meses), el modelo ofrece una proyección conservadora, con intervalos más amplios que reflejan la naturaleza probabilística del proceso. ## ## En nuestra serie de tiempo con estacionalidad diaria (s=24), se considera: ## - Corto plazo: entre 24 y 168 horas (1 a 7 días). ## - Mediano plazo: entre 1 semana y 3 meses. ## - Largo plazo: más de 3 meses. ## En el presente análisis, los pronósticos de 1 y 7 días se interpretan como proyecciones de corto plazo con alta fiabilidad, mientras que los pronósticos a 3 meses constituyen una proyección de mediano a largo plazo, útil para identificar tendencias y variabilidad global, aunque con mayor incertidumbre. "],["Prophet.html", "7 Regresión en series de tiempo - Algoritmo Facebook’s Prophet 7.1 Introducción 7.2 Regresión y series de tiempo 7.3 Descripción de los datos 7.4 Limpieza e imputación de faltantes 7.5 Exploración inicial de la serie 7.6 Correlación temperatura–potencia 7.7 Conversión a tsibble 7.8 Descomposición clásica 7.9 División de los datos en entrenamiento y prueba 7.10 Ajuste de modelos ARIMA, ETS y Prophet 7.11 Pronósticos y comparación de métricas 7.12 Diagnóstico de residuos Prophet 7.13 Conclusiones", " 7 Regresión en series de tiempo - Algoritmo Facebook’s Prophet 7.1 Introducción En este capítulo se combinan modelos causales con datos de series de tiempo mediante algoritmos de aprendizaje estadístico. Esto supone pasar de ver la serie únicamente como una sucesión de observaciones dependientes en el tiempo, a interpretarla también como el resultado de una relación de regresión entre la variable respuesta y uno o varios regresores. En este capítulo se realizan las siguientes actividades para interpretar la serie de potencia de una subestación eléctrica: Limpieza, imputación y exploración de la serie. Ajuste de modelos autorregresivos clásicos (ARIMA, ETS). Ajuste del modelo Prophet, utilizando la variable temperatura como regresor. Comparación de desempeño entre modelos (ARIMA, ETS, Prophet). 7.2 Regresión y series de tiempo 7.2.1 Regresión con errores ARMA/ARIMA En la regresión clásica se supone que los errores son independientes y con varianza constante. En las series de tiempo esta suposición suele violarse: los errores muestran autocorrelación, tendencia o cambios de varianza. Una manera de incorporar esta estructura es suponer que el error sigue un proceso ARMA/ARIMA. Un modelo general puede escribirse como: \\[ y_t = \\beta_0 + \\beta_1 x_{1,t} + \\cdots + \\beta_k x_{k,t} + \\eta_t, \\] donde \\(\\eta_t\\) sigue un proceso ARIMA. Esto es lo que se conoce como un modelo de regresión con errores ARIMA, o un modelo ARIMAX cuando los regresores son variables externas. Todas las variables del modelo deben ser estacionarias o, al menos, cointegradas. Cuando no lo son, se trabaja sobre las diferencias (modelo en diferencias) en lugar de los niveles. 7.2.2 Estacionariedad y modelos en diferencias Si las series \\(y_t\\) y \\(x_{i,t}\\) no son estacionarias, una práctica habitual es diferenciarlas: \\[ y_t&#39; = y_t - y_{t-1}, \\quad x_{i,t}&#39; = x_{i,t} - x_{i,t-1}. \\] Así, podemos ajustar un modelo de la forma: \\[ y_t&#39; = \\beta_1 x&#39;_{1,t} + \\cdots + \\beta_k x&#39;_{k,t} + \\eta_t&#39;, \\] donde \\(\\eta_t&#39;\\) sigue un proceso ARMA. Tal como se discute en el material de la unidad, esto es equivalente a un modelo de regresión con errores ARIMA, pero expresado en diferencias. De este modo, la regresión respeta la estructura de dependencia temporal de la serie. 7.2.3 Prophet como regresión no lineal en el tiempo El modelo Prophet, introducido por Facebook (Taylor &amp; Letham, 2018), puede entenderse como una regresión no lineal sobre el tiempo: \\[ y_t = g(t) + s(t) + h(t) + \\varepsilon_t, \\] donde: \\(g(t)\\) representa la tendencia (lineal por tramos o logística). \\(s(t)\\) captura los comportamientos estacionales mediante términos de Fourier. \\(h(t)\\) incorpora los efectos de eventos especiales (por ejemplo, festivos). \\(\\varepsilon_t\\) es un término de error aproximadamente de ruido blanco. En este modelo, el tiempo actúa como un regresor principal, al que se agregan regresores derivados (tendencia por tramos, términos de Fourier para estacionalidad, variables indicadoras para eventos). Por esto, Prophet encaja muy bien dentro de la idea de regresión en series de tiempo, pero con componentes flexibles y no lineales. 7.2.4 Justificación para la serie de potencia eléctrica La serie de potencia de una subestación eléctrica presenta típicamente: Comportamientos cíclicos (diarios, semanales…). Cambios de nivel asociados a patrones de uso, clima, calendario, etc. Variabilidad considerable, con posibles picos y valles. Desde esta perspectiva, es razonable interpretar la serie como el resultado de: Una tendencia \\(g(t)\\) asociada a la evolución de la demanda en el tiempo. Estacionalidades \\(s(t)\\) debidas a ciclos de consumo (por ejemplo, horario laboral vs. nocturno). Posibles efectos \\(h(t)\\) asociados a fechas específicas (mantenimientos, eventos especiales). Un componente aleatorio \\(\\varepsilon_t\\). Por lo tanto, tiene sentido aplicar Prophet a esta serie y, al mismo tiempo, compararlo con modelos ARIMA y ETS utilizados previamente. 7.3 Descripción de los datos Los datos corresponden a mediciones de potencia (kW) registradas en una subestación eléctrica, a la temperatura (°C) y al índice temporal fecha (fecha-hora). csv_dir &lt;- &quot;C:/Users/Lenovo/PUJ Cali/OSCAR VELASQUEZ CHALA - Proyecto Aplicado - Proy. Demanda Electrica/2. Fuentes de Datos&quot; csv_name &lt;- &quot;2025.11.15.potencia_temperatura.csv&quot; ruta_archivo &lt;- file.path(csv_dir, csv_name) datos_raw &lt;- read.csv(ruta_archivo, header = TRUE, sep = &quot;,&quot;, stringsAsFactors = FALSE) str(datos_raw) ## &#39;data.frame&#39;: 58448 obs. of 3 variables: ## $ fecha : chr &quot;2019-01-01 00:00:00&quot; &quot;2019-01-01 01:00:00&quot; &quot;2019-01-01 02:00:00&quot; &quot;2019-01-01 03:00:00&quot; ... ## $ temp : num 21.9 20.5 19.4 18.2 18.1 20.7 20.5 20.7 21.8 27.7 ... ## $ potencia: num 778 766 765 735 731 ... head(datos_raw) ## fecha temp potencia ## 1 2019-01-01 00:00:00 21.9 778.2125 ## 2 2019-01-01 01:00:00 20.5 766.2975 ## 3 2019-01-01 02:00:00 19.4 764.6450 ## 4 2019-01-01 03:00:00 18.2 734.6750 ## 5 2019-01-01 04:00:00 18.1 731.0275 ## 6 2019-01-01 05:00:00 20.7 735.7500 Los datos corresponden a una serie horaria entre los años 2019–2025. 7.4 Limpieza e imputación de faltantes A continuación, se aplica la limpieza e imputación de datos faltanters. datos &lt;- datos_raw %&gt;% janitor::clean_names() %&gt;% mutate( fecha = lubridate::ymd_hms(fecha) ) %&gt;% arrange(fecha) # Comprobar NA en la serie cat(&quot;Cantidad de datos faltantes variable potencia, dataset original: &quot;, sum(is.na(datos$potencia)), &quot;\\n&quot;) ## Cantidad de datos faltantes variable potencia, dataset original: 456 cat(&quot;Cantidad de datos faltantes variable temperatura, dataset original: &quot;, sum(is.na(datos$temp)), &quot;\\n&quot;) ## Cantidad de datos faltantes variable temperatura, dataset original: 0 # Interpolar NA para no romper la serie horaria # (usa método de forecast, respeta patrones) serie_sin_na &lt;- forecast::na.interp(datos$potencia) # Volvemos a pegar a los datos datos &lt;- datos %&gt;% mutate(potencia = serie_sin_na) # Comprobar NA en la serie cat(&quot;Cantidad de datos faltantes, después de la imputación: &quot;, sum(is.na(datos$potencia)), &quot;\\n&quot;) ## Cantidad de datos faltantes, después de la imputación: 0 cat(&quot;Resumen Serie de Datos - Potencia Subestación Eléctrica&quot;, &quot;\\n&quot;) ## Resumen Serie de Datos - Potencia Subestación Eléctrica summary(datos$potencia) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0 2593 3194 3308 4068 6676 cat(&quot;Resumen Serie de Datos - Temperatura&quot;, &quot;\\n&quot;) ## Resumen Serie de Datos - Temperatura summary(datos$temp) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 17.00 22.80 24.50 24.88 26.90 35.10 La variable potencia tenía faltantes, pero todos fueron imputados mediante interpolación (na.interp), preservando la continuidad temporal. Los datos de la variable potencia presentan una distribución asimétrica hacia la derecha, con valores máximos significativamente superiores al promedio. Valores cercanos a 0 kW (mínimo) representan probablemente caídas abruptas: cortes de energía, mantenimientos, fallos de medición o cargas extremadamente bajas fuera de horario. La variable temperatura no presenta faltantes, lo cual es muy favorable para la aplicación de modelos con regresores externos (ARIMAX, Prophet). Los datos de temperatura indican un promedio estable (≈ 25 °C), variabilidad moderada entre 17–35 °C, comportamientos cíclicos diarios (noches frías, días cálidos) y ciclos estacionales (épocas cálidas/frías del año). 7.5 Exploración inicial de la serie 7.5.1 Serie de datos: Potencia y Temperatura fig &lt;- plot_ly() # ---------------------------- # SERIE 1: Potencia (eje izquierdo) # ---------------------------- fig &lt;- fig %&gt;% add_lines( data = datos, x = ~fecha, y = ~potencia, name = &quot;Potencia&quot;, line = list(color = &quot;blue&quot;) ) # ---------------------------- # SERIE 2: Temperatura (eje derecho) # ---------------------------- fig &lt;- fig %&gt;% add_lines( data = datos, x = ~fecha, y = ~temp, name = &quot;Temperatura&quot;, yaxis = &quot;y2&quot;, line = list(color = &quot;red&quot;) ) # ---------------------------- # CONFIGURACIÓN DE LOS EJES # ---------------------------- fig &lt;- fig %&gt;% layout( title = &quot;Potencia y Temperatura - Exploración Temporal&quot;, xaxis = list(title = &quot;Fecha&quot;), yaxis = list(title = &quot;Potencia (kW)&quot;, side = &quot;left&quot;), yaxis2 = list( title = &quot;Temperatura (°C)&quot;, overlaying = &quot;y&quot;, side = &quot;right&quot;, showgrid = FALSE ), legend = list( x = 1.05, # Posición horizontal (derecha) y = 0.8, # Centrada verticalmente orientation = &quot;v&quot; # Leyenda vertical ) ) fig fig_pot &lt;- plot_ly(datos, x = ~fecha, y = ~potencia, type=&quot;scatter&quot;, mode=&quot;lines&quot;, name=&quot;Potencia&quot;, line=list(color=&quot;blue&quot;)) fig_temp &lt;- plot_ly(datos, x = ~fecha, y = ~temp, type=&quot;scatter&quot;, mode=&quot;lines&quot;, name=&quot;Temperatura&quot;, line=list(color=&quot;red&quot;)) subplot( fig_pot, fig_temp, nrows = 2, shareX = TRUE, titleX = TRUE, titleY = TRUE ) %&gt;% layout(title = &quot;Series de Potencia y Temperatura&quot;) En la gráfica de potencia se observa: Picos pronunciados y caídas abruptas. A partir de 2022-2025 la serie parece tener un incremento estructural, posiblemente por crecimiento de la demanda, expansión de cargas, cambios climáticos, aumento de producción industrial/comercial. Existe un patrón ondulante, correspondiente a series horarias con estacionalidad diaria. La potencia eléctrica muestra estacionalidad diaria, tendencia creciente a lo largo de los años, ruido alto + picos pronunciados, caídas esporádicas (valores casi cero). En la gráfica de temperatura se observa: Curva completamente ondulante, repetitiva, con ciclos bien definidos. Se observan noches más frías, días más cálidos. La temperatura muestra un patrón regular y estable, ciclos repetitivos diarios, incrementos estacionales ligeros, no tiene valores atípicos extremos. Observando las gráficas superpuestas de potencia y temperatura se observa: Un patron sincronizado: cuando la temperatura sube, la Potencia sube; y cuando la temperatura baja, la Potencia baja. La potencia tiene un desfase mínimo respecto a la temperatura, lo que sugiere relación causal directa (climatización) y sensibilidad inmediata al calor. La temperatura máxima entre 11am–3pm coincide con picos de potencia. La temperatura mínima en madrugada coincide con mínimos de potencia. Correlación directa fuerte entre las variables a nivel diario, asociación creciente a medida que sube la carga base de la subestación, altas temperaturas inducen alta demanda eléctrica (principalmente por climatización). por lo tanto, se asumen que la señal de potencia combina demanda térmica (relación directa con temperatura) y demanda no térmica (ruido de operación, cargas industriales/comerciales). 7.5.2 Líneas suavizadas (LOESS - suavizamiento estimado localmente) # Gráfico con línea original + suavizado LOESS fig_loess &lt;- plot_ly() fig_loess &lt;- fig_loess %&gt;% add_lines( data = datos, x = ~fecha, y = ~potencia, name = &quot;Potencia&quot;, line = list(color = &quot;steelblue&quot;) ) %&gt;% add_lines( data = datos, x = ~fecha, y = ~fitted(loess(potencia ~ as.numeric(fecha), span = 0.1)), name = &quot;LOESS suavizado&quot;, line = list(color = &quot;red&quot;, width = 3) ) %&gt;% layout( title = &quot;Potencia con suavizado LOESS&quot;, xaxis = list(title = &quot;Fecha&quot;), yaxis = list(title = &quot;Potencia&quot;) ) fig_loess La curva de suavizado LOESS representa la tendencia real, libre de ruido, durante 2019–2025, se observa : Tendencia general creciente, debido tal vez al incremento sostenido de carga conectada, al aumento progresivo del consumo de hogares/industria o a mayor uso de equipos eléctricos. Comportamientos por periodos: 2019 – inicio de 2020, asciende rápidamente desde valores bajos (~0–1500 kW) hasta niveles más estables de 2500–2800 kW. 2020 – 2021, la demanda se mantiene relativamente estable entre 2700 y 3000 kW. 2022 – crecimiento moderado, se observa un incremento más claro hacia 3500–3800 kW. 2023 – ascenso fuerte, muestra mayor pendiente hacia niveles superiores a 4000 kW. 2024 - pico máximo estructural, el suavizado alcanza niveles cercanos a 4500–4800 kW. 2025 – estabilización, la curva parece estabilizarse o incluso reducirse ligeramente. La demanda eléctrica ha crecido de manera sostenida entre 2019 y La serie no es estacionaria, tiene tendencia creciente. La serie original tiene mucho ruido y valores atípicos, pero LOESS revela un patrón claro y robusto. El comportamiento refleja aumento creciente de carga instalada, mayor uso de equipos eléctricos, influencia significativa de la temperatura, efectos estacionales de larga duración. LOESS demuestra que se deben usar modelos de forecasting capaces de capturar tendencia, incorporar regresores externos (como temperatura), manejar alta variabilidad, soportar valores atípicos. 7.5.3 Promedios móviles datos$SMA_24 &lt;- zoo::rollmean(datos$potencia, k = 24, fill = NA) # móvil diario datos$SMA_168 &lt;- zoo::rollmean(datos$potencia, k = 24*7, fill = NA) # móvil semanal datos$EMA_24 &lt;- forecast::ma(datos$potencia, order = 24) # suavizado exponencial simple fig_ma &lt;- plot_ly() %&gt;% add_lines(data = datos, x = ~fecha, y = ~potencia, name = &quot;Potencia&quot;) %&gt;% add_lines(data = datos, x = ~fecha, y = ~SMA_24, name = &quot;SMA 24h&quot;, line=list(color=&quot;orange&quot;)) %&gt;% add_lines(data = datos, x = ~fecha, y = ~SMA_168, name = &quot;SMA 7 días&quot;, line=list(color=&quot;green&quot;)) %&gt;% add_lines(data = datos, x = ~fecha, y = ~EMA_24, name = &quot;EMA 24h&quot;, line=list(color=&quot;red&quot;)) %&gt;% layout( title = &quot;Promedios móviles (SMA y EMA)&quot;, xaxis = list(title = &quot;Fecha&quot;), yaxis = list(title = &quot;Potencia&quot;) ) fig_ma La gráfica del promedio simple de 24 horas, captura la tendencia de corto plazo, útil para comparar semanas o evaluar drásticamente cambios diarios promedio, en esta se observa: Ciclos diarios suavizados, los picos y valles del día se “aplanan”. Comportamiento semanal más claro, en los primeros años (2019–2021), la SMA24h muestra un nivel estable alrededor de 2500–3000 kW. Incremento gradual, la curva asciende principalmente hacia: 2022: ~3200–3500 kW 2023: ~3500–3800 kW 2024–2025: ~3800–4200 kW Eliminación parcial de valores atípicos. La gráfica del promedio simple de 7 días, es ideal para detectar cambios estructurales (cambio de carga base, estacionalidades climáticas semanales o picos sostenidos), en esta se observa: El suavizado elimina fluctuaciones interdiarias, resaltando variaciones inter-semanales. Cambio progresivo de carga: 2019–2021: demanda estable (2700–3100 kW) 2022–2023: demanda en ascenso (3100–3600 kW) 2024–2025: estabilización alrededor de 3800–4200 kW Desacople del ruido, permite ver mejor los cambios “reales” del sistema energético, aislados del ruido operativo y las variaciones diarias. La gráfica del promedio exponencial de 24 horas, es muy útil para detectar cambios rápidos en la demanda y para generar señales de alerta temprana en sistemas eléctricos, en esta se observa: Respuesta más rápida a incrementos y caídas. Al ser más sensible al comportamiento reciente, muestra aceleraciones en la tendencia, momentos donde la demanda aumenta más rápidamente, transiciones estacionales cortas. Se mantiene dentro del rango intermedio, no suaviza tanto como SMA 7 días, pero tampoco es tan ruidoso como la serie original. La serie presenta un crecimiento progresivo y robusto en la demanda eléctrica durante los últimos 6 años. El SMA 24h y SMA 7d confirman la existencia de incrementos escalonados, no de un crecimiento lineal. El EMA 24h detecta cambios rápidos en el sistema, revelando que la carga eléctrica es altamente sensible a variaciones de corto plazo (temperatura, actividad, eventos). En conjunto, los promedios móviles permiten aislar tendencias reales y no solo el ruido horario. 7.6 Correlación temperatura–potencia 7.6.1 Correlación dinámica temperatura–potencia Para ver cómo cambia la correlación temp–potencia en el tiempo. window &lt;- 24 * 7 # ventana de 1 semana, puedes ajustarla corr_ts &lt;- datos %&gt;% mutate( corr = slider::slide_dbl( .x = pick(potencia, temp), .f = ~ cor(.x$potencia, .x$temp, use = &quot;complete.obs&quot;), .before = window, .complete = FALSE ) ) fig_corr &lt;- corr_ts %&gt;% plot_ly(x = ~fecha, y = ~corr, type = &quot;scatter&quot;, mode = &quot;lines&quot;, line = list(color = &quot;purple&quot;)) %&gt;% layout( title = &quot;Correlación dinámica Potencia–Temperatura&quot;, xaxis = list(title = &quot;Fecha&quot;), yaxis = list(title = &quot;Correlación&quot;) ) fig_corr Es una serie temporal donde cada punto es la correlación entre potencia y temperatura, calculada en una ventana deslizante (7 días), a medida que avanza el tiempo, la correlación se actualiza con datos más recientes. Esto permite ver cómo cambia la relación entre temperatura y potencia a lo largo de los años. La correlación varía entre -0.6 y +0.4, esto indica que en algunos periodos, a mayor temperatura, mayor potencia, correlación positiva. En otros periodos, a mayor temperatura, menor potencia, correlación negativa. Esto es normal en sistemas eléctricos complejos porque la temperatura afecta algunas cargas (refrigeración, calefacción, equipos térmicos), pero otras cargas no térmicas (industria, comercio, alumbrado) operan independientemente de la temperatura. No hay una correlación estable, la relación no es constante; cambia según la estación del año, la hora del día, el tipo de carga conectada, el crecimiento de la demanda, los cambios climáticos y la variabilidad operativa. A partir de 2022 la correlación tiende a volverse más positiva, entre 2019 y 2021 la correlación está alrededor de 0, con fuertes oscilaciones. Desde 2022–2025 se observa un ligero sesgo hacia valores positivos (~0 a +0.3). Es decir, la demanda térmica (climatización) tiene mayor peso en los años recientes. Esto puede deberse al aumento de temperatura ambiental, mayor uso de equipos de enfriamiento, mayor actividad en horas de calor, expansión de carga sensible a temperatura. 7.6.2 Matriz de dispersión y correlación global (temperatura–potencia) datos %&gt;% GGally::ggpairs(columns = 2:3) La correlación de Pearson global es de 0.043. La Correlación global es extremadamente baja, es decir la temperatura no explica bien la potencia cuando se observa a nivel global (2019–2025). la gráfica de dispersión está muy dispersa, los puntos no forman una nube inclinada clara: La potencia varía entre 0 y ~6000 sin un patrón definido. La temperatura se mantiene entre ~17 y 35°C. Se observa el efecto de outliers de potencia = 0, los puntos en cero (caídas abruptas) afectan fuertemente la correlación global al reducir la linealidad, generar valores extremos que distorsionan la relación. La correlación global (0.043) es casi nula, la temperatura NO explica toda la potencia a nivel macro (2019–2025). La correlación dinámica revela ventanas donde la temperatura sí tiene impacto, especialmente en 2022–2025, cuando el sistema energético es más sensible al calor. El análisis dinámico captura información que un análisis global no puede, de allí la importancia de mirar correlación móvil y no solo correlación simple. El análisis muestra que la relación entre la temperatura y la potencia eléctrica no es estable ni constante a lo largo de los años. Cuando se observa toda la serie completa (2019–2025), la correlación entre temperatura y potencia es casi cero, lo que significa que, a gran escala, la temperatura por sí sola no explica toda la variación de la potencia. Sin embargo, cuando analizamos la correlación de manera dinámica (por ventanas de tiempo más pequeñas), encontramos momentos en los que sí existe una relación clara: En algunos periodos, cuando la temperatura sube, también aumenta la potencia. En otros periodos, sucede lo contrario. A partir de 2022, la relación positiva entre temperatura y potencia se vuelve más frecuente. Esto quiere decir que la temperatura sí influye en la demanda eléctrica, pero su impacto cambia con el tiempo, dependiendo de la estación, el año y las condiciones de uso de la energía. En resumen, la temperatura sí influye en la potencia eléctrica, pero no de forma simple ni constante. La demanda eléctrica depende de muchos factores, además del clima. Los modelos más flexibles (como Prophet con temperatura) son los que mejor se adaptan a estos cambios y ofrecen mejores pronósticos. Las relaciones entre temperatura y demanda deben analizarse en ventanas de tiempo, no solo con un promedio global, porque la realidad cambia día a día. 7.7 Conversión a tsibble Conversión de data frame en una estructura de serie temporal moderna (llamada )tsibble). datos_ts &lt;- datos %&gt;% as_tsibble(index = fecha) datos_ts ## # A tsibble: 58,448 x 6 [1h] &lt;UTC&gt; ## fecha temp potencia SMA_24 SMA_168 EMA_24 ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2019-01-01 00:00:00 21.9 778. NA NA NA ## 2 2019-01-01 01:00:00 20.5 766. NA NA NA ## 3 2019-01-01 02:00:00 19.4 765. NA NA NA ## 4 2019-01-01 03:00:00 18.2 735. NA NA NA ## 5 2019-01-01 04:00:00 18.1 731. NA NA NA ## 6 2019-01-01 05:00:00 20.7 736. NA NA NA ## 7 2019-01-01 06:00:00 20.5 726. NA NA NA ## 8 2019-01-01 07:00:00 20.7 712. NA NA NA ## 9 2019-01-01 08:00:00 21.8 712. NA NA NA ## 10 2019-01-01 09:00:00 27.7 712. NA NA NA ## # ℹ 58,438 more rows interval(datos_ts) ## &lt;interval[1]&gt; ## [1] 1h 7.8 Descomposición clásica Se realiza la descomposición clásica utilizando una frecuencia diaria: datos_ts_diario &lt;- datos_ts %&gt;% mutate(dia = as_date(fecha)) %&gt;% index_by(dia) %&gt;% summarise(potencia = mean(potencia, na.rm = TRUE)) datos_ts_diario %&gt;% model(STL(potencia ~ season(window = &quot;periodic&quot;))) %&gt;% components() %&gt;% autoplot() + labs(title = &quot;Descomposición STL de la potencia (promedio diario)&quot;) Esta descomposición separa la serie en: Tendencia (trend) Estacionalidad anual (season_year) Estacionalidad semanal (season_week) Residuo (remainder) Serie original: Se observa variabilidad considerable pero mucho más suave que la serie horaria, incremento claro desde 2019 hasta 2024, algunos días con caídas notorias (picos hacia abajo), probablemente por fallos o mantenimientos. El valor promedio estabilizado en niveles más altos a partir de 2023–2024. Tendencia: Se observa Crecimiento continuo (2019–2024), ligera caída o estabilización en 2025. La demanda promedio diaria de la subestación ha aumentado de manera sostenida, y el 2024 fue el año de mayor carga. Estacionalidad anual: Se observa oscilación clara con picos y valles repetitivos, esto indica que en ciertos meses (épocas cálidas), la potencia promedio aumenta y en meses más fríos o lluviosos: la potencia disminuye. Estacionalidad semanal: Se observa una onda casi perfecta semanal, prácticamente es un ciclo idéntico semana tras semana en todos los años. Residuo: La gráfica muestra lo que queda después de remover tendencia + estacionalidad anual + estacionalidad semanal. Refleja ruido operativo, variaciones abruptas del sistema, días atípicos o fallas, eventos puntuales no explicados por clima ni comportamiento habitual. Tambien se observan caídas fuertes en días aislados, debido posiblemente a fallas o apagones puntuales, mediciones erróneas, desconexiones programadas. La demanda eléctrica tiene un comportamiento altamente estructurado, sigue patrones muy claros y estables. Hay tres componentes que explican casi todo el comportamiento: Tendencia creciente (más usuarios, más actividad, más calor, más uso eléctrico) Estacionalidad anual marcada (cambios de clima y temporadas) Estacionalidad semanal fuerte (actividad laboral) El residuo recoge pocas irregularidades, es ruido + eventos puntuales. El sistema eléctrico ha crecido año tras año, la carga base de la subestación es mucho mayor en 2023–2024 que en 2019–2020. 7.9 División de los datos en entrenamiento y prueba Se reserva un subconjunto final de la serie para evaluar la capacidad predictiva de los modelos. Los ultimos 6 meses se utilizan para la prueba de los modelos. n_total &lt;- nrow(datos_ts) n_test &lt;- 24 * 30 * 6 # 6 meses n_train &lt;- n_total - n_test datos_train &lt;- datos_ts %&gt;% slice(1:n_train) datos_test &lt;- datos_ts %&gt;% slice((n_train + 1):n_total) # Índices numéricos para Prophet original idx_train &lt;- 1:n_train idx_test &lt;- (n_train + 1):n_total cat(&quot;Cantidad total de datos: &quot;, n_total, &quot;\\n&quot;) ## Cantidad total de datos: 58448 cat(&quot;Cantidad de datos para entrenamiento: &quot;, n_train, &quot;\\n&quot;) ## Cantidad de datos para entrenamiento: 54128 cat(&quot;Cantidad de datos para prueba: &quot;, n_test, &quot;\\n&quot;) ## Cantidad de datos para prueba: 4320 7.10 Ajuste de modelos ARIMA, ETS y Prophet En esta sección se ajustan tres modelos sobre el conjunto de entrenamiento: ARIMA: modelo autorregresivo integrado de medias móviles. ETS: modelo de suavizamiento exponencial (Error, Trend, Seasonality). Prophet: modelo de regresión no lineal en el tiempo. 7.10.1 Modelos fable: ARIMAX (con temp) + ETS (sin regresor) # Modelos dentro de fable: # - ARIMA con regresor externo (temp) # - ETS sin regresor modelos_fable &lt;- datos_train %&gt;% model( arima_x = ARIMA(potencia ~ temp), # ARIMAX con regresor externo (temp) ets = ETS(potencia) # ETS no admite regresores externos ) #report(modelos_fable) modelos_fable %&gt;% select(arima_x) %&gt;% report() ## Series: potencia ## Model: LM w/ ARIMA(3,0,1)(2,1,0)[24] errors ## ## Coefficients: ## ar1 ar2 ar3 ma1 sar1 sar2 temp ## 1.3521 -0.5501 0.1302 -0.3252 -0.6372 -0.3175 4.9116 ## s.e. 0.0417 0.0416 0.0060 0.0420 0.0041 0.0041 0.9428 ## ## sigma^2 estimated as 25373: log likelihood=-351119.5 ## AIC=702254.9 AICc=702254.9 BIC=702326.1 Modelo ARIMAX: ARIMA(3,0,1)(2,1,0)[24] con regresor temperatura Este modelo combina: Componente autorregresiva AR(3) Componente de media móvil MA(1) Componente estacional SAR(2) con período 24 Una diferenciación estacional D=1 Un regresor externo: la temperatura modelos_fable %&gt;% select(ets) %&gt;% report() ## Series: potencia ## Model: ETS(A,N,A) ## Smoothing parameters: ## alpha = 0.9658659 ## gamma = 0.02173433 ## ## Initial states: ## l[0] s[0] s[-1] s[-2] s[-3] s[-4] s[-5] s[-6] ## 737.5383 575.079 602.6087 495.9476 379.6667 204.5187 -112.6017 -48.92082 ## s[-7] s[-8] s[-9] s[-10] s[-11] s[-12] s[-13] s[-14] ## 52.16891 80.52854 -51.76333 -234.5562 -215.375 -285.13 -345.7436 -402.4462 ## s[-15] s[-16] s[-17] s[-18] s[-19] s[-20] s[-21] s[-22] ## -490.6121 -452.1371 -283.8625 -151.7084 -74.77285 18.19228 127.8915 262.7413 ## s[-23] ## 350.2864 ## ## sigma^2: 23639.88 ## ## AIC AICc BIC ## 1135081 1135081 1135321 Modelo ETS(A,N,A) Este es un modelo de: Error aditivo (A) Sin tendencia (N) Estacionalidad aditiva (A) Parámetros de suavizamiento: α (alpha) = 0.9659, El modelo da mucho peso a las observaciones recientes, casi reaccionando punto a punto. El nivel cambia muy rápido. γ (gamma) = 0.0217, la estacionalidad cambia muy lentamente. 7.10.2 Prophet con regresor temp (NO fable) Aquí usamos el paquete prophet de Facebook (no el de fable.prophet) para poder incluir temp como regresor. # Data frame de entrenamiento para Prophet: ds (fecha), y (potencia), temp (regresor) df_train_prophet &lt;- datos %&gt;% slice(idx_train) %&gt;% transmute( ds = fecha, y = potencia, temp = temp ) # Definir modelo Prophet con regresor externo temp m_prophet &lt;- prophet() m_prophet &lt;- add_regressor(m_prophet, &#39;temp&#39;) # Ajustar el modelo m_prophet &lt;- fit.prophet(m_prophet, df_train_prophet) # Data frame de TEST para Prophet (mismas fechas que datos_test) df_test_prophet &lt;- datos %&gt;% slice(idx_test) %&gt;% transmute( ds = fecha, temp = temp ) # Pronóstico de Prophet sobre el periodo de TEST fc_prophet_test &lt;- predict(m_prophet, df_test_prophet) head(fc_prophet_test) ## ds trend additive_terms additive_terms_lower ## 1 2025-03-05 08:00:00 4398.593 -267.15895 -267.15895 ## 2 2025-03-05 09:00:00 4398.602 -197.32202 -197.32202 ## 3 2025-03-05 10:00:00 4398.611 -146.77776 -146.77776 ## 4 2025-03-05 11:00:00 4398.620 -74.43053 -74.43053 ## 5 2025-03-05 12:00:00 4398.629 -17.25649 -17.25649 ## 6 2025-03-05 13:00:00 4398.638 -40.84672 -40.84672 ## additive_terms_upper daily daily_lower daily_upper ## 1 -267.15895 -411.5955 -411.5955 -411.5955 ## 2 -197.32202 -443.6572 -443.6572 -443.6572 ## 3 -146.77776 -450.8788 -450.8788 -450.8788 ## 4 -74.43053 -448.8877 -448.8877 -448.8877 ## 5 -17.25649 -424.2324 -424.2324 -424.2324 ## 6 -40.84672 -360.5613 -360.5613 -360.5613 ## extra_regressors_additive extra_regressors_additive_lower ## 1 -81.81078 -81.81078 ## 2 19.03749 19.03749 ## 3 75.76464 75.76464 ## 4 145.09782 145.09782 ## 5 176.61291 176.61291 ## 6 88.37067 88.37067 ## extra_regressors_additive_upper temp temp_lower temp_upper weekly ## 1 -81.81078 -81.81078 -81.81078 -81.81078 21.98357 ## 2 19.03749 19.03749 19.03749 19.03749 22.78723 ## 3 75.76464 75.76464 75.76464 75.76464 23.58068 ## 4 145.09782 145.09782 145.09782 145.09782 24.35992 ## 5 176.61291 176.61291 176.61291 176.61291 25.12131 ## 6 88.37067 88.37067 88.37067 88.37067 25.86155 ## weekly_lower weekly_upper yearly yearly_lower yearly_upper ## 1 21.98357 21.98357 204.2638 204.2638 204.2638 ## 2 22.78723 22.78723 204.5105 204.5105 204.5105 ## 3 23.58068 23.58068 204.7557 204.7557 204.7557 ## 4 24.35992 24.35992 204.9995 204.9995 204.9995 ## 5 25.12131 25.12131 205.2417 205.2417 205.2417 ## 6 25.86155 25.86155 205.4823 205.4823 205.4823 ## multiplicative_terms multiplicative_terms_lower multiplicative_terms_upper ## 1 0 0 0 ## 2 0 0 0 ## 3 0 0 0 ## 4 0 0 0 ## 5 0 0 0 ## 6 0 0 0 ## yhat_lower yhat_upper trend_lower trend_upper yhat ## 1 3602.274 4647.963 4398.593 4398.593 4131.434 ## 2 3706.877 4747.568 4398.602 4398.602 4201.280 ## 3 3708.027 4781.216 4398.611 4398.611 4251.833 ## 4 3812.201 4843.178 4398.620 4398.620 4324.189 ## 5 3864.574 4917.284 4398.629 4398.629 4381.372 ## 6 3856.914 4838.161 4398.638 4398.638 4357.791 Prophet descompone el pronóstico en: trend → tendencia general a largo plazo daily → patrón diario (sube en horas de mayor actividad, baja en madrugada) weekly → patrón semanal (días laborales vs. fines de semana) yearly → patrón estacional anual (clima/temporada) extra_regressors_additive → efecto de la temperatura additive_terms → suma de daily + weekly + yearly + regresores yhat → valor pronosticado final yhat_lower / yhat_upper → intervalo de confianza yhat=trend+daily+weekly+yearly+regressors+remainder La tendencia muestra que la demanda en 2025 es alta, rondando los 4400 kW. A primera hora (8am), la demanda es relativamente baja, pero sube rápidamente hacia el mediodía. La temperatura juega un papel importante, cuando sube, la potencia aumenta significativamente (entre +75 y +176 kW). La estacionalidad semanal y anual agregan una contribución positiva estable. Prophet interpreta que en esa fecha (pronóstico) la demanda eléctrica estará subiendo durante la mañana, impulsada sobre todo por el calor del día y el patrón típico diario. 7.11 Pronósticos y comparación de métricas Ahora generamos pronósticos para el mismo horizonte de datos_test con: ARIMAX + ETS vía fable Prophet con regresor temp # 4.1 Pronósticos fable en TEST (usando datos_test como new_data) fc_fable_test &lt;- modelos_fable %&gt;% forecast(new_data = datos_test) # Métricas para modelos fable (ARIMAX y ETS) acc_fable &lt;- fc_fable_test %&gt;% accuracy(datos_test) %&gt;% filter(.type == &quot;Test&quot;) %&gt;% select(.model, RMSE, MAE, MAPE) #acc_fable # 4.2 Métricas para Prophet original con temp # Observado (y_real) y pronosticado (yhat_prophet) en TEST # 4.2 Métricas para Prophet original con temp # Observado (y_real) y pronosticado (y_hat_p) en TEST y_real &lt;- datos$potencia[idx_test] y_hat_p &lt;- fc_prophet_test$yhat # Construimos un data frame para yardstick df_eval_prophet &lt;- tibble( truth = y_real, estimate = y_hat_p ) # Usar SIEMPRE las funciones de yardstick, con namespace explícito rmse_p &lt;- yardstick::rmse( df_eval_prophet, truth = truth, estimate = estimate )$.estimate mae_p &lt;- yardstick::mae( df_eval_prophet, truth = truth, estimate = estimate )$.estimate mape_p &lt;- yardstick::mape( df_eval_prophet, truth = truth, estimate = estimate )$.estimate * 100 acc_prophet &lt;- tibble( .model = &quot;prophet_x_temp&quot;, RMSE = rmse_p, MAE = mae_p, MAPE = mape_p ) RMSE (Root Mean Square Error): mide el error cuadrático promedio. Penaliza fuertemente errores grandes. MAE (Mean Absolute Error): mide el error absoluto promedio. Más fácil de interpretar. MAPE (Mean Absolute Percentage Error): mide error porcentual, pero cuando la serie tiene valores cercanos a cero, se vuelve inválido (por eso aparece “Inf”). Prophet(temp) es el mejor modelo, tiene las métricas más bajas, (RMSE=477.23) y (MAE=316.46). Esto indica que Prophet con temperatura: Produce pronósticos más cercanos a los valores reales. Captura mejor los patrones de la serie (tendencias + estacionalidades). Incorpora de manera efectiva la variable externa temperatura. Maneja bien las fluctuaciones y picos. ETS tuvo un desempeño aceptable, pero al no usar temperatura, no puede competir con Prophet. ARIMA con temperatura fue el menos preciso, probablemente porque la serie es demasiado variable y estacional para un ARIMA clásico. 7.11.1 Comparación gráfica de los pronósticos Unimos pronósticos de ARIMAX, ETS y Prophet (con temp) sobre el conjunto de prueba y los visualizamos junto con los datos reales de potencia. # Rango de fechas del TEST inicio_test &lt;- min(datos_test$fecha) fin_test &lt;- max(datos_test$fecha) # Preparar pronósticos fable en formato largo fc_fable_long &lt;- fc_fable_test %&gt;% as_tibble() %&gt;% select(fecha = fecha, .model, .mean) # Preparar pronósticos Prophet en el mismo formato fc_prophet_long &lt;- tibble( fecha = df_test_prophet$ds, .model = &quot;prophet_x_temp&quot;, .mean = y_hat_p ) # Unir todos los pronósticos fc_todos &lt;- bind_rows( fc_fable_long, fc_prophet_long ) # Datos reales en TEST datos_test_df &lt;- datos %&gt;% slice(idx_test) %&gt;% select(fecha, potencia) # Gráfico interactivo fig_fc &lt;- plot_ly() # Serie real fig_fc &lt;- fig_fc %&gt;% add_lines( data = datos_test_df, x = ~fecha, y = ~potencia, name = &quot;Real&quot;, line = list(color = &quot;black&quot;) ) # ARIMAX y ETS fig_fc &lt;- fig_fc %&gt;% add_lines( data = fc_todos %&gt;% filter(.model == &quot;arima_x&quot;), x = ~fecha, y = ~.mean, name = &quot;ARIMAX (temp)&quot;, line = list(color = &quot;blue&quot;) ) %&gt;% add_lines( data = fc_todos %&gt;% filter(.model == &quot;ets&quot;), x = ~fecha, y = ~.mean, name = &quot;ETS&quot;, line = list(color = &quot;green&quot;) ) # Prophet con temp fig_fc &lt;- fig_fc %&gt;% add_lines( data = fc_todos %&gt;% filter(.model == &quot;prophet_x_temp&quot;), x = ~fecha, y = ~.mean, name = &quot;Prophet (temp)&quot;, line = list(color = &quot;red&quot;) ) fig_fc &lt;- fig_fc %&gt;% layout( title = &quot;Comparación de Pronósticos en TEST: ARIMAX(temp), ETS y Prophet(temp)&quot;, xaxis = list(title = &quot;Fecha&quot;), yaxis = list(title = &quot;Potencia&quot;), legend = list(x = 1.05, y = 0.5) ) fig_fc Prophet(temp) modela muy bien la forma general de los ciclos diarios y semanales, y ajusta la influencia de la temperatura, pero no reproduce fluctuaciones extremas. Es el modelo más estable y con mejor error promedio (RMSE y MAE). Prophet(temp) es el modelo que mejor reproduce el comportamiento real del sistema eléctrico, esto se debe a que captura múltiples estacionalidades (diaria, semanal, anual), integra la temperatura como regresor externo, se ajusta rápidamente a cambios en el nivel de la demanda, suaviza correctamente el ruido sin perder la forma del ciclo. ETS captura la estacionalidad diaria pero le cuesta adaptarse a variaciones rápidas. Funciona bien para detectar patrones estables pero no para fluctuaciones intensas. ETS ocupa un segundo lugar, captura el patrón diario, pero no usa temperatura, tiene menos flexibilidad. ARIMAX(temp) logra capturar estacionalidad diaria, pero falla en ajustar tendencias o cambios estructurales del sistema. Es el modelo que peor se adapta al periodo de prueba (más alto RMSE y MAE). ARIMAX(temp) queda en tercer lugar, aunque incorpora temperatura, no logra captar bien la variación real ni cambios repentinos, su estacionalidad es rígida y menos adaptativa. 7.12 Diagnóstico de residuos Prophet # 1. Obtener valores ajustados en TRAIN usando predict() # (usamos las mismas filas y regresores que df_train_prophet) future_train &lt;- df_train_prophet %&gt;% select(ds, temp) fc_train_prophet &lt;- predict(m_prophet, future_train) # 2. Cálculo de residuos en TRAIN y_real_train &lt;- df_train_prophet$y y_fitted &lt;- fc_train_prophet$yhat res_prophet &lt;- y_real_train - y_fitted # 3. Convertir a tibble con fecha df_res_prophet &lt;- tibble( fecha = df_train_prophet$ds, residuo = res_prophet ) # 4. Gráficos de diagnóstico p1 &lt;- ggplot(df_res_prophet, aes(x = fecha, y = residuo)) + geom_line(color = &quot;steelblue&quot;) + labs(title = &quot;Residuos del modelo Prophet(temp)&quot;, x = &quot;Fecha&quot;, y = &quot;Residuo&quot;) p2 &lt;- ggplot(df_res_prophet, aes(x = residuo)) + geom_histogram(bins = 40, fill = &quot;gray70&quot;, color = &quot;black&quot;) + labs(title = &quot;Histograma de residuos Prophet(temp)&quot;) p3 &lt;- ggAcf(df_res_prophet$residuo) + labs(title = &quot;ACF de residuos Prophet(temp)&quot;) p4 &lt;- ggPacf(df_res_prophet$residuo) + labs(title = &quot;PACF de residuos Prophet(temp)&quot;) p5 &lt;- ggplot(df_res_prophet, aes(sample = residuo)) + stat_qq() + stat_qq_line() + labs(title = &quot;QQ-Plot residuos Prophet(temp)&quot;) # 5. Prueba de Ljung-Box (ejemplo con 24 rezagos) lb &lt;- Box.test(df_res_prophet$residuo, lag = 24, type = &quot;Ljung-Box&quot;) lb ## ## Box-Ljung test ## ## data: df_res_prophet$residuo ## X-squared = 353631, df = 24, p-value &lt; 2.2e-16 # Mostrar gráficos (puedes organizarlos como prefieras) p1 p2 p3 p4 p5 Serie temporal de residuos: permite ver patrones no capturados: Prophet(temp) captura la tendencia general y la forma diaria/semanal, pero no explica bien valores atípicos, no modela eventos anómalos (cortes, mantenimientos) y queda ruido significativo sin explicar, como ocurre en series energéticas reales. Histograma: evalúa normalidad: No hay normalidad perfecta. La cola izquierda larga indica días con demanda real anormalmente baja, errores grandes por valores reales cercanos a cero. El modelo tiende a sobreestimar en estos episodios. ACF / PACF: evalúa autocorrelación; ruido blanco es lo deseable: De la gráfica ACF se interpeta que los residuos no son ruido blanco. Prophet(temp) captura bien parte de la estacionalidad, pero no elimina completamente la dependencia temporal. Esto ocurre porque la serie tiene estacionalidad horaria MUY intensa, Prophet usa Fourier para estacionalidad diaria pero no siempre capta ciclos exactos hora a hora. El modelo aún deja información rutinaria sin explicar. De la gráfica PACF se confirma la presencia de autocorrelación estructural. Prophet(temp) no elimina la memoria de la serie, porque la serie horaria es extremadamente autocorrelacionada, la estacionalidad diaria es compleja. QQ-plot: inspección visual de normalidad: Los residuos NO son normales. La asimetría se debe a valores reales extremadamente bajos (≈ 0), picos altos que tampoco son siempre capturados, alta variabilidad intradía no totalmente modelada. Prophet(temp) cumple su función de tendencia + estacionalidad + regresor, pero la serie contiene outliers y ruido estructurado que no encajan con supuestos normales. Ljung–Box: evalúa si quedan patrones no explicados (H0 = residuos sin autocorrelación): p-value &lt; 2.2e–16 (extremadamente pequeño), rechazamos con claridad la hipótesis nula del test. Los residuos NO son ruido blanco. Los residuos del modelo Prophet(temp) muestran que el modelo captura bien la tendencia y las estacionalidades, pero aún deja patrones no explicados. Persisten autocorrelaciones altas, especialmente a nivel horario y diario, y la distribución de los errores tiene colas pesadas por eventos atípicos en la demanda. En consecuencia, aunque Prophet(temp) ofrece los mejores pronósticos entre los modelos evaluados, sus residuos no son completamente aleatorios, lo cual es normal en series eléctricas reales con alta variabilidad y picos extremos. 7.12.1 Resumen numérico de residuos (media, sd, skewness, kurtosis) # 1. Residuos ARIMAX y ETS desde modelos_fable res_fable &lt;- modelos_fable %&gt;% augment() %&gt;% # agrega .fitted, .resid, .innov, etc. as_tibble() # Seleccionamos solo lo necesario res_fable_long &lt;- res_fable %&gt;% select(.model, fecha, resid = .resid) # 2. Residuos Prophet(temp) desde df_res_prophet (creado en el chunk anterior) res_prophet_tbl &lt;- df_res_prophet %&gt;% transmute( .model = &quot;prophet_x_temp&quot;, fecha, resid = residuo ) # 3. Unimos todos los residuos resid_all &lt;- bind_rows( res_fable_long, res_prophet_tbl ) # 4. Resumen numérico: media, sd, skewness, kurtosis resumen_residuos &lt;- resid_all %&gt;% group_by(.model) %&gt;% summarise( mean = mean(resid, na.rm = TRUE), sd = sd(resid, na.rm = TRUE), skew = moments::skewness(resid, na.rm = TRUE), kurt = moments::kurtosis(resid, na.rm = TRUE), .groups = &quot;drop&quot; ) resumen_residuos %&gt;% mutate( mean = round(mean, 2), sd = round(sd, 2), skew = round(skew, 3), kurt = round(kurt, 3) ) %&gt;% knitr::kable( caption = &quot;Resumen numérico de residuos: ARIMAX(temp), ETS y Prophet(temp)&quot;, digits = 2 ) Table 7.1: Resumen numérico de residuos: ARIMAX(temp), ETS y Prophet(temp) .model mean sd skew kurt arima_x 0.35 159.24 -0.79 105.58 ets 0.07 153.72 -0.31 146.19 prophet_x_temp -0.01 400.23 -2.37 17.29 mean: media del residuo (ideal ~ 0): Todos los promedios son cercanos a 0. Los tres modelos no presentan sesgo sistemático sd: desviación estándar: ETS tiene menor dispersión, mientras que Prophet(temp) tiene la más alta. Prophet suaviza la serie cuando la serie real tiene picos o desplomes extremos, los residuos se vuelven muy grandes. Prophet evita sobreajustar picos extremos. skew: asimetría (0 ≈ distribución simétrica): arima_x (ligera cola hacia errores negativos), ETS (casi simétrico), prophet_x_temp (fuerte cola negativa (muchos errores negativos grandes)). Prophet tiene fuerte skew negativo porque no predice caídas inesperadas, lo cual es normal y esperable. kurt: curtosis (3 ≈ normal; &gt;3 colas más pesadas): los residuos de ARIMAX y ETS tienen muchísimos valores atípicos, errores extremos frecuentes, sensibilidad alta al ruido de la serie. Prophet, en cambio suaviza, no persigue los picos extremos, produce residuos menos extremos.Prophet(temp) presenta una mejor distribución, con menos outliers extremos comparado con ETS y ARIMA. Prophet(temp) es el modelo con mejor comportamiento global en residuos, pues aunque su desviación estándar es mayor, su distribución es mucho más razonable (baja curtosis) y su media es prácticamente cero. ETS y ARIMAX tienen residuos menos dispersos, pero con colas extremadamente pesadas, lo cual indica que producen errores extremos con mucha frecuencia. En modelos de series energéticas —con picos y caídas bruscas— esto favorece a Prophet, que maneja mejor la forma general del proceso y evita el sobreajuste. 7.12.2 Comparación gráfica de residuos (ARIMAX, ETS, Prophet) library(ggplot2) # Usamos el mismo objeto resid_all del chunk anterior # (si quieres que este chunk sea independiente, # copia también la construcción de resid_all aquí) p_res &lt;- ggplot(resid_all, aes(x = fecha, y = resid)) + geom_line(color = &quot;steelblue&quot;) + facet_wrap(~ .model, ncol = 1, scales = &quot;free_y&quot;) + labs( title = &quot;Comparación de residuos: ARIMAX(temp), ETS y Prophet(temp)&quot;, x = &quot;Fecha&quot;, y = &quot;Residuo&quot; ) + theme_minimal() p_res El análisis visual de los residuos muestra que ningún modelo captura completamente la dinámica de la serie, lo cual es normal en datos eléctricos horarios. Sin embargo, Prophet(temp) presenta el mejor comportamiento global: Menor cantidad de outliers extremos respecto a ETS y ARIMA. Residuos más estables a largo plazo. Mejor adaptación a cambios estructurales, aunque con picos negativos severos cuando la serie real cae abruptamente. ETS y ARIMAX(temp) generan residuos más ruidosos y con picos más frecuentes, señal de que no modelan adecuadamente toda la estructura temporal ni los efectos externos. 7.13 Conclusiones Los resultados obtenidos en este ejercicio, donde se compararon tres enfoques de modelamiento —ARIMAX con temperatura como regresor, ETS univariante y Prophet con regresor externo— permiten desarrollar conclusiones desde las métricas: El RMSE sugiere que Prophet con temperatura como regresor externo fue el mejor modelo, seguido por ETS y, en último lugar, el modelo ARIMAX. Sin embargo, el MAPE resultó infinito en los tres modelos, lo que se explica por la presencia de valores extremadamente bajos (cercanos a cero) en la demanda real durante el periodo de evaluación, haciendo imposible calcular correctamente el error porcentual. Dado este comportamiento, el RMSE y el MAE son métricas más apropiadas para esta serie. Bajo estas métricas, Prophet(temp) se posiciona como el modelo más preciso en el periodo analizado. El modelo ARIMAX obtuvo la siguiente especificación: ARIMA(3,0,1)(2,1,0)[24] con un regresor externo temp β_temp = 4.91, altamente significativo Esto sugiere que, en promedio, un aumento de 1°C en la temperatura produce un aumento esperado de 4.9 unidades en la potencia, manteniendo constantes los efectos temporales capturados por el ARIMA. Este resultado indica que la temperatura sí posee un efecto directo sobre la serie, aunque la magnitud del coeficiente debe interpretarse en el contexto de los niveles de potencia. Por su parte, ETS(A,N,A) mostró una estructura suave y flexible, pero su desempeño en TEST fue inferior a Prophet(temp) y mayormente influido por la fuerte variabilidad de la serie. Prophet(temp) logró capturar tendencias y estacionalidades con mayor estabilidad, especialmente ante eventos abruptos. Su estructura aditiva y su capacidad para incorporar regresores externos favorecieron un mejor ajuste al comportamiento real durante el horizonte de prueba. El análisis de residuos del modelo Prophet(temp) mostró: Residuos con distribución aproximadamente simétrica. Presencia de autocorrelación moderada, aunque menor que en ARIMAX. QQ-plot con colas más pesadas de lo esperado, lo que refleja la alta variabilidad de la serie. Ljung–Box significativo en varios rezagos, indicando que aún quedan patrones no capturados por el modelo. A pesar de estas limitaciones, Prophet(temp) produjo los residuos más estables y homogéneos entre los tres modelos, lo cual coincide con su mejor desempeño en RMSE y MAE. La inclusión de la temperatura como variable explicativa mostró ser relevante, tanto en Prophet como en ARIMAX, aunque la capacidad de Prophet para modelar tendencias no lineales y estacionalidades complejas lo hizo más robusto para este conjunto de datos. Es importante destacar que la serie contiene valores atípicos y caídas abruptas cercanas a cero, lo cual afecta la estabilidad del MAPE y dificulta la estimación de modelos puramente aditivos. En conjunto, se concluye que Prophet con temperatura como regresor externo es el modelo más adecuado para el pronóstico de potencia eléctrica en este caso específico, dada su mayor estabilidad, menor error cuadrático y mejor manejo de la alta variabilidad y de los patrones abruptos presentes en la serie. No obstante, el ARIMAX(temp) proporciona información valiosa sobre el efecto directo de la temperatura, mientras que ETS constituye una alternativa simple y robusta en contextos de menor variabilidad. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
