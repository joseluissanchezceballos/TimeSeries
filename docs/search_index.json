[["index.html", "Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos 1 Presentación del Bookdown", " Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos Fredy A. Ordoñez · Oscar F. Velásquez · José L. Sánchez 03 de noviembre de 2025 1 Presentación del Bookdown Este Bookdown recopila las actividades desarrolladas a lo largo del curso de Series de Tiempo. Cada capítulo corresponde a una entrega o avance del proyecto, permitiendo evidenciar el progreso del análisis, los modelos aplicados y las conclusiones del trabajo final. ## NULL "],["propuesta.html", "2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? 2.2 ¿Por qué es importante? 2.3 Fuente de datos y permisos 2.4 Impacto esperado 2.5 Referencias", " 2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? La demanda eléctrica de corto plazo (1 hora adelante) en una subestación de distribución, usando la serie de potencia activa (kW) con resolución horaria. 2.2 ¿Por qué es importante? Operación eficiente: anticipar picos para evitar sobrecargas y maniobras reactivas. Calidad del servicio (SAIDI/SAIFI): programar mantenimientos y gestionar eventos reduciendo frecuencia y duración de interrupciones.SAIFI (System Average Interruption Frequency Index) indica la frecuencia promedio de las interrupciones que un cliente experimenta en un período determinado (por ejemplo, cuántas veces se va la luz al año), y el SAIDI (System Average Interruption Duration Index) mide la duración promedio acumulada de esas interrupciones para un cliente en ese mismo período (cuánto tiempo en total está sin servicio). Valor agregado: entregar una plantilla reproducible (scripts, métricas y gráficos) que soporte decisiones operativas. 2.3 Fuente de datos y permisos Fuente: datos SCADA históricos del operador de red de una subestación específica resolución horaria. Permisos: uso académico con anonimización de subestación y operador; no se publican datos crudos, solo resultados agregados y visualizaciones. Alcance: una subestación; análisis offline (sin integración en tiempo real). 2.4 Impacto esperado Técnico: reducción de error frente a métodos manuales; soporte a decisiones en turnos. Económico: mejor dimensionamiento de respaldo y diferimiento de inversiones. Académico: caso replicable en otras subestaciones con datos equivalentes. 2.5 Referencias Hyndman, R. &amp; Athanasopoulos (2018). Forecasting: Principles and Practice (3ª). Box, G. et al. (2015). Time Series Analysis: Forecasting and Control (5ª). Zhang, H. et al. (2019). “Short-term Load Forecasting Using LSTM Networks”, IEEE TSG. Herramienta TIC: Bookdown + GitHub Pages Sitio: https://joseluissanchezceballos.github.io/TimeSeries/propuesta.html Repo: https://github.com/joseluissanchezceballos/TimeSeries "],["análisis-de-serie-de-tiempo-potencia-eléctrica-horaria.html", "3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos 3.2 Cargue de Librerías 3.3 Lectura y preparación de los datos 3.4 Funciones auxiliares de visualización de la serie de tiempo 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) 3.7 Promedios móviles 3.8 Rezagos (lags) y autocorrelación 3.9 Estacionalidad (gráficos y descomposición) 3.10 Indicadores resumidos 3.11 Conclusiones", " 3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos El estudio analiza una serie temporal de potencia eléctrica horaria entre 2018 y 2025. El objetivo fue detectar patrones, ciclos y estacionalidades usando herramientas de R (lubridate, zoo, forecast) y visualizar la calidad de los datos (huecos, tendencias, estacionalidad, rezagos). El conjunto de datos es altamente completo: Completitud global: 99.48%. Años con menos completitud: 2019 (97.9%) y 2021 (99.4%). Años recientes (2022–2025): 100% de registros, sin huecos. La idea es detectar patrones y ciclos del comportamiento de la potencia eléctrica. 3.2 Cargue de Librerías library(readr) library(dplyr) ## ## Adjuntando el paquete: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(tidyr) library(lubridate) ## ## Adjuntando el paquete: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(ggplot2) library(scales) ## ## Adjuntando el paquete: &#39;scales&#39; ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor library(zoo) ## ## Adjuntando el paquete: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo 3.3 Lectura y preparación de los datos csv_dir &lt;- &quot;C:/Users/Lenovo/PUJ Cali/OSCAR VELASQUEZ CHALA - Proyecto Aplicado - Proy. Demanda Electrica/2. Fuentes de Datos&quot; csv_name &lt;- &quot;015 SOLO POTENCIA PARA SUBI A BOOKDOWN.csv&quot; csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot; y_col &lt;- &quot;VALOR_IMPUTADO&quot; TZ &lt;- &quot;America/Bogota&quot; # Lectura robusta df &lt;- tryCatch( readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE) ) stopifnot(time_col %in% names(df), y_col %in% names(df)) # Parseo de fechas (varios formatos) df[[time_col]] &lt;- parse_date_time( df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ ) # A numérico df[[y_col]] &lt;- suppressWarnings(readr::parse_number(as.character(df[[y_col]]))) # Malla horaria completa (sin imputar, para marcar huecos) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% select(!!time_col, !!y_col) %&gt;% arrange(.data[[time_col]]) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) summary(df_full[[y_col]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0 1241 3550 3244 4996 10000 610 cat(&quot;Proporción de NA:&quot;, mean(is.na(df_full[[y_col]])), &quot;\\n&quot;) ## Proporción de NA: 0.005141302 3.4 Funciones auxiliares de visualización de la serie de tiempo # Unir horas NA contiguas en bandas na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% dplyr::filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } # Agregación genérica sin imputar tagrega &lt;- function(data, unit, time_col, y_col, tz = TZ) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) } 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) plot_df &lt;- bind_rows( tagrega(df_full, &quot;day&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Diaria&quot;), tagrega(df_full, &quot;week&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Semanal&quot;), tagrega(df_full, &quot;month&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Mensual&quot;), tagrega(df_full, &quot;year&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Anual&quot;) ) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;,&quot;Semanal&quot;,&quot;Mensual&quot;,&quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.25) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.7, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + scale_x_datetime(labels = date_format(&quot;%Y&quot;), date_breaks = &quot;1 year&quot;) + labs(title = &quot;Potencia con huecos (NA)&quot;, subtitle = &quot;Bandas rojas = periodos con NA en la serie horaria original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Curva de Potencia Diaria: muestra alta variabilidad horaria con picos bien definidos, evidenciando que la potencia cambia fuertemente a lo largo del día. Curva de Potencia Semanal: suaviza los ciclos, pero aún se aprecian repeticiones cada pocos días, sugiriendo un patrón operativo estable. Curva de Potencia Mensual: las oscilaciones se atenúan, revelando la tendencia global; los huecos rojos (NA) se observan concentrados en pocos periodos. Curva de Potencia Anual: la línea muestra el comportamiento global a largo rango: valores medios estables sin deriva significativa, lo que sugiere una operación controlada y sin aumento sostenido del consumo. La serie mantiene un patrón estacional fuerte (diario y semanal) y una tendencia global estacionaria. Los huecos (en rojo) son mínimos y no distorsionan las medias agregadas. 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) # Día dia_obj &lt;- as.Date(&quot;2023-02-01&quot;) ini_dia &lt;- as.POSIXct(dia_obj, tz = TZ); fin_dia &lt;- ini_dia + days(1) df_day &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_dia, .data[[time_col]] &lt; fin_dia) na_day &lt;- na_spans_runs(df_day[[time_col]], df_day$is_na) g_day &lt;- ggplot() + geom_rect(data = na_day, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_day, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_dia, fin_dia), date_labels=&quot;%H:%M&quot;, breaks=seq(ini_dia, fin_dia, by=&quot;2 hour&quot;)) + labs(title=paste0(&quot;Curva horaria — &quot;, dia_obj), x=&quot;Hora&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_day Día: 1 febrero 2023:Curva con forma sinusoidal: potencia baja en la madrugada, aumento progresivo durante el día, pico en horas centrales y descenso nocturno. Refleja un ciclo operativo típico diario. # Semana semana_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_sem &lt;- as.POSIXct(floor_date(semana_ref, &quot;week&quot;, week_start=1), tz=TZ) fin_sem &lt;- ini_sem + weeks(1) df_week &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_sem, .data[[time_col]] &lt; fin_sem) na_week &lt;- na_spans_runs(df_week[[time_col]], df_week$is_na) g_week &lt;- ggplot() + geom_rect(data = na_week, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_week, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_sem, fin_sem), date_labels=&quot;%a %d&quot;, breaks=seq(ini_sem, fin_sem, by=&quot;1 day&quot;)) + labs(title=paste0(&quot;Semana del &quot;, ini_sem), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_week Semana: 1–7 febrero 2021: Repetición diaria clara, pero con leves diferencias entre días. Puede reflejar cambios de carga entre jornadas laborales y fines de semana. # Mes mes_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_mes &lt;- as.POSIXct(floor_date(mes_ref, &quot;month&quot;), tz=TZ); fin_mes &lt;- as.POSIXct(ceiling_date(mes_ref, &quot;month&quot;), tz=TZ) df_month &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_mes, .data[[time_col]] &lt; fin_mes) na_month &lt;- na_spans_runs(df_month[[time_col]], df_month$is_na) g_month &lt;- ggplot() + geom_rect(data = na_month, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.25) + geom_line(data = filter(df_month, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.6) + scale_x_datetime(limits=c(ini_mes, fin_mes), date_labels=&quot;%d-%b&quot;, breaks=seq(ini_mes, fin_mes, by=&quot;3 days&quot;)) + labs(title=paste0(&quot;Mes &quot;, format(ini_mes, &#39;%Y-%m&#39;)), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_month Mes: febrero 2021: Patrón reiterado de picos semanales. Los huecos rojos (NA) marcan interrupciones puntuales sin afectar la tendencia global. # Año (panel único) anio_ref &lt;- 2021 ini_anio &lt;- as.POSIXct(ymd(paste0(anio_ref, &quot;-01-01&quot;)), tz=TZ); fin_anio &lt;- as.POSIXct(ymd(paste0(anio_ref+1, &quot;-01-01&quot;)), tz=TZ) df_year &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_anio, .data[[time_col]] &lt; fin_anio) na_year &lt;- na_spans_runs(df_year[[time_col]], df_year$is_na) g_year &lt;- ggplot() + geom_rect(data = na_year, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.20) + geom_line(data = filter(df_year, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.3) + scale_x_datetime(limits=c(ini_anio, fin_anio), date_labels=&quot;%b&quot;, breaks=seq(ini_anio, fin_anio, by=&quot;1 month&quot;)) + labs(title=paste0(&quot;Año &quot;, anio_ref), x=&quot;Mes&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_year Año: 2021: Oscilaciones estacionales sin tendencia definida. No se observan desviaciones estructurales. A nivel temporal, la potencia responde a ciclos regulares con comportamiento casi periódico. 3.7 Promedios móviles Promedios móviles sobre la serie horaria (imputada solo para continuidad visual con na.interp). # --- Promedios móviles coloreados (24h, 168h, 720h) --- # 1) Crea la serie imputada y los MAs df_impu &lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) df_ma &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), `MA 24h` = zoo::rollmean(val_impu, k = 24, align = &quot;right&quot;, fill = NA), `MA 168h` = zoo::rollmean(val_impu, k = 168, align = &quot;right&quot;, fill = NA), `MA 720h` = zoo::rollmean(val_impu, k = 720, align = &quot;right&quot;, fill = NA) ) # 2) Pasar los MAs a formato largo para mapear color por serie library(tidyr) df_ma_long &lt;- df_ma %&gt;% tidyr::pivot_longer(cols = c(`MA 24h`,`MA 168h`,`MA 720h`), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) # 3) Graficar: original en gris, MAs en colores ggplot(df_ma, aes(x = time)) + # Serie original geom_line(aes(y = y), color = &quot;grey80&quot;, linewidth = 0.2, alpha = 0.6) + # Promedio móvil corto (24h) — se dibuja primero geom_line(aes(y = `MA 24h`), color = &quot;#1f77b4&quot;, linewidth = 0.6, alpha = 0.8) + # Promedio móvil intermedio (168h) — encima de la azul geom_line(aes(y = `MA 168h`), color = &quot;#2ca02c&quot;, linewidth = 0.9, alpha = 0.9) + # Promedio móvil largo (720h) — encima de las anteriores geom_line(aes(y = `MA 720h`), color = &quot;#d62728&quot;, linewidth = 1.1, alpha = 1) + labs( title = &quot;Promedios móviles (24h, 168h, 720h)&quot;, subtitle = &quot;Curvas suavizadas de corto, mediano y largo plazo&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;)) La línea gris (serie original) muestra picos horarios abruptos. La línea azul (media móvil 24h) suaviza el ruido diario. La línea verde (media móvil 168h) identifica la tendencia semanal. La línea roja (media móvil 720h) resume la tendencia mensual. No se observan rupturas ni tendencias marcadas. Las tres medias convergen en un rango estable. 3.8 Rezagos (lags) y autocorrelación # --- Rezagos a nivel horario (1, 24, 168, 720) --- df_lags &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), lag_1 = dplyr::lag(as.numeric(val_impu), 1), lag_24 = dplyr::lag(as.numeric(val_impu), 24), lag_168 = dplyr::lag(as.numeric(val_impu), 168), lag_720 = dplyr::lag(as.numeric(val_impu), 720) ) # Correlaciones cors &lt;- c( cor(df_lags$y, df_lags$lag_1, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_24, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_168, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_720, use = &quot;complete.obs&quot;) ) setNames(round(cors, 3), c(&quot;lag1&quot;,&quot;lag24&quot;,&quot;lag168&quot;,&quot;lag720&quot;)) ## lag1 lag24 lag168 lag720 ## 0.977 0.802 0.766 0.749 Lag 1: 0.977 → fuerte dependencia entre horas consecutivas. Lag 24: 0.802 → patrón diario repetitivo. Lag 168: 0.766 → correlación semanal clara. Lag 720: 0.749 → correlación mensual aún significativa. Los altos valores confirman una autocorrelación fuerte y múltiple (hora, día, semana, mes). Esto valida la presencia de estacionalidad múltiple y un comportamiento cíclico persistente. #ACF y PACF: Análisis de Autocorrelación library(ggplot2) # 1) Serie imputada -&gt; vector numérico sin NA serie_vec &lt;- as.numeric(df_impu$val_impu) serie_vec &lt;- serie_vec[!is.na(serie_vec)] # 2) Definir lag máximo (p.ej. 30 días = 24*30) max_lag &lt;- 24 * 30 # 3) Calcular ACF y PACF sin graficar acf_obj &lt;- acf(serie_vec, lag.max = max_lag, plot = FALSE) pacf_obj &lt;- pacf(serie_vec, lag.max = max_lag, plot = FALSE) # 4) Pasar a data frame (ojo: ambos traen valores en $acf) acf_df &lt;- data.frame( lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf) ) pacf_df &lt;- data.frame( lag = as.numeric(pacf_obj$lag), # lags desde 1 normalmente pacf = as.numeric(pacf_obj$acf) # valores de PACF están en $acf ) # 5) Bandas de confianza 95% n_eff &lt;- length(serie_vec) ci &lt;- 1.96 / sqrt(n_eff) # 6) Graficar con ggplot2 # --- ACF --- ggplot(acf_df, aes(x = lag, y = acf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;ACF - Autocorrelación de la serie horaria&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal(base_size = 12) El gráfico ACF muestra la correlación de la serie de potencia horaria consigo misma a diferentes rezagos (lags), medidos en horas. En el rezago 0 la autocorrelación es 1, cada punto está completamente correlacionado consigo mismo. Se observa una autocorrelación muy alta y sostenida en casi todos los rezagos, con valores cercanos a 0.75–0.80 hasta aproximadamente 700 horas (~30 días). Esta persistencia indica que la serie mantiene una dependencia temporal fuerte, es decir, los valores pasados tienen gran influencia sobre los futuros. Se aprecian picos regulares (aprox. cada 24, 168 y 720 rezagos), lo que evidencia patrones estacionales diarios, semanales y mensuales. Las bandas rojas horizontales representan los límites de significancia al 95% (±0.006). Todos los valores de la ACF están muy por encima de esas bandas, lo que confirma que la autocorrelación es estadísticamente significativa en todos los horizontes analizados. La serie presenta una estructura fuertemente autocorrelacionada, con periodicidad marcada y ciclos regulares. Esto indica que no es una serie puramente aleatoria, sino que está dominada por una estacionalidad sistemática de carácter diario y semanal. # --- PACF --- ggplot(pacf_df, aes(x = lag, y = pacf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;PACF - Autocorrelación parcial&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal(base_size = 12) El gráfico PACF muestra la correlación entre la serie y sus rezagos una vez eliminada la influencia de los rezagos intermedios. Se observa un pico alto en el primer rezago (lag = 1), lo que indica una fuerte dependencia inmediata (efecto de la hora anterior). Después del primer rezago, los valores de la PACF caen rápidamente y se mantienen cerca de cero, salvo algunos picos débiles en rezagos aproximadamente iguales a 24, 168 y 720 horas, que corresponden a efectos estacionales. Estos picos secundarios son pequeños pero significativos, lo que sugiere una estacionalidad múltiple (día, semana, mes). La PACF confirma que el comportamiento actual de la potencia depende principalmente de su valor en la hora anterior (AR(1)), junto con componentes estacionales de largo plazo. 3.9 Estacionalidad (gráficos y descomposición) Para descomponer, usamos un objeto ts regular con frecuencia diaria (24), semanal (24*7) o anual (24*365). Utilizamos la serie imputada val_impu para evitar huecos. # Construir ts con frecuencia diaria (24 por ciclo) start_time &lt;- min(df_impu[[time_col]], na.rm = TRUE) Indice.ts.diaria &lt;- ts(df_impu$val_impu, start = c(year(start_time), hour(start_time) + 1), frequency = 24) # Gráficos estacionales (por hora del día y por mes) autoplot(Indice.ts.diaria) + ggtitle(&quot;Serie ts (freq=24)&quot;) Serie ts (freq = 24) La serie presenta alta variabilidad (cada día cambia mucho), con rupturas o cambios estructurales en determinados años. Esto indica que el sistema de potencia tiene patrones por periodos largos más que una estacionalidad estricta diaria. # STL y gráficos estacionales fit_stl &lt;- stl(Indice.ts.diaria, s.window = &quot;periodic&quot;) plot(fit_stl, main = &quot;Descomposición STL (frecuencia diaria)&quot;) Decomposición STL frecuencia diaria * data: Muestra la potencia total observada con todas sus fluctuaciones. * seasonal: Se observa una banda negra uniforme, porque la variabilidad de la serie es mucho mayor que la amplitud de la estacionalidad. * trend: Se observan periodos con incrementos o descensos sostenidos de potencia * remainder: Presenta la variabilidad de corto plazo, los picos, fallos de medición y valores atípicos # Define un inicio dinámico (o fija una fecha) ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) slice &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(slice$val_impu), frequency = 24) fit_zoom &lt;- stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE) plot(fit_zoom, range.bars = FALSE, main = &quot;STL en ventana (4 semanas)&quot;) Decomposición STL en una ventana de 4 semanas data: Se observan oscilaciones regulares de subida y bajada cada 24 horas, lo cual refleja el patrón de potencia diario. Hay algunos huecos o caídas abruptas que corresponden a datos faltantes o interrupciones de registro de los datos. La serie se mueve alrededor de una media aproximada de 5000–6000 KW, con variaciones diarias de alrededor de ±1000 – 1500 KW. seasonal: Se observa una forma de onda repetitiva tipo sinusoinal, con un ciclo por día. La serie tiene una estacionalidad clara diaria: la potencia sube en ciertas horas (probablemente durante el día laboral) y baja en otras (probablemente por la noche). La amplitud del patrón se mantiene bastante constante, lo que sugiere que la estacionalidad diaria no cambia mucho entre semanas. trend: Se observan ondas de mayor periodo que podrían corresponder a variaciones semanales. La tendencia muestra subidas y bajadas lentas, lo que indica variabilidad estructural o cambios progresivos en el nivel medio de potencia. La escala vertical está alrededor de los 5000–7000 KW. remainder: Los picos hacia arriba o abajo representan anomalías, errores o eventos inusuales. Se observan algunos picos negativos fuertes, que podrían deberse a interrupciones o registros incorrectos de potencia (NA o 0). El resto del residuo oscila cerca de cero, lo cual es deseable (significa que la mayor parte de la variabilidad fue capturada por tendencia + estacionalidad). En resumen, la serie de potencia tiene una estacionalidad diaria fuerte, una tendencia suave semanal, y ruido moderado. 3.10 Indicadores resumidos # Completitud global comp_global &lt;- 1 - mean(is.na(df_full[[y_col]])) # Completitud por año comp_anio &lt;- df_full %&gt;% dplyr::group_by(anio = lubridate::year(.data[[time_col]])) %&gt;% dplyr::summarise( comp = 1 - mean(is.na(.data[[y_col]])), n_obs = dplyr::n(), .groups = &quot;drop&quot; ) comp_global ## [1] 0.9948587 comp_anio ## # A tibble: 8 × 3 ## anio comp n_obs ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2018 0.996 38330 ## 2 2019 0.979 15639 ## 3 2020 0.997 17424 ## 4 2021 0.994 11444 ## 5 2022 1 9793 ## 6 2023 1 9893 ## 7 2024 1 9712 ## 8 2025 1 6412 Año Completitud Observaciones 2018 99.6% Muy buena cobertura 2019 97.9% Ligera pérdida de datos 2020 99.7% Excelente 2021 99.4% Alta 2022–2025 100% Sin huecos 3.11 Conclusiones La serie de potencia es altamente estacionaria y cíclica. Existen ciclos claros de 24 y 168 horas, reflejando comportamientos diarios y semanales. No se detectan tendencias de crecimiento, lo que indica estabilidad en la operación. Los promedios móviles confirman consistencia estructural. La descomposición STL y la ACF refuerzan la idea de una estacionalidad regular y predecible. La calidad del registro (99.5%) garantiza confiabilidad para análisis predictivos. "],["Preprocesamiento.html", "4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen 4.2 Carga de librerías 4.3 Carga de datos y visualización 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación 4.5 ACF y PACF (original y diferenciada) 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico 4.8 Puntos de cambio y visualización 4.9 Outliers y verificación de supuestos del ARIMA 4.10 Transformación logarítmica para estabilizar la varianza 4.11 Ajuste del modelo ARIMA en escala logarítmica 4.12 Verificación de supuestos del nuevo modelo 4.13 Pronóstico con el modelo mejorado (escala logarítmica) 4.14 Conclusiones", " 4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen Este cápitulo presenta una interpretación detallada de los resultados de Preprocesamiento y visualización de la serie temporal horaria de potencia. Se describen los patrones de tendencia y estacionalidad a distintas escalas (diaria, semanal, mensual y anual), la verificación/inducción de estacionariedad (diferenciación), el análisis ACF/PACF, la descomposición STL/MSTL, la detección de puntos de cambio, la identificación de outliers, el ajuste SARIMA (auto.arima) y el pronóstico. 4.2 Carga de librerías library(readr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(scales) library(zoo) library(forecast) library(tseries) library(changepoint) 4.3 Carga de datos y visualización csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot;; y_col &lt;- &quot;VALOR_IMPUTADO&quot; df &lt;- tryCatch(readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE)) # Parseo robusto de fecha-hora y valor df[[time_col]] &lt;- parse_date_time(df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ) df[[y_col]] &lt;- suppressWarnings(as.numeric(df[[y_col]])) # Malla horaria completa para marcar NA (sin imputar) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% arrange(.data[[time_col]]) %&gt;% select(!!time_col, !!y_col) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) # Serie imputada (para métodos que exigen regularidad) tm(&quot;Imputación (na.interp)&quot;, { df_impu &lt;&lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) }) # Vista rápida: primer tramo ggplot(df_full, aes(x = .data[[time_col]], y = .data[[y_col]])) + geom_line(na.rm = TRUE) + labs(title = &quot;Serie horaria de potencia (con huecos)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() Se observa la secuencia temporal de los valores de potencia con discontinuidades. 4.3.1 Bandas para huecos (NA) y vistas multiescala na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } agg_by &lt;- function(data, unit, label, time_col, y_col) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% mutate(freq = label) } na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) diaria &lt;- agg_by(df_full, &quot;day&quot;, &quot;Diaria&quot;, time_col, y_col) semanal &lt;- agg_by(df_full, &quot;week&quot;, &quot;Semanal&quot;, time_col, y_col) mensual &lt;- agg_by(df_full, &quot;month&quot;, &quot;Mensual&quot;, time_col, y_col) anual &lt;- agg_by(df_full, &quot;year&quot;, &quot;Anual&quot;, time_col, y_col) plot_df &lt;- bind_rows(diaria, semanal, mensual, anual) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;, &quot;Semanal&quot;, &quot;Mensual&quot;, &quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.3) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.6, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + labs(title = &quot;Potencia — vistas diaria, semanal, mensual y anual&quot;, subtitle = &quot;Bandas rojas: periodos con NA en la serie original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Las discontinuidades se indicaron con franjas de color rojo. Estos huecos fueron imputados usando forecast::na.interp, método lineal-local que mantiene la coherencia temporal. La imputación es obligatoria para construir una serie regular (necesaria para ARIMA, STL y MSTL). Si no se hace, los modelos no convergen ni generan predicciones confiables. La potencia muestra una variabilidad cíclica, con fluctuaciones más suaves en las escalas semanales y mensuales. Las bandas rojas señalan períodos con datos ausentes; su distribución ayuda a evaluar si hay estacionalidad interrumpida. El análisis multiescala permite identificar tendencias de largo plazo y patrones repetitivos en diferentes horizontes. 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación # Vector numérico imputado serie_vec &lt;- as.numeric(df_impu$val_impu) # ADF en serie original adf_raw &lt;- tseries::adf.test(serie_vec, k = 24) adf_raw ## ## Augmented Dickey-Fuller Test ## ## data: serie_vec ## Dickey-Fuller = -24.434, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria en media. # Diferenciación sugerida y gráfico d_sugerido &lt;- forecast::ndiffs(serie_vec) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 “ndiffs” sugiere una diferenciación (d = 1) para estabilizar tendencia y variabilidad. serie_diff &lt;- if (d_sugerido &gt; 0) diff(serie_vec, differences = d_sugerido) else serie_vec df_diff &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]])[seq_along(serie_vec)], Original = as.numeric(serie_vec), Diferenciada = c(rep(NA, d_sugerido), as.numeric(serie_diff)) ) |&gt; tidyr::pivot_longer(cols = c(Original, Diferenciada), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) ggplot(df_diff, aes(time, Valor, color = Serie)) + geom_line(linewidth = 0.6, alpha = 0.9, na.rm = TRUE) + scale_color_manual(values = c(Original = &quot;#6B7280&quot;, Diferenciada = &quot;#1F77B4&quot;)) + labs(title = &quot;Serie original vs. diferenciada&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia / ΔPotencia&quot;, color = &quot;Serie&quot;) + theme_minimal(base_size = 12) La serie original presenta tendencia ascendente y picos altos. La serie diferenciada elimina la tendencia de la serie original, centrando la media alrededor de cero y reduciendo varianza. # ADF nuevamente si se diferenció if (d_sugerido &gt; 0) { cat(&quot;\\nRe-prueba ADF en la serie diferenciada (d =&quot;, d_sugerido, &quot;):\\n&quot;) print(tseries::adf.test(serie_diff, k = 24)) } ## ## Re-prueba ADF en la serie diferenciada (d = 1 ): ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff ## Dickey-Fuller = -91.566, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) para la serie diferenciada indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria. En modelos ARIMA se necesita estacionariedad. La diferenciación controla la no estacionariedad estructural sin alterar la forma estacional de corto plazo. 4.5 ACF y PACF (original y diferenciada) # ============================================================ # 6. ACF y PACF (original y diferenciada) # ============================================================ # --- Calcular ACF/PACF de la serie original --- t0 &lt;- Sys.time() acf_obj &lt;- try(acf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_obj &lt;- try(pacf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (original)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_obj, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) # --- Graficar ACF/PACF de la serie original --- if (!inherits(acf_obj, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_obj, &quot;try-error&quot;)) { acf_df &lt;- data.frame(lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf)) pacf_df &lt;- data.frame(lag = as.numeric(pacf_obj$lag), pacf = as.numeric(pacf_obj$acf)) ci &lt;- 1.96 / sqrt(length(serie_vec)) p1 &lt;- ggplot(acf_df, aes(lag, acf)) + geom_col(fill = &quot;#1f77b4&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p2 &lt;- ggplot(pacf_df, aes(lag, pacf)) + geom_col(fill = &quot;#ff7f0e&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p1); print(p2) } else { cat(&quot;Error al calcular ACF/PACF de la serie original.\\n&quot;) } # --- Serie diferenciada --- if (exists(&quot;serie_diff&quot;) &amp;&amp; length(serie_diff) &gt; 10 &amp;&amp; !identical(serie_diff, serie_vec)) { t0 &lt;- Sys.time() acf_d &lt;- try(acf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_d &lt;- try(pacf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (diferenciada)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_d, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) if (!inherits(acf_d, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_d, &quot;try-error&quot;)) { acf_df_d &lt;- data.frame(lag = as.numeric(acf_d$lag), acf = as.numeric(acf_d$acf)) pacf_df_d &lt;- data.frame(lag = as.numeric(pacf_d$lag), pacf = as.numeric(pacf_d$acf)) ci_d &lt;- 1.96 / sqrt(length(serie_diff)) p3 &lt;- ggplot(acf_df_d, aes(lag, acf)) + geom_col(fill = &quot;#17becf&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p4 &lt;- ggplot(pacf_df_d, aes(lag, pacf)) + geom_col(fill = &quot;#2ca02c&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p3); print(p4) } else { cat(&quot;Error al calcular ACF/PACF diferenciada.\\n&quot;) } } La ACF de la serie original muestra valores muy altos (cercanos a 1) en los primeros rezagos y una disminución muy lenta a medida que aumenta el lag (hasta aproximadamente 168 horas, es decir, 7 días). La curva no cruza la banda de significancia (líneas rojas), lo cual indica una persistencia fuerte. La alta autocorrelación inicial y su decaimiento lento son señales claras de no estacionariedad. Este patrón implica que los valores pasados influyen fuertemente en los futuros, y que la serie tiene una tendencia o un ciclo estacional persistente. La leve oscilación alrededor de los rezagos 24, 48, 72, etc., sugiere la presencia de una estacionalidad diaria (24 horas). En conjunto, la ACF indica que la serie no tiene media constante y no fluctúa alrededor de un equilibrio estable. La serie original no es estacionaria y requiere una transformación (diferenciación) para eliminar la tendencia y permitir el uso de modelos ARIMA. La PACF de la serie original presenta un pico muy pronunciado en el lag 1 y luego una rápida caída hacia valores pequeños alrededor de cero. El gran valor en el primer rezago indica un componente autoregresivo fuerte de orden 1 (AR(1)). La rápida caída posterior confirma que la mayor parte de la dependencia directa se concentra en los primeros rezagos. Los valores bajos pero persistentes en rezagos múltiples reflejan todavía efectos indirectos acumulados, producto de la tendencia no estacionaria detectada. La PACF confirma un componente autoregresivo significativo en la estructura de la serie original, aunque su interpretación precisa se distorsiona por la presencia de tendencia y estacionalidad. La ACF de la serie diferenciada muestra una autocorrelación fuerte únicamente en el rezago 1, pero el resto de las barras caen rápidamente dentro del intervalo de confianza (líneas rojas). La diferenciación ha eliminado con éxito la tendencia y la dependencia a largo plazo. Los valores cercanos a cero en los rezagos mayores indican que la serie ya no tiene memoria prolongada, es decir, es estacionaria en media. El ligero pico negativo en los primeros rezagos podría sugerir un componente MA (Media Móvil) de bajo orden. Tras la diferenciación, la ACF evidencia una serie estacionaria y más estable, con correlación significativa sólo a corto plazo. En la PACF de la serie diferenciada se observa un primer pico negativo (ligeramente pronunciado) y luego valores pequeños oscilando alrededor de cero, sin superar el umbral de significancia. Este patrón es típico de una serie con componente MA (q) después de la diferenciación. La ausencia de picos claros más allá del primer rezago indica que no existen dependencias autoregresivas persistentes. La PACF de la serie diferenciada confirma que el proceso se estabilizó tras la diferenciación, y que la estructura autoregresiva se redujo sustancialmente, favoreciendo modelos ARIMA sencillos con un componente de media móvil dominante. 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else if (&quot;VALOR_IMPUTADO&quot; %in% names(df_impu)) &quot;VALOR_IMPUTADO&quot; else stop(&quot;No encuentro columna de valores: usa &#39;val_impu&#39; o &#39;VALOR_IMPUTADO&#39;.&quot;) # Utilidad para detectar columna estacional por periodo (acepta &#39;Seasonal-24&#39;, &#39;Seasonal 24&#39;, etc.) find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) if (!any(is_seas)) return(NULL) seas_nm &lt;- nm[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # ========== A) df_seas24: Estacionalidad diaria (24h) desde SERIE HORARIA ========== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_m_hour &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_h &lt;- as.data.frame(fit_m_hour) col_s24 &lt;- find_seasonal_col(comp_h, 24) if (is.null(col_s24)) { # fallback: primera &#39;Seasonal&#39; si no se pudo detectar 24 específicamente cand &lt;- grep(&quot;^Seasonal&quot;, names(comp_h), ignore.case = TRUE, value = TRUE) col_s24 &lt;- cand[1] } df_seas24 &lt;- tibble( time = time_hr, Componente = &quot;Estacionalidad diaria (24h)&quot;, Valor = comp_h[[col_s24]] ) # ========== B) df_seas12: Estacionalidad mensual (12) desde SERIE MENSUAL ========== monthly &lt;- df_impu %&gt;% mutate(mes = floor_date(.data[[time_col]], &quot;month&quot;)) %&gt;% summarise(.by = mes, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(mes) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(year(min(monthly$mes)), month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # detectar columna estacional (nombre puede ser &quot;seasonal&quot;/&quot;Seasonal&quot;) seas_col_m &lt;- names(comp_m)[grepl(&quot;season&quot;, names(comp_m), ignore.case = TRUE)][1] if (is.na(seas_col_m)) stop(&quot;No se encontró columna estacional en STL mensual.&quot;) df_seas12 &lt;- tibble( time = as.POSIXct(monthly$mes), # unificamos a POSIXct Componente = &quot;Estacionalidad mensual (12)&quot;, Valor = comp_m[[seas_col_m]] ) # ========== C) df_day_panel: Observada, Tendencia, Semanal(7d), Anual(365d), Residuo (SERIE DIARIA) ========== daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% summarise(.by = day, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(day) ts_day &lt;- forecast::msts(daily$y, seasonal.periods = c(7, 365)) fit_m_day &lt;- forecast::mstl(ts_day, robust = TRUE) comp_d &lt;- as.data.frame(fit_m_day) # Normalizamos nombres para &#39;Trend&#39; y &#39;Remainder&#39; nmd &lt;- names(comp_d) nmd &lt;- sub(&quot;^trend$&quot;, &quot;Trend&quot;, nmd, ignore.case = TRUE) nmd &lt;- sub(&quot;^remainder$&quot;, &quot;Remainder&quot;, nmd, ignore.case = TRUE) names(comp_d) &lt;- nmd # Detectar columnas estacionales 7 y 365 is_seas &lt;- grepl(&quot;^Seasonal&quot;, names(comp_d), ignore.case = TRUE) seas_nms &lt;- names(comp_d)[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } seas_p &lt;- vapply(seas_nms, getp, integer(1)) idx7 &lt;- which(seas_p == 7) idx365 &lt;- which(seas_p == 365) seas7 &lt;- if (length(idx7)) comp_d[[seas_nms[idx7[1]]]] else NULL seas365 &lt;- if (length(idx365)) comp_d[[seas_nms[idx365[1]]]] else NULL df_day_panel &lt;- tibble( time = as.POSIXct(daily$day), Observada = daily$y, Tendencia = if (&quot;Trend&quot; %in% names(comp_d)) comp_d$Trend else NA_real_, Residuo = if (&quot;Remainder&quot; %in% names(comp_d)) comp_d$Remainder else NA_real_ ) if (!is.null(seas7)) df_day_panel[[&quot;Estacionalidad semanal (7d)&quot;]] &lt;- seas7 if (!is.null(seas365)) df_day_panel[[&quot;Estacionalidad anual (365d)&quot;]] &lt;- seas365 df_day_panel &lt;- df_day_panel |&gt; pivot_longer(-time, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) # ========== D) Panel combinado ========== panel_all &lt;- bind_rows( df_day_panel, # Observada/Tendencia/Residuo + 7d/365d si existen df_seas24, # Estacionalidad diaria (24h) desde HORAS df_seas12 # Estacionalidad mensual (12) desde MESES ) %&gt;% mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;, &quot;Tendencia&quot;, &quot;Estacionalidad diaria (24h)&quot;, &quot;Estacionalidad semanal (7d)&quot;, &quot;Estacionalidad mensual (12)&quot;, &quot;Estacionalidad anual (365d)&quot;, &quot;Residuo&quot;) ) ) # ========== E) Gráfico ========== ggplot(panel_all, aes(x = time, y = Valor)) + geom_line(linewidth = 0.45, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;, drop = FALSE) + scale_x_datetime(date_breaks = &quot;6 months&quot;, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) + labs( title = &quot;Descomposición combinada de la serie completa&quot;, subtitle = &quot;Tendencia + Estacionalidades diaria (24h), semanal (7d), mensual (12) y anual (365d) + Residuo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) 4.6.1 Descomposición de la serie por estacionalidades # ============================================================ # Descomposición óptima de la serie: # - Diaria (24h) → serie horaria (MSTL, seasonal.periods=24) # - Semanal (7d) → serie horaria (MSTL, seasonal.periods=168) # - Mensual (12) → serie mensual (STL, frequency=12) # - Anual (365d) → serie diaria (STL, frequency=365) # Gráficos en orden: Observada → Tendencia → Estacionalidad → Residuo # ============================================================ # ==== 0) Utilidades ==== val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else &quot;VALOR_IMPUTADO&quot; # Detecta, dentro de un data.frame de mstl/stl, la columna estacional de un periodo dado find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) # posibles nombres: &quot;Seasonal-24&quot;, &quot;Seasonal 24&quot;, &quot;seasonal24&quot;, etc. is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) seas_nm &lt;- nm[is_seas] if (!length(seas_nm)) return(NULL) getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # Devuelve nombres (o NA) para Trend y Remainder segun el objeto mstl/stl find_trend_remainder &lt;- function(df_comp) { nm &lt;- names(df_comp) trend &lt;- nm[grepl(&quot;^Trend$&quot;, nm, ignore.case = TRUE)] remainder &lt;- nm[grepl(&quot;^Remainder$&quot;, nm, ignore.case = TRUE)] list(trend = if (length(trend)) trend[1] else NA_character_, remainder = if (length(remainder)) remainder[1] else NA_character_) } # Constructor genérico de gráfico con orden fijo de facetas plot_decomp &lt;- function(df_wide, time_col_name = &quot;time&quot;, title_txt = &quot;&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) { df_long &lt;- df_wide |&gt; tidyr::pivot_longer(-dplyr::all_of(time_col_name), names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) |&gt; dplyr::mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;,&quot;Tendencia&quot;,&quot;Estacionalidad&quot;,&quot;Residuo&quot;) ) ) p &lt;- ggplot(df_long, aes(x = .data[[time_col_name]], y = Valor)) + geom_line(linewidth = 0.6, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;) + labs(title = title_txt, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) if (x_is_date) { p &lt;- p + scale_x_date(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } else { p &lt;- p + scale_x_datetime(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } p } # ==== 1) Serie HORARIA → diaria(24h) y semanal(168h) con MSTL ==== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_mstl_hr &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_hr &lt;- as.data.frame(fit_mstl_hr) # columnas clave cols_hr &lt;- find_trend_remainder(comp_hr) col_trend_hr &lt;- cols_hr$trend col_rem_hr &lt;- cols_hr$remainder col_s24 &lt;- find_seasonal_col(comp_hr, 24) col_s168 &lt;- find_seasonal_col(comp_hr, 168) # --- A) Diaria (24h) sobre la serie horaria --- df_day24 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s24)) comp_hr[[col_s24]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_day24 &lt;- plot_decomp(df_day24, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición DIARIA (24h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) # --- B) Semanal (7d=168h) sobre la serie horaria --- df_week168 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s168)) comp_hr[[col_s168]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_week168 &lt;- plot_decomp(df_week168, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición SEMANAL (7d = 168h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;6 months&quot;) # ==== 2) Serie MENSUAL → mensual(12) con STL ==== monthly &lt;- df_impu |&gt; dplyr::mutate(mes = lubridate::floor_date(.data[[time_col]], &quot;month&quot;)) |&gt; dplyr::group_by(mes) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(lubridate::year(min(monthly$mes)), lubridate::month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # seasonal, trend, remainder # nombres estandar names(comp_m) &lt;- tolower(names(comp_m)) df_month12 &lt;- dplyr::tibble( time = as.Date(monthly$mes), Observada = as.numeric(ts_month), Tendencia = comp_m$trend, Estacionalidad= comp_m$seasonal, Residuo = comp_m$remainder ) p_month12 &lt;- plot_decomp(df_month12, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición MENSUAL (12) — serie mensual&quot;, x_is_date = TRUE, date_breaks_main = &quot;6 months&quot;) # ==== 3) Serie DIARIA → anual(365) con STL ==== daily &lt;- df_impu |&gt; dplyr::mutate(day = lubridate::floor_date(.data[[time_col]], &quot;day&quot;)) |&gt; dplyr::group_by(day) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(daily) &gt;= 365) # ideal ≥ 2*365 para patrón robusto ts_year &lt;- stats::ts( daily$y, frequency = 365, start = c(lubridate::year(min(daily$day)), as.integer(format(min(daily$day), &quot;%j&quot;))) ) fit_stl_y &lt;- stats::stl(ts_year, s.window = &quot;periodic&quot;, robust = TRUE) comp_y &lt;- as.data.frame(fit_stl_y$time.series) names(comp_y) &lt;- tolower(names(comp_y)) df_year365 &lt;- dplyr::tibble( time = as.POSIXct(daily$day), Observada = as.numeric(ts_year), Tendencia = comp_y$trend, Estacionalidad= comp_y$seasonal, Residuo = comp_y$remainder ) p_year365 &lt;- plot_decomp(df_year365, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición ANUAL (365d) — serie diaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;1 year&quot;) # ==== 4) Mostrar los 4 gráficos ==== p_day24 p_week168 p_month12 p_year365 Tendencia: suaviza el comportamiento global; muestra una evolución sostenida de la potencia en el tiempo. Estacionalidades: 24 h: patrón diario con repeticiones claras (potencia eléctrica según horas). 7 d: variación semanal con máximos en ciertos días. 12 m: ciclo anual ligado a estaciones o periodos de consumo. 365 d: refina oscilaciones de largo plazo. Residuo: oscilaciones aleatorias sin patrón sistemático. La descomposición MSTL permite aislar múltiples estacionalidades y verificar si cada componente explica variaciones específicas. No requiere transformaciones adicionales al trabajar sobre serie imputada y diferenciada. 4.6.2 Descomposición de la serie en una ventana de 4 semanas t0 &lt;- Sys.time() ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) seg_4w &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(seg_4w$val_impu), frequency = 24) fit_stl &lt;- try(stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE), silent = TRUE) .timing[[&quot;STL (ventana 4 semanas)&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(fit_stl, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = if (inherits(fit_stl, &quot;try-error&quot;)) as.character(fit_stl) else &quot;&quot; ) if (!inherits(fit_stl, &quot;try-error&quot;)) { plot(fit_stl, range.bars = FALSE, main = &quot;STL (ventana de 4 semanas)&quot;) } else { cat(&quot;No se pudo calcular STL (ver mensaje en la tabla de tiempos).\\n&quot;) } Muestra el detalle de la estructura estacional de corto plazo: ciclos diarios consistentes. Permite comprobar estabilidad local de la tendencia y detectar posibles cambios abruptos. Analizar ventanas cortas sirve para validar la homogeneidad de los patrones estacionales dentro del año. 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico tm(&quot;Ajuste SARIMA + Pronóstico&quot;, { y_fit &lt;&lt;- ts(serie_vec, frequency = 24) m_auto &lt;&lt;- forecast::auto.arima( y_fit, d = d_sugerido, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx, max.p = 5, max.q = 5, max.P = 2, max.Q = 2 ) print(m_auto) h_days &lt;&lt;- horizon_days h &lt;&lt;- 24 * h_days fc &lt;&lt;- forecast::forecast(m_auto, h = h) print(autoplot(fc) + labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;)) }) ## Series: y_fit ## ARIMA(1,1,1)(0,0,2)[24] ## ## Coefficients: ## ar1 ma1 sma1 sma2 ## -0.8940 0.9736 0.0222 0.0110 ## s.e. 0.0023 0.0012 0.0029 0.0028 ## ## sigma^2 = 249612: log likelihood = -905595.9 ## AIC=1811202 AICc=1811202 BIC=1811250 auto.arima selecciona automáticamente (p, d, q) y (P, D, Q)[s] d = 1 (diferenciación no estacional) para eliminar tendencia. [24] como periodicidad diaria. MA/AR estacionales que capturan los picos en ACF/PACF. El modelo incluye diferenciación (d = 1) y componente estacional de 24 h; por tanto, controla la tendencia y la variabilidad residual detectadas en etapas anteriores. SARIMA es apropiado cuando existe estructura autoregresiva + estacionalidad fija. La diferenciación previa y la evidencia ACF/PACF respaldan esta elección. 4.7.1 Zoom al Pronóstico # ==== ZOOM FINAL AL PRONÓSTICO ==== history_days &lt;- 21 h_days &lt;- horizon_days %||% 7 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) h &lt;- length(fc$mean) f_times &lt;- seq(from = t_max + hours(1), by = &quot;1 hour&quot;, length.out = h) fc_df &lt;- tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[,&quot;80%&quot;]), hi80 = as.numeric(fc$upper[,&quot;80%&quot;]), lo95 = as.numeric(fc$lower[,&quot;95%&quot;]), hi95 = as.numeric(fc$upper[,&quot;95%&quot;]) ) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.4, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, # ← espaciado más grande date_labels = &quot;%d-%b&quot;) + # ← formato sin hora coord_cartesian(ylim = c(0, 10000)) + # recorta sin descartar filas labs(title = paste0(&quot;Zoom final del Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1) # ← evita solapamiento ) Línea negra: representa los últimos 21 días de la serie observada, durante este período, la potencia muestra una variabilidad marcada con picos altos (entre 7000 y 10000 unidades) y caídas bruscas hacia valores bajos. Línea azul: corresponde a la predicción puntual generada por el modelo SARIMA para los siguientes 7 días. Esta predicción se mantiene estable y suavizada en comparación con la serie observada, lo que indica que el modelo estima que la potencia tenderá a estabilizarse alrededor de un valor medio cercano a los 4500–5000 unidades. Franjas azules (bandas de confianza): La franja más oscura representa el intervalo de confianza al 80 % y la franja más clara, el intervalo al 95 %. Estas bandas muestran la incertidumbre asociada a la predicción: a medida que el horizonte temporal avanza, las bandas se ensanchan, lo que significa que el modelo tiene menos certeza sobre los valores futuros. El ensanchamiento pronunciado indica que la volatilidad pasada influye fuertemente en la incertidumbre del pronóstico. El modelo sugiere una tendencia de estabilización en los valores de potencia para la semana siguiente. No se anticipan picos extremos ni caídas abruptas. Dado que las bandas de confianza se mantienen dentro del rango esperado (0 – 10000), el ajuste es razonable y coherente con la magnitud de los datos históricos. Las bandas amplias implican que, aunque el modelo capta bien la tendencia general, la precisión puntual es limitada. Esto es común en series con ruido y estacionalidades múltiples. 4.8 Puntos de cambio y visualización daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% group_by(day) %&gt;% summarise(y = mean(val_impu), .groups = &quot;drop&quot;) tm(&quot;Changepoint (media diaria, PELT)&quot;, { cp &lt;&lt;- cpt.mean(daily$y, method = &quot;PELT&quot;, penalty = &quot;SIC&quot;) }) head (cp@cpts,100) # índices de cambio ## [1] 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ## [19] 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 66 ## [37] 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ## [55] 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## [73] 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 ## [91] 121 123 124 125 126 127 128 129 130 131 # Overlay en la curva diaria ggplot(daily, aes(day, y)) + geom_line() + geom_vline(xintercept = daily$day[cp@cpts], linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Media diaria con puntos de cambio (cpt.mean)&quot;, x = &quot;Día&quot;, y = &quot;Potencia media diaria&quot;) + theme_minimal() El método utilizado (cpt.mean del paquete changepoint) permite identificar momentos en el tiempo donde la media del proceso cambia significativamente, lo cual es muy útil para detectar rupturas, transiciones o alteraciones del régimen de la serie. Líneas negras, corresponden a la serie diaria suavizada. Es decir, los valores promedio por día de la potencia, eliminando la variación horaria interna. Líneas horizontales rojas (puntos de cambio), indican los momentos en que el algoritmo PELT (Pruned Exact Linear Time) identificó cambios estadísticamente significativos en la media. Cada línea roja marca una ruptura: un punto donde el nivel promedio de la serie cambia de forma abrupta o sostenida. La gran cantidad de líneas rojas indica múltiples cambios en la media a lo largo de la serie. Esto sugiere que la potencia no sigue un comportamiento estacionario estable, sino que ha tenido varios periodos con medias distintas —lo cual puede corresponder a modificaciones en la demanda, mantenimiento de equipos, cambios operativos o condiciones externas. Periodo 2018–2020: Los valores son relativamente bajos y estables, con algunos incrementos graduales. Los puntos de cambio aquí podrían asociarse a una transición hacia niveles más altos de consumo o potencia. Periodo 2020–2021: Se observa una mayor volatilidad, con picos y caídas pronunciadas. Es probable que los puntos de cambio detecten episodios transitorios de aumento o reducción drástica. 2022 en adelante: La serie aumenta en nivel medio y muestra mayor dispersión, con valores que alcanzan niveles altos de potencia (&gt;6000). Las múltiples líneas rojas en esta etapa indican fluctuaciones más frecuentes, reflejando un sistema con variabilidad estructural más alta o cambios en los patrones de uso. La serie de potencia no es homogénea en el tiempo: exhibe múltiples cambios estructurales en su comportamiento medio. Estos cambios pueden ser interpretados como etapas operativas o periodos de régimen distinto, lo que justifica la necesidad de aplicar modelos con parámetros variables o segmentados.. La alta frecuencia de cambios después de 2022 podría indicar mayor inestabilidad del sistema o sensibilidad a factores externos, lo cual también se relaciona con la amplia incertidumbre observada en las bandas del pronóstico SARIMA. 4.9 Outliers y verificación de supuestos del ARIMA # Outliers to &lt;- tryCatch(forecast::tsoutliers(ts(serie_vec, frequency = 24)), error = function(e) NULL) if (!is.null(to)) { #print(to) idx &lt;- to$index df_ol &lt;- tibble(time = as.POSIXct(df_impu[[time_col]])[idx], y = serie_vec[idx]) ggplot(tibble(time = as.POSIXct(df_impu[[time_col]]), y = serie_vec), aes(time, y)) + geom_line(alpha = 0.6) + geom_point(data = df_ol, aes(time, y), color = &quot;red&quot;, size = 1.4) + labs(title = &quot;Outliers detectados (forecast::tsoutliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() } El análisis de valores atípicos (outliers) identifica puntos que se desvían significativamente del patrón esperado de la serie, considerando su tendencia, estacionalidad y variabilidad histórica. Línea gris: Muestra la serie temporal original de potencia, donde se pueden observar los patrones de oscilación, los aumentos progresivos y los periodos de mayor variabilidad. Puntos rojos: Señalan los outliers detectados automáticamente por el algoritmo de tsoutliers.Estos puntos representan valores que el modelo considera anómalos, es decir, que se alejan más de lo esperado de acuerdo con la estructura de tendencia y estacionalidad estimada. 2018–2019: Pocos outliers, mayormente en valores bajos, lo que sugiere una etapa relativamente estable. 2020–2021: Aumenta la cantidad de outliers tanto por exceso como por defecto (picos y caídas abruptas).Esto puede estar asociado con eventos externos (fallos eléctricos, cambios en la demanda o mantenimiento del sistema) o ajustes en la infraestructura que alteraron momentáneamente los registros. 2022–2025: Se observa una alta concentración de outliers en la parte superior de la serie, especialmente en los valores más altos de potencia (por encima de 7500). Esto indica un incremento de la variabilidad o posiblemente una saturación del sistema, donde las mediciones superan los niveles esperados con frecuencia.También podría sugerir la presencia de nuevas condiciones operativas no captadas por el modelo (por ejemplo, aumento de la capacidad instalada o un cambio en los hábitos de consumo). Los outliers más extremos se presentan en valores cercanos a 0 y por encima de 9000, indicando errores o comportamientos anómalos graves. En los periodos intermedios (2019–2020 y 2023–2024), los picos son muy frecuentes, lo que puede afectar la estimación de parámetros del modelo si no se tratan adecuadamente. La presencia de tantos outliers sugiere que la serie presenta eventos atípicos recurrentes, los cuales rompen la suposición de normalidad y homocedasticidad requerida por muchos modelos de series temporales. Es recomendable tratar o ajustar estos valores antes del modelado. # Supuestos del modelo ARIMA (residuales) checkresiduals(m_auto) # ACF de residuales, Ljung-Box, histograma, qq-plot ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,1)(0,0,2)[24] ## Q* = 3889, df = 44, p-value &lt; 2.2e-16 ## ## Model df: 4. Total lags used: 48 Ljung-Box test La prueba de Ljung–Box aplicada a los residuales del modelo ARIMA(1,1,1)(0,0,2)[24], se realiza para evaluar la independencia (no autocorrelación) de los residuos en un modelo de series temporales. El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, los residuos presentan autocorrelación, el modelo no explica completamente la dependencia temporal. Los residuos NO son ruido blanco, es decir, conservan autocorrelación significativa a lo largo del tiempo. Diagnósticos residuales del modelo ARIMA(1,1,1)(0,0,2)[24] Estas tres gráficas es evaluar si los residuos del modelo cumplen los supuestos de un buen ajuste estadístico: independencia, homocedasticidad y normalidad. La primera gráfica representa los residuos en el tiempo (diferencia entre los valores observados y los predichos por el modelo ARIMA). Cada punto corresponde al error de predicción en una hora. Los residuos oscilan alrededor de 0, lo cual es un signo deseable. Sin embargo, la amplitud de las oscilaciones aumenta considerablemente con el tiempo (desde 2020 en adelante). Esto evidencia heterocedasticidad, la varianza de los errores no es constante a lo largo del tiempo. Hay picos extremos, tanto positivos como negativos (superiores a ±10.000), lo que sugiere la presencia de outliers o errores sistemáticos del modelo en determinados periodos. Las secciones con mayor densidad de oscilaciones indican que el modelo no logra seguir bien los cambios de nivel o tendencia en esas etapas (por ejemplo, entre 2022 y 2025, coincidiendo con tus resultados de cambio estructural). Los residuos no son homogéneos ni estacionarios en varianza. Esto implica que el modelo ARIMA(1,1,1)(0,0,2)[24] no captura completamente la dinámica temporal ni la variabilidad creciente de la serie. ACF (Función de Autocorrelación de los residuos), mide la dependencia serial entre los residuos en diferentes rezagos (lags). Las líneas azules representan los límites de confianza (±1.96/√n), dentro de los cuales las autocorrelaciones deberían estar si los residuos fueran puro ruido blanco. En los primeros rezagos (1–10), se aprecian barras que superan los límites de confianza, indicando autocorrelación significativa. A partir del lag 24 (una periodicidad diaria), todavía se observa un patrón repetitivo leve, lo que sugiere persistencia estacional no explicada. El resto de los lags muestran valores cercanos a 0, pero el exceso inicial es suficiente para rechazar la hipótesis de independencia. Los residuos no son completamente independientes, existen dependencias a corto plazo (y posiblemente estacionales) que el modelo no eliminó. Esto coincide con el resultado del test de Ljung–Box, que arrojó un p-valor &lt; 2.2e-16, confirmando la autocorrelación residual. Histograma y densidad de los residuos, muestra la distribución de los errores del modelo comparada con una curva normal teórica (línea roja). La distribución está altamente concentrada en torno a 0, pero con colas muy largas y picos extremos. Es decir, los residuos no siguen una distribución normal (hay asimetría y curtosis alta). Existen muchos valores extremos tanto positivos como negativos, coherentes con los outliers detectados. La curva teórica normal (en rojo) es mucho más estrecha que la real, lo que confirma la no normalidad de los residuos. Los residuos no son normales, presentando colas pesadas y picos excesivos.Esto sugiere que el modelo no solo deja autocorrelación, sino también errores estructurados y variabilidad anómala. Las tres gráficas indican que el modelo ARIMA(1,1,1)(0,0,2)[24] no logra capturar completamente la estructura de la serie temporal. Los residuos conservan autocorrelación, varianza no constante y outliers, por lo que no pueden considerarse ruido blanco. 4.9.1 Q–Q Plot de los residuos del modelo ARIMA # 1) Extraer residuos del modelo ajustado residuales &lt;- residuals(m_auto) # 2) Q-Q Plot base (comparación con distribución normal) qqnorm(residuales, main = &quot;Q–Q Plot de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24]&quot;, xlab = &quot;Cuantiles teóricos (Normal)&quot;, ylab = &quot;Cuantiles de los residuos&quot;, pch = 19, col = &quot;#1f77b4&quot;, cex = 0.8) qqline(residuales, col = &quot;red&quot;, lwd = 2) El Q–Q Plot (Quantile–Quantile Plot) de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24], una herramienta fundamental para evaluar la normalidad de los errores del modelo. En el eje X (horizontal) se representan los cuantiles teóricos de una distribución normal estándar. En el eje Y (vertical) se muestran los cuantiles observados de los residuos del modelo. La línea roja representa la situación ideal, si los residuos fueran perfectamente normales, los puntos azules se alinearían a lo largo de esa línea. Los puntos se desvían fuertemente de la línea roja, formando una curva escalonada y asimétrica. En las colas (extremos izquierdo y derecho) se observan valores alejados de la recta, indicando colas pesadas o valores extremos. En la zona central (cercana a 0), los puntos permanecen relativamente agrupados, pero el patrón general muestra una marcada asimetría vertical, con una diferencia notable entre los residuos negativos (abajo) y positivos (arriba). La forma escalonada del gráfico indica que los residuos no siguen una distribución normal. Los valores extremos (outliers) son responsables de la curvatura al inicio y al final del gráfico. 4.10 Transformación logarítmica para estabilizar la varianza # ============================================================ # Transformación logarítmica de la serie de potencia # ============================================================ # Evitar log(0) o negativos df_log &lt;- df_impu %&gt;% mutate(val_log = log1p(val_impu)) # log(1 + x) evita infinitos # Crear serie temporal log-transformada ts_log &lt;- ts(df_log$val_log, frequency = 24) # frecuencia diaria (24 horas) # Visualización básica autoplot(ts_log) + labs(title = &quot;Serie transformada logarítmicamente (log1p)&quot;, y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal() La transformación logarítmica se aplicó para reducir la heterocedasticidad (variabilidad creciente con el nivel de la serie), atenuar los valores extremos (outliers), especialmente los picos de alta potencia y aproximar la distribución de los datos a la normalidad, facilitando la aplicación del modelo ARIMA. En otras palabras, se busca estabilizar la varianza y mejorar el cumplimiento de los supuestos del modelo. En la gráfica se observa un comportamiento estructural similar al de la serie original, pero con amplitud comprimida; los picos muy altos (de más de 10.000 en escala original) se reducen a valores entre 7 y 9 en log(1+x); las fluctuaciones bruscas entre periodos de alta y baja potencia se suavizan notablemente; aun cuando existen saltos entre periodos (régimenes distintos), la variabilidad interna dentro de cada tramo es mucho más homogénea. La serie transformada conserva la estructura temporal fundamental (tendencia y estacionalidad) pero elimina gran parte del ruido que dificulta el modelado. 4.11 Ajuste del modelo ARIMA en escala logarítmica # ============================================================ # Ajuste automático ARIMA sobre serie log-transformada # ============================================================ tm(&quot;Ajuste SARIMA TS log-transformada&quot;, { m_log &lt;&lt;- auto.arima(ts_log, seasonal = TRUE, stepwise = FALSE, approximation = arima_approx, trace = TRUE) summary(m_log) }) ## ## Fitting models using approximations to speed things up... ## ## ARIMA(0,1,0) : 114852.4 ## ARIMA(0,1,0) with drift : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] with drift : 114856.4 ## ARIMA(0,1,0)(0,0,2)[24] : 114855.9 ## ARIMA(0,1,0)(0,0,2)[24] with drift : 114857.9 ## ARIMA(0,1,0)(1,0,0)[24] : 114878.2 ## ARIMA(0,1,0)(1,0,0)[24] with drift : 114880.2 ## ARIMA(0,1,0)(1,0,1)[24] : Inf ## ARIMA(0,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(1,0,2)[24] : Inf ## ARIMA(0,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,0)[24] : 114903.7 ## ARIMA(0,1,0)(2,0,0)[24] with drift : 114905.7 ## ARIMA(0,1,0)(2,0,1)[24] : Inf ## ARIMA(0,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,2)[24] : 114907.7 ## ARIMA(0,1,0)(2,0,2)[24] with drift : 114909.7 ## ARIMA(0,1,1) : 114849.4 ## ARIMA(0,1,1) with drift : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] with drift : 114853.4 ## ARIMA(0,1,1)(0,0,2)[24] : 114853 ## ARIMA(0,1,1)(0,0,2)[24] with drift : 114854.9 ## ARIMA(0,1,1)(1,0,0)[24] : 114875.2 ## ARIMA(0,1,1)(1,0,0)[24] with drift : 114877.2 ## ARIMA(0,1,1)(1,0,1)[24] : Inf ## ARIMA(0,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(1,0,2)[24] : Inf ## ARIMA(0,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,0)[24] : 114900.7 ## ARIMA(0,1,1)(2,0,0)[24] with drift : 114902.7 ## ARIMA(0,1,1)(2,0,1)[24] : Inf ## ARIMA(0,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,2)[24] : 114904.7 ## ARIMA(0,1,1)(2,0,2)[24] with drift : 114906.7 ## ARIMA(0,1,2) : 114534.4 ## ARIMA(0,1,2) with drift : 114536.4 ## ARIMA(0,1,2)(0,0,1)[24] : 114536.2 ## ARIMA(0,1,2)(0,0,1)[24] with drift : 114538.2 ## ARIMA(0,1,2)(0,0,2)[24] : 114537.7 ## ARIMA(0,1,2)(0,0,2)[24] with drift : 114539.7 ## ARIMA(0,1,2)(1,0,0)[24] : 114560.1 ## ARIMA(0,1,2)(1,0,0)[24] with drift : 114562.1 ## ARIMA(0,1,2)(1,0,1)[24] : Inf ## ARIMA(0,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,2)(1,0,2)[24] : Inf ## ARIMA(0,1,2)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,2)(2,0,0)[24] : 114585.5 ## ARIMA(0,1,2)(2,0,0)[24] with drift : 114587.5 ## ARIMA(0,1,2)(2,0,1)[24] : Inf ## ARIMA(0,1,2)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,3) : 114522.7 ## ARIMA(0,1,3) with drift : 114524.6 ## ARIMA(0,1,3)(0,0,1)[24] : 114524.4 ## ARIMA(0,1,3)(0,0,1)[24] with drift : 114526.4 ## ARIMA(0,1,3)(0,0,2)[24] : 114526 ## ARIMA(0,1,3)(0,0,2)[24] with drift : 114528 ## ARIMA(0,1,3)(1,0,0)[24] : 114548.3 ## ARIMA(0,1,3)(1,0,0)[24] with drift : 114550.3 ## ARIMA(0,1,3)(1,0,1)[24] : Inf ## ARIMA(0,1,3)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,3)(2,0,0)[24] : 114573.7 ## ARIMA(0,1,3)(2,0,0)[24] with drift : 114575.7 ## ARIMA(0,1,4) : 104511.7 ## ARIMA(0,1,4) with drift : 104513.7 ## ARIMA(0,1,4)(0,0,1)[24] : 104481.2 ## ARIMA(0,1,4)(0,0,1)[24] with drift : 104483.2 ## ARIMA(0,1,4)(1,0,0)[24] : 104504.9 ## ARIMA(0,1,4)(1,0,0)[24] with drift : 104506.9 ## ARIMA(0,1,5) : 104454.2 ## ARIMA(0,1,5) with drift : 104456.2 ## ARIMA(1,1,0) : 114850.7 ## ARIMA(1,1,0) with drift : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] with drift : 114854.7 ## ARIMA(1,1,0)(0,0,2)[24] : 114854.3 ## ARIMA(1,1,0)(0,0,2)[24] with drift : 114856.3 ## ARIMA(1,1,0)(1,0,0)[24] : 114876.6 ## ARIMA(1,1,0)(1,0,0)[24] with drift : 114878.6 ## ARIMA(1,1,0)(1,0,1)[24] : Inf ## ARIMA(1,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(1,0,2)[24] : Inf ## ARIMA(1,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,0)[24] : 114902.1 ## ARIMA(1,1,0)(2,0,0)[24] with drift : 114904.1 ## ARIMA(1,1,0)(2,0,1)[24] : Inf ## ARIMA(1,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,2)[24] : 114906.1 ## ARIMA(1,1,0)(2,0,2)[24] with drift : 114908.1 ## ARIMA(1,1,1) : 111225.1 ## ARIMA(1,1,1) with drift : 111227.1 ## ARIMA(1,1,1)(0,0,1)[24] : 111226.3 ## ARIMA(1,1,1)(0,0,1)[24] with drift : 111228.3 ## ARIMA(1,1,1)(0,0,2)[24] : 111226.8 ## ARIMA(1,1,1)(0,0,2)[24] with drift : 111228.8 ## ARIMA(1,1,1)(1,0,0)[24] : 111250.2 ## ARIMA(1,1,1)(1,0,0)[24] with drift : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] with drift : 111254.2 ## ARIMA(1,1,1)(1,0,2)[24] : Inf ## ARIMA(1,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,1)(2,0,0)[24] : 111274.5 ## ARIMA(1,1,1)(2,0,0)[24] with drift : 111276.5 ## ARIMA(1,1,1)(2,0,1)[24] : Inf ## ARIMA(1,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,2) : 107610.3 ## ARIMA(1,1,2) with drift : 107612 ## ARIMA(1,1,2)(0,0,1)[24] : 107611.4 ## ARIMA(1,1,2)(0,0,1)[24] with drift : 107613.1 ## ARIMA(1,1,2)(0,0,2)[24] : 107612.9 ## ARIMA(1,1,2)(0,0,2)[24] with drift : 107614.5 ## ARIMA(1,1,2)(1,0,0)[24] : 107635.3 ## ARIMA(1,1,2)(1,0,0)[24] with drift : 107637 ## ARIMA(1,1,2)(1,0,1)[24] : 107637.3 ## ARIMA(1,1,2)(1,0,1)[24] with drift : 107639 ## ARIMA(1,1,2)(2,0,0)[24] : 107660.6 ## ARIMA(1,1,2)(2,0,0)[24] with drift : 107662.3 ## ARIMA(1,1,3) : 107440.7 ## ARIMA(1,1,3) with drift : 107442.4 ## ARIMA(1,1,3)(0,0,1)[24] : 107442.1 ## ARIMA(1,1,3)(0,0,1)[24] with drift : 107443.7 ## ARIMA(1,1,3)(1,0,0)[24] : 107466 ## ARIMA(1,1,3)(1,0,0)[24] with drift : 107467.7 ## ARIMA(1,1,4) : 104357.1 ## ARIMA(1,1,4) with drift : 104359.1 ## ARIMA(2,1,0) : 114693.2 ## ARIMA(2,1,0) with drift : 114695.2 ## ARIMA(2,1,0)(0,0,1)[24] : 114695.1 ## ARIMA(2,1,0)(0,0,1)[24] with drift : 114697.1 ## ARIMA(2,1,0)(0,0,2)[24] : 114696.6 ## ARIMA(2,1,0)(0,0,2)[24] with drift : 114698.6 ## ARIMA(2,1,0)(1,0,0)[24] : 114718.9 ## ARIMA(2,1,0)(1,0,0)[24] with drift : 114720.9 ## ARIMA(2,1,0)(1,0,1)[24] : Inf ## ARIMA(2,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,0)(1,0,2)[24] : Inf ## ARIMA(2,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(2,1,0)(2,0,0)[24] : 114744.4 ## ARIMA(2,1,0)(2,0,0)[24] with drift : 114746.4 ## ARIMA(2,1,0)(2,0,1)[24] : Inf ## ARIMA(2,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(2,1,1) : 107556.5 ## ARIMA(2,1,1) with drift : 107558.1 ## ARIMA(2,1,1)(0,0,1)[24] : 107557.7 ## ARIMA(2,1,1)(0,0,1)[24] with drift : 107559.4 ## ARIMA(2,1,1)(0,0,2)[24] : 107559.3 ## ARIMA(2,1,1)(0,0,2)[24] with drift : 107561 ## ARIMA(2,1,1)(1,0,0)[24] : 107581.6 ## ARIMA(2,1,1)(1,0,0)[24] with drift : 107583.2 ## ARIMA(2,1,1)(1,0,1)[24] : 107583.6 ## ARIMA(2,1,1)(1,0,1)[24] with drift : 107585.2 ## ARIMA(2,1,1)(2,0,0)[24] : 107606.9 ## ARIMA(2,1,1)(2,0,0)[24] with drift : 107608.6 ## ARIMA(2,1,2) : 104088.8 ## ARIMA(2,1,2) with drift : 104090.5 ## ARIMA(2,1,2)(0,0,1)[24] : 104087.4 ## ARIMA(2,1,2)(0,0,1)[24] with drift : 104089 ## ARIMA(2,1,2)(1,0,0)[24] : 104111.2 ## ARIMA(2,1,2)(1,0,0)[24] with drift : 104112.9 ## ARIMA(2,1,3) : 104080.4 ## ARIMA(2,1,3) with drift : 104082.1 ## ARIMA(3,1,0) : 114683 ## ARIMA(3,1,0) with drift : 114685 ## ARIMA(3,1,0)(0,0,1)[24] : 114684.9 ## ARIMA(3,1,0)(0,0,1)[24] with drift : 114686.9 ## ARIMA(3,1,0)(0,0,2)[24] : 114686.5 ## ARIMA(3,1,0)(0,0,2)[24] with drift : 114688.5 ## ARIMA(3,1,0)(1,0,0)[24] : 114708.8 ## ARIMA(3,1,0)(1,0,0)[24] with drift : 114710.8 ## ARIMA(3,1,0)(1,0,1)[24] : Inf ## ARIMA(3,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(3,1,0)(2,0,0)[24] : 114734.2 ## ARIMA(3,1,0)(2,0,0)[24] with drift : 114736.2 ## ARIMA(3,1,1) : 107367.9 ## ARIMA(3,1,1) with drift : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] with drift : 107371.3 ## ARIMA(3,1,1)(1,0,0)[24] : 107393.5 ## ARIMA(3,1,1)(1,0,0)[24] with drift : 107395.2 ## ARIMA(3,1,2) : 104077.9 ## ARIMA(3,1,2) with drift : 104079.5 ## ARIMA(4,1,0) : 107261.2 ## ARIMA(4,1,0) with drift : 107263.2 ## ARIMA(4,1,0)(0,0,1)[24] : 107260.4 ## ARIMA(4,1,0)(0,0,1)[24] with drift : 107262.4 ## ARIMA(4,1,0)(1,0,0)[24] : 107284.3 ## ARIMA(4,1,0)(1,0,0)[24] with drift : 107286.3 ## ARIMA(4,1,1) : 107262.6 ## ARIMA(4,1,1) with drift : 107264.6 ## ARIMA(5,1,0) : 107263.9 ## ARIMA(5,1,0) with drift : 107265.9 ## ## Now re-fitting the best model(s) without approximations... ## ## ## ## ## Best model: ARIMA(3,1,2) El mejor modelo ARIMA(3,1,2) tiene: Tres términos autorregresivos (AR), la serie depende de los tres valores anteriores de sí misma. Diferenciación (d=1), se toma la primera diferencia para estabilizar la tendencia. Dos términos de media móvil (MA) presentaron el menor AICc (Akaike Information Criterion corregido), por tanto, el mejor equilibrio entre ajuste y simplicidad. ARIMA(3,1,2) describe una dinámica compleja pero estable, donde tanto la inercia de los valores pasados como los errores anteriores influyen en la predicción actual. 4.12 Verificación de supuestos del nuevo modelo # ============================================================ # Diagnóstico de los residuos del modelo ARIMA (log) # ============================================================ checkresiduals(m_log) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,1,2) ## Q* = 3151.5, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, existe autocorrelación significativa en los errores a ciertos rezagos. El modelo ARIMA(3,1,2), aunque mejora respecto al anterior, no captura toda la estructura dependiente de la serie. Diagnósticos residuales del modelo ARIMA(3,1,2) Los residuos son en general estacionarios, pero aún presentan fluctuaciones en la varianza y algunos picos pronunciados que podrían afectar la normalidad. El modelo logra reducir significativamente la autocorrelación, aunque persisten correlaciones menores en rezagos cortos, coherentes con el resultado del test de Ljung–Box La distribución de los residuos se aproxima a la normalidad, aunque no perfectamente. La transformación logarítmica ayudó a estabilizar la varianza, pero persisten valores extremos. 4.13 Pronóstico con el modelo mejorado (escala logarítmica) # ============================================================ # Pronóstico en escala logarítmica # ============================================================ h &lt;- 24 * horizon_days # pronóstico a 7 días (horas) fc_log &lt;- forecast(m_log, h = h) autoplot(fc_log) + labs(title = paste0(&quot;Pronóstico log-transformado con ARIMA (&quot;, horizon_days, &quot; días)&quot;), y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal(base_size = 12) 4.13.1 Reconversión a escala original (exponencial inversa) # ============================================================ # Transformar el pronóstico a escala original # ============================================================ fc_exp &lt;- expm1(fc_log$mean) # inversa de log1p fc_exp80 &lt;- expm1(fc_log$lower[,&quot;80%&quot;]) fc_exp95 &lt;- expm1(fc_log$upper[,&quot;95%&quot;]) # Crear data frame para visualización f_times &lt;- seq(from = max(df_impu[[time_col]]) + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) fc_plot &lt;- tibble( time = f_times, mean = fc_exp, lo80 = fc_exp80, hi80 = fc_exp95 ) # Graficar pronóstico en escala original ggplot(fc_plot, aes(x = time, y = mean)) + geom_ribbon(aes(ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25) + geom_line(color = &quot;#1f77b4&quot;, linewidth = 1.1) + labs(title = &quot;Pronóstico ARIMA (log-transformado, 7 días)&quot;, subtitle = &quot;Transformación log(1 + x) revertida a escala original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia estimada&quot;) + theme_minimal(base_size = 12) El modelo proyecta una potencia promedio estable a lo largo del horizonte de 7 días, con un leve crecimiento progresivo. Este patrón indica que no se esperan cambios abruptos ni tendencia marcada en el corto plazo, lo cual concuerda con una serie que, tras la transformación y diferenciación, se comporta de manera estacionaria. Las bandas de confianza se ensanchán conforme avanza el tiempo, lo que es normal en modelos ARIMA: la incertidumbre aumenta al alejarnos de la última observación disponible. La transformación log1p() redujo la asimetría de la serie, estabilizó la varianza y permitió que el modelo ARIMA se ajustara mejor. Al revertir la transformación (exp(x) - 1), los valores pronosticados se amplifican exponencialmente, por lo que incluso pequeñas variaciones en los residuos logarítmicos se traducen en grandes rangos de incertidumbre en la escala original. 4.14 Conclusiones El análisis realizado sobre la serie temporal de potencia permitió evaluar y comparar el desempeño del modelo ARIMA bajo dos enfoques: primero, utilizando la serie en su escala original, y posteriormente aplicando una transformación logarítmica (log1p) para estabilizar la varianza y mejorar la capacidad predictiva del modelo. Modelo con la serie original El ajuste inicial con el modelo ARIMA(1,1,1)(0,0,2)[24] mostró limitaciones en los residuos: El test de Ljung–Box (Q = 3889, p &lt; 0.05)* reveló autocorrelación significativa, indicando que el modelo no capturó completamente la estructura temporal de los datos. Los gráficos diagnósticos evidenciaron heterocedasticidad y valores atípicos, lo cual afectó la normalidad de los residuos. En consecuencia, aunque el modelo reprodujo la tendencia general, su precisión predictiva fue limitada y las bandas de confianza del pronóstico resultaron amplias e inestables. Modelo con la serie log-transformada Para mejorar el comportamiento del modelo, se aplicó una transformación logarítmica que redujo la variabilidad extrema y permitió una distribución más simétrica. El modelo seleccionado automáticamente fue ARIMA(3,1,2), que presentó un AIC significativamente menor (≈ 104 080 frente a &gt;111 000 en la serie original), reflejando un mejor ajuste global. Los residuos del modelo se centraron alrededor de cero, con autocorrelación mínima y distribución casi normal. El test de Ljung–Box (Q = 3151, p &lt; 0.05)* indicó todavía cierta dependencia remanente, aunque en menor grado que el modelo previo. El pronóstico a 7 días, una vez revertida la transformación (exp(x) - 1), mostró una tendencia estable y coherente con el comportamiento reciente de la serie, con bandas de confianza más razonables que en el caso anterior, aunque naturalmente amplias por la incertidumbre acumulada. En conclusión, el modelo ARIMA aplicado sobre la serie original permitió identificar la tendencia general, pero su desempeño predictivo se vio afectado por la alta varianza y la presencia de valores atípicos. En contraste, la aplicación de la transformación logarítmica mejoró la calidad del ajuste, redujo la dispersión y generó un modelo ARIMA(3,1,2) más parsimonioso y estable, con predicciones más coherentes y bandas de confianza razonables. En términos prácticos, se evidencia que la transformación logarítmica es una estrategia efectiva para estabilizar la varianza y mejorar la capacidad de predicción de modelos ARIMA en series con gran amplitud y comportamiento no estacionario. Por tanto, se recomienda utilizar la versión log-transformada para futuras predicciones y análisis, dado que ofrece un mejor equilibrio entre ajuste, estabilidad y capacidad interpretativa, reflejando de manera más realista la evolución de la potencia en el tiempo. Se recomienda analizar los valores de potencia de la serie de tiempo de forma independiente para cada uno de los tres circuitos eléctricos que conforman la potencia de salida de la subestación. Asimismo, se sugiere generar predicciones individuales por circuito y consolidarlas posteriormente. Esta estrategia permite evitar problemas de valores faltantes y atípicos, además de reducir la variabilidad de los datos. 4.14.1 Resumen de tiempos de ejecución del código tabla_tiempos &lt;- report_timing_table() if (!is.null(tabla_tiempos)) { knitr::kable(tabla_tiempos, caption = &quot;Resumen de tiempos por bloque&quot;) } else { cat(&quot;No se registraron bloques cronometrados.\\n&quot;) } Table 4.1: Resumen de tiempos por bloque Bloque Tiempo Unidad Estado Mensaje Imputación (na.interp) 0.024 s OK ACF/PACF (original) 0.139 s OK ACF/PACF (diferenciada) 0.124 s OK STL (ventana 4 semanas) 0.037 s OK Ajuste SARIMA + Pronóstico 213.879 s OK Changepoint (media diaria, PELT) 0.026 s OK Ajuste SARIMA TS log-transformada 417.990 s OK "],["Modelización.html", "5 Modelos de pronóstico - Metodología Holt – Winter 5.1 Resumen 5.2 Cambio de la serie de tiempo a circuito de potencia - Preprocesamiento y visualización 5.3 Preprocesamiento de la serie de datos para Holt–Winters 5.4 División de los datos entre TRAIN/TEST 5.5 Ajuste Holt–Winters aditivo y multiplicativo (usando TRAIN y h definidos) 5.6 Gráfica comparativa: TRAIN/TEST + pronósticos HW (aditivo vs. multiplicativo) 5.7 Evaluación en TEST (MAPE y RMSE) 5.8 Comparación con un ARIMA simple 5.9 Holt Winter en Box–Cox (ajuste + pronóstico en BC + reconversión a escala original) 5.10 Gráfica comparativa (TRAIN/TEST en original) + HW Box–Cox reconvertido 5.11 Zoom al pronóstico Holt Winter Box–Cox en original 5.12 Métricas en TEST comparando en escala original (Holt Winter y Box–Cox) 5.13 Resumen final de métricas (RMSE / MAPE) 5.14 Gráficas de predicción por modelo 5.15 Resumen de tiempos de ejecución del código", " 5 Modelos de pronóstico - Metodología Holt – Winter 5.1 Resumen Los métodos de suavizamiento desempeñan un papel fundamental, ya que permiten reducir el ruido en los datos, resaltando la estructura subyacente de la serie. Entre ellos, destacan el promedio móvil, el suavizamiento exponencial simple y el modelo de Holt-Winters, que constituye una extensión más completa capaz de captar tanto la tendencia como la estacionalidad. En este capítulo se aplica el método de Holt-Winters como herramienta de predicción para series con comportamiento no estacionario. Sin embargo, la serie de datos analizada en el capitulo anterior presenta alta variabilidad en los datos debido a que corresponde a la sumatoria de tres series de datos asociados a los circuitos de salida de la subestación eléctrica, de las cuales, una serie presenta faltantes aproximadamente en el 50% del horizonte de tiempo, objeto de este estudio; otra serie presente aproximadamente un 25% de faltantes, sumada a una alta variabilidad en las media de la potencia, generando un gran porcentaje de outliers probablemente incorrectos. Razón por la cual, para continuar con el análisis de la serie de tiempo, seleccionamos solo un circuito de salida que tiene la tendencia más estable con un bajo porcentaje de datos faltantes. 5.2 Cambio de la serie de tiempo a circuito de potencia - Preprocesamiento y visualización 5.2.1 Carga de librerías library(readr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(scales) library(zoo) library(forecast) library(tseries) library(changepoint) 5.2.2 Carga de datos y visualización csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot;; y_col &lt;- &quot;VALOR_IMPUTADO&quot; df &lt;- tryCatch(readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE)) # Parseo robusto de fecha-hora y valor df[[time_col]] &lt;- parse_date_time(df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ) df[[y_col]] &lt;- suppressWarnings(as.numeric(df[[y_col]])) # Malla horaria completa para marcar NA (sin imputar) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% arrange(.data[[time_col]]) %&gt;% select(!!time_col, !!y_col) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) # Serie imputada (para métodos que exigen regularidad) tm(&quot;Imputación (na.interp)&quot;, { df_impu &lt;&lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) }) # Vista rápida # ggplot(df_full, aes(x = .data[[time_col]], y = .data[[y_col]])) + # geom_line(na.rm = TRUE) + # labs(title = &quot;Serie horaria de potencia (con huecos)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal() na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } agg_by &lt;- function(data, unit, label, time_col, y_col) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% mutate(freq = label) } na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) diaria &lt;- agg_by(df_full, &quot;day&quot;, &quot;Diaria&quot;, time_col, y_col) semanal &lt;- agg_by(df_full, &quot;week&quot;, &quot;Semanal&quot;, time_col, y_col) mensual &lt;- agg_by(df_full, &quot;month&quot;, &quot;Mensual&quot;, time_col, y_col) anual &lt;- agg_by(df_full, &quot;year&quot;, &quot;Anual&quot;, time_col, y_col) plot_df &lt;- bind_rows(diaria, semanal, mensual, anual) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;, &quot;Semanal&quot;, &quot;Mensual&quot;, &quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.3) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.6, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + labs(title = &quot;Potencia — vistas diaria, semanal, mensual y anual&quot;, subtitle = &quot;Bandas rojas: periodos con NA en la serie original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) La serie presenta coherencia temporal y crecimiento moderado en todas las escalas. Existen períodos con datos faltantes y posible ruido o outliers en la frecuencia diaria, que en las gráficas semanal, mensual y anual se atenúan. Esta exploración multiescala sugiere que la serie es adecuada para modelar con métodos como Holt–Winters o ARIMA, siempre y cuando antes se aplique imputación de valores faltantes, detección y corrección de outliers, y estabilización de la varianza. 5.2.3 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación # Vector numérico imputado serie_vec &lt;- as.numeric(df_impu$val_impu) # ADF en serie original adf_raw &lt;- tseries::adf.test(serie_vec, k = 24) adf_raw ## ## Augmented Dickey-Fuller Test ## ## data: serie_vec ## Dickey-Fuller = -37.721, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria en media. # Diferenciación sugerida y gráfico d_sugerido &lt;- forecast::ndiffs(serie_vec) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 “ndiffs” sugiere una diferenciación (d = 1) para estabilizar tendencia y variabilidad. serie_diff &lt;- if (d_sugerido &gt; 0) diff(serie_vec, differences = d_sugerido) else serie_vec df_diff &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]])[seq_along(serie_vec)], Original = as.numeric(serie_vec), Diferenciada = c(rep(NA, d_sugerido), as.numeric(serie_diff)) ) |&gt; tidyr::pivot_longer(cols = c(Original, Diferenciada), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) ggplot(df_diff, aes(time, Valor, color = Serie)) + geom_line(linewidth = 0.6, alpha = 0.9, na.rm = TRUE) + scale_color_manual(values = c(Original = &quot;#6B7280&quot;, Diferenciada = &quot;#1F77B4&quot;)) + labs(title = &quot;Serie original vs. diferenciada&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia / ΔPotencia&quot;, color = &quot;Serie&quot;) + theme_minimal(base_size = 12) La serie diferenciada muestra valores centrados alrededor de cero, eliminando la tendencia de largo plazo. La dispersión es más estable y simétrica, lo que indica que la varianza se ha homogenizado. La diferenciación logró transformar la serie en estacionaria, condición necesaria para aplicar modelos como ARIMA. Aún se observan algunos picos esporádicos (outliers) que podrían representar eventos atípicos o ruido extremo. # ADF nuevamente si se diferenció if (d_sugerido &gt; 0) { cat(&quot;\\nRe-prueba ADF en la serie diferenciada (d =&quot;, d_sugerido, &quot;):\\n&quot;) print(tseries::adf.test(serie_diff, k = 24)) } ## ## Re-prueba ADF en la serie diferenciada (d = 1 ): ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff ## Dickey-Fuller = -91.466, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) para la serie diferenciada indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria. La serie diferenciada (d = 1) cumple con el requisito de estacionariedad, condición indispensable para la modelación ARIMA. No se requieren más diferenciaciones. 5.2.4 ACF y PACF (original y diferenciada) # ============================================================ # 6. ACF y PACF (original y diferenciada) # ============================================================ # --- Calcular ACF/PACF de la serie original --- t0 &lt;- Sys.time() acf_obj &lt;- try(acf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_obj &lt;- try(pacf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (original)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_obj, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) # --- Graficar ACF/PACF de la serie original --- if (!inherits(acf_obj, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_obj, &quot;try-error&quot;)) { acf_df &lt;- data.frame(lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf)) pacf_df &lt;- data.frame(lag = as.numeric(pacf_obj$lag), pacf = as.numeric(pacf_obj$acf)) ci &lt;- 1.96 / sqrt(length(serie_vec)) p1 &lt;- ggplot(acf_df, aes(lag, acf)) + geom_col(fill = &quot;#1f77b4&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p2 &lt;- ggplot(pacf_df, aes(lag, pacf)) + geom_col(fill = &quot;#ff7f0e&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p1); print(p2) } else { cat(&quot;Error al calcular ACF/PACF de la serie original.\\n&quot;) } # --- Serie diferenciada --- if (exists(&quot;serie_diff&quot;) &amp;&amp; length(serie_diff) &gt; 10 &amp;&amp; !identical(serie_diff, serie_vec)) { t0 &lt;- Sys.time() acf_d &lt;- try(acf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_d &lt;- try(pacf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (diferenciada)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_d, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) if (!inherits(acf_d, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_d, &quot;try-error&quot;)) { acf_df_d &lt;- data.frame(lag = as.numeric(acf_d$lag), acf = as.numeric(acf_d$acf)) pacf_df_d &lt;- data.frame(lag = as.numeric(pacf_d$lag), pacf = as.numeric(pacf_d$acf)) ci_d &lt;- 1.96 / sqrt(length(serie_diff)) p3 &lt;- ggplot(acf_df_d, aes(lag, acf)) + geom_col(fill = &quot;#17becf&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p4 &lt;- ggplot(pacf_df_d, aes(lag, pacf)) + geom_col(fill = &quot;#2ca02c&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p3); print(p4) } else { cat(&quot;Error al calcular ACF/PACF diferenciada.\\n&quot;) } } La ACF de la serie original presenta una decadencia lenta y oscilante, sin cortar bruscamente, lo que indica que la serie no es estacionaria. Se observan picos significativos en rezagos cercanos a 24, 48, 72, 96 y 120 horas (múltiplos de 24), lo cual sugiere una estacionalidad diaria (ciclos de 24 h). El patrón sinusoidal de la ACF evidencia repetición de ciclos de comportamiento, probablemente relacionados con el uso o generación de potencia a lo largo del día. La PACF de la serie original muestra un pico muy fuerte en el primer rezago (lag 1) y luego decae rápidamente a valores cercanos a cer, esto indica alta autocorrelación inmediata, es decir, el valor actual depende fuertemente del valor anterior. El resto de los rezagos no son significativos, lo que refuerza la presencia de una tendencia o componente autorregresiva dominante. La serie original no es estacionaria, presenta tendencia y una fuerte estacionalidad diaria. Esto confirma la necesidad de diferenciar la serie antes del modelado ARIMA. La ACF de la serie diferenciada muestra que los valores caen a cero rápidamente, salvo en algunos rezagos aislados. La pérdida de la estructura oscilante confirma que la tendencia fue eliminada y que la serie se ha vuelto más estacionaria. Persisten algunos picos moderados en múltiplos de 24 horas, indicando que aún hay componente estacional residual (ciclo diario). En la PACF de la serie diferenciada muestra solo unos pocos rezagos significativos (lag 1 y algunos alrededor de 24), suguiriendo que podría haber un componente AR de bajo orden (p ≈ 1) y posiblemente un componente estacional AR o MA en los múltiplos de 24. La diferenciación logró estacionarizar la serie, eliminando la tendencia. 5.2.5 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else if (&quot;VALOR_IMPUTADO&quot; %in% names(df_impu)) &quot;VALOR_IMPUTADO&quot; else stop(&quot;No encuentro columna de valores: usa &#39;val_impu&#39; o &#39;VALOR_IMPUTADO&#39;.&quot;) # Utilidad para detectar columna estacional por periodo (acepta &#39;Seasonal-24&#39;, &#39;Seasonal 24&#39;, etc.) find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) if (!any(is_seas)) return(NULL) seas_nm &lt;- nm[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # ========== A) df_seas24: Estacionalidad diaria (24h) desde SERIE HORARIA ========== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_m_hour &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_h &lt;- as.data.frame(fit_m_hour) col_s24 &lt;- find_seasonal_col(comp_h, 24) if (is.null(col_s24)) { # fallback: primera &#39;Seasonal&#39; si no se pudo detectar 24 específicamente cand &lt;- grep(&quot;^Seasonal&quot;, names(comp_h), ignore.case = TRUE, value = TRUE) col_s24 &lt;- cand[1] } df_seas24 &lt;- tibble( time = time_hr, Componente = &quot;Estacionalidad diaria (24h)&quot;, Valor = comp_h[[col_s24]] ) # ========== B) df_seas12: Estacionalidad mensual (12) desde SERIE MENSUAL ========== monthly &lt;- df_impu %&gt;% mutate(mes = floor_date(.data[[time_col]], &quot;month&quot;)) %&gt;% summarise(.by = mes, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(mes) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(year(min(monthly$mes)), month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # detectar columna estacional (nombre puede ser &quot;seasonal&quot;/&quot;Seasonal&quot;) seas_col_m &lt;- names(comp_m)[grepl(&quot;season&quot;, names(comp_m), ignore.case = TRUE)][1] if (is.na(seas_col_m)) stop(&quot;No se encontró columna estacional en STL mensual.&quot;) df_seas12 &lt;- tibble( time = as.POSIXct(monthly$mes), # unificamos a POSIXct Componente = &quot;Estacionalidad mensual (12)&quot;, Valor = comp_m[[seas_col_m]] ) # ========== C) df_day_panel: Observada, Tendencia, Semanal(7d), Anual(365d), Residuo (SERIE DIARIA) ========== daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% summarise(.by = day, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(day) ts_day &lt;- forecast::msts(daily$y, seasonal.periods = c(7, 365)) fit_m_day &lt;- forecast::mstl(ts_day, robust = TRUE) comp_d &lt;- as.data.frame(fit_m_day) # Normalizamos nombres para &#39;Trend&#39; y &#39;Remainder&#39; nmd &lt;- names(comp_d) nmd &lt;- sub(&quot;^trend$&quot;, &quot;Trend&quot;, nmd, ignore.case = TRUE) nmd &lt;- sub(&quot;^remainder$&quot;, &quot;Remainder&quot;, nmd, ignore.case = TRUE) names(comp_d) &lt;- nmd # Detectar columnas estacionales 7 y 365 is_seas &lt;- grepl(&quot;^Seasonal&quot;, names(comp_d), ignore.case = TRUE) seas_nms &lt;- names(comp_d)[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } seas_p &lt;- vapply(seas_nms, getp, integer(1)) idx7 &lt;- which(seas_p == 7) idx365 &lt;- which(seas_p == 365) seas7 &lt;- if (length(idx7)) comp_d[[seas_nms[idx7[1]]]] else NULL seas365 &lt;- if (length(idx365)) comp_d[[seas_nms[idx365[1]]]] else NULL df_day_panel &lt;- tibble( time = as.POSIXct(daily$day), Observada = daily$y, Tendencia = if (&quot;Trend&quot; %in% names(comp_d)) comp_d$Trend else NA_real_, Residuo = if (&quot;Remainder&quot; %in% names(comp_d)) comp_d$Remainder else NA_real_ ) if (!is.null(seas7)) df_day_panel[[&quot;Estacionalidad semanal (7d)&quot;]] &lt;- seas7 if (!is.null(seas365)) df_day_panel[[&quot;Estacionalidad anual (365d)&quot;]] &lt;- seas365 df_day_panel &lt;- df_day_panel |&gt; pivot_longer(-time, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) # ========== D) Panel combinado ========== panel_all &lt;- bind_rows( df_day_panel, # Observada/Tendencia/Residuo + 7d/365d si existen df_seas24, # Estacionalidad diaria (24h) desde HORAS df_seas12 # Estacionalidad mensual (12) desde MESES ) %&gt;% mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;, &quot;Tendencia&quot;, &quot;Estacionalidad diaria (24h)&quot;, &quot;Estacionalidad semanal (7d)&quot;, &quot;Estacionalidad mensual (12)&quot;, &quot;Estacionalidad anual (365d)&quot;, &quot;Residuo&quot;) ) ) # ========== E) Gráfico ========== ggplot(panel_all, aes(x = time, y = Valor)) + geom_line(linewidth = 0.45, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;, drop = FALSE) + scale_x_datetime(date_breaks = &quot;6 months&quot;, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) + labs( title = &quot;Descomposición combinada de la serie completa&quot;, subtitle = &quot;Tendencia + Estacionalidades diaria (24h), semanal (7d), mensual (12) y anual (365d) + Residuo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) La descomposición evidencia que la serie de potencia es altamente estructurada, con una tendencia creciente de largo plazo, ciclos estacionales fuertes en las escalas diaria y semanal, modulaciones mensuales y anuales de menor intensidad y un residuo controlado, con algunos eventos atípicos aislados. 5.2.6 Promedios móviles (24h, 168h, 720h) df_ma &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]]), Original = as.numeric(df_impu$val_impu), MA_24 = as.numeric(zoo::rollmean(df_impu$val_impu, 24, align = &quot;right&quot;, fill = NA)), MA_168 = as.numeric(zoo::rollmean(df_impu$val_impu, 168, align = &quot;right&quot;, fill = NA)), MA_720 = as.numeric(zoo::rollmean(df_impu$val_impu, 720, align = &quot;right&quot;, fill = NA)) ) ggplot(df_ma, aes(x = time)) + geom_line(aes(y = Original), color = &quot;grey70&quot;, linewidth = 0.3, alpha = 0.6, na.rm = TRUE) + # Halo para la verde geom_line(aes(y = MA_168), color = &quot;white&quot;, linewidth = 1.8, alpha = 0.9, na.rm = TRUE) + # Mapear color con etiquetas literales -&gt; leyenda geom_line(aes(y = MA_24, color = &quot;MA 24h&quot;), linewidth = 1.0, alpha = 0.95, na.rm = TRUE) + geom_line(aes(y = MA_168, color = &quot;MA 168h&quot;), linewidth = 1.0, alpha = 1.00, na.rm = TRUE) + geom_line(aes(y = MA_720, color = &quot;MA 720h&quot;), linewidth = 1.0, alpha = 0.95, na.rm = TRUE) + scale_color_manual( values = c(&quot;MA 24h&quot; = &quot;#1f77b4&quot;, &quot;MA 168h&quot; = &quot;#00B050&quot;, &quot;MA 720h&quot; = &quot;#D62728&quot;), name = &quot;Serie&quot;, breaks = c(&quot;MA 24h&quot;, &quot;MA 168h&quot;, &quot;MA 720h&quot;), labels = c(&quot;MA 24h (1 día)&quot;, &quot;MA 168h (1 semana)&quot;, &quot;MA 720h (1 mes)&quot;) ) + labs(title = &quot;Promedios móviles (24h, 168h, 720h)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), legend.position = &quot;right&quot;, panel.grid.minor = element_blank()) Las tres curvas muestran consistencia ascendente: la serie tiende a crecer lentamente con el tiempo. Las diferencias de amplitud entre los promedios móviles demuestran que la serie presenta alta volatilidad horaria, pero un comportamiento más estable a mediano y largo plazo. Los picos muy marcados, especialmente entre 2019 y 2024, pueden deberse a eventos excepcionales o registros atípicos, sin afectar la tendencia general. El análisis de promedios móviles evidencia una serie con fuerte variabilidad de corto plazo, pero con una tendencia creciente sostenida en el largo plazo. 5.2.7 Selección del modelo eficiente (auto.arima) y Pronóstico tm(&quot;Ajuste SARIMA + Pronóstico&quot;, { y_fit &lt;&lt;- ts(serie_vec, frequency = 24) m_auto &lt;&lt;- forecast::auto.arima( y_fit, d = d_sugerido, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx, max.p = 5, max.q = 5, max.P = 2, max.Q = 2 ) print(m_auto) h_days &lt;&lt;- horizon_days h &lt;&lt;- 24 * h_days fc &lt;&lt;- forecast::forecast(m_auto, h = h) print(autoplot(fc) + labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;)) }) ## Series: y_fit ## ARIMA(1,1,1)(2,0,1)[24] with drift ## ## Coefficients: ## ar1 ma1 sar1 sar2 sma1 drift ## 0.3106 -0.2732 0.5660 0.1735 -0.5697 0.0069 ## s.e. 0.0315 0.0319 0.0197 0.0047 0.0205 0.2816 ## ## sigma^2 = 3105: log likelihood = -645389 ## AIC=1290792 AICc=1290792 BIC=1290860 5.2.7.1 Zoom al pronóstico del modelo eficiente (auto.arima) # ==== ZOOM FINAL AL PRONÓSTICO ==== history_days &lt;- 21 h_days &lt;- horizon_days %||% 7 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) h &lt;- length(fc$mean) f_times &lt;- seq(from = t_max + hours(1), by = &quot;1 hour&quot;, length.out = h) fc_df &lt;- tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[,&quot;80%&quot;]), hi80 = as.numeric(fc$upper[,&quot;80%&quot;]), lo95 = as.numeric(fc$lower[,&quot;95%&quot;]), hi95 = as.numeric(fc$upper[,&quot;95%&quot;]) ) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.4, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, # ← espaciado más grande date_labels = &quot;%d-%b&quot;) + # ← formato sin hora coord_cartesian(ylim = c(0, 2000)) + # recorta sin descartar filas labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1) # ← evita solapamiento ) El modelo captura una estructura diaria muy fuerte y una persistencia corta; la tendencia ya fue removida con d = 1; el “drift” es irrelevante. En la gráfica general el pronóstico es casi invisible por el rango y la alta variabilidad histórica (picos/outliers). En la gráfica de pronóstico, la línea azul se mantiene alrededor de 850–950 (un nivel cercano al observado justo antes del corte), con ondulación diaria y ciclos de 24 h. El SARIMA escogido capta el patrón diario y da una proyección estable a 7 días, pero la incertidumbre es alta por la variabilidad de la serie. Las bandas amplias avisan que, en escala original, la serie es muy heterocedástica y contiene outliers. 5.2.8 Puntos de cambio y visualización daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% group_by(day) %&gt;% summarise(y = mean(val_impu), .groups = &quot;drop&quot;) tm(&quot;Changepoint&quot;, { cp &lt;&lt;- cpt.mean(daily$y, method = &quot;PELT&quot;, penalty = &quot;SIC&quot;) }) head (cp@cpts,100) # índices de cambio ## [1] 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ## [19] 48 49 50 51 52 53 54 55 57 58 59 60 61 62 63 64 66 67 ## [37] 68 69 70 71 72 73 74 75 76 77 79 80 81 82 83 84 85 86 ## [55] 87 88 89 90 91 92 93 94 95 97 98 99 100 101 102 103 104 105 ## [73] 106 107 109 110 111 112 113 114 115 116 117 118 119 120 121 123 124 125 ## [91] 126 127 128 129 130 131 132 134 136 137 # Overlay en la curva diaria ggplot(daily, aes(day, y)) + geom_line() + geom_vline(xintercept = daily$day[cp@cpts], linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Media diaria con puntos de cambio (cpt.mean)&quot;, x = &quot;Día&quot;, y = &quot;Potencia media diaria&quot;) + theme_minimal() Líneas rojas horizontales indican los puntos de cambio detectados en la media de la serie. Cada uno de ellos marca un momento en el que el nivel promedio de la potencia cambió de manera estadísticamente significativa. Se observa en la gráfica: Alta frecuencia de puntos de cambio (bandas rojas), sugiriendo que la serie es altamente inestable o no estacionaria a lo largo del tiempo. Cambios localizados por períodos, entre 2018 y 2020, la serie muestra mayor variabilidad y frecuentes saltos reflejando volátilidad o errores de registro. Entre 2021 y 2024, los cambios son menos abruptos, aunque todavía se observan alteraciones cíclicas en los promedios diarios. Entre 2024–2025, la media parece estabilizarse en un rango más constante, pero aún con picos esporádicos (outliers). La media diaria parece mostrar una tendencia leve al alza, con algunos descensos temporales; los puntos de cambio ayudan a identificar momentos clave donde la serie cambió de nivel promedio. La gráfica evidencia que la potencia media diaria ha experimentado múltiples rupturas estructurales en su comportamiento a lo largo de los años. Estas discontinuidades confirman que la serie no es estacionaria en media y requiere preprocesamiento o modelado segmentado. 5.2.9 Outliers y verificación de supuestos del ARIMA # Outliers to &lt;- tryCatch(forecast::tsoutliers(ts(serie_vec, frequency = 24)), error = function(e) NULL) if (!is.null(to)) { #print(to) idx &lt;- to$index df_ol &lt;- tibble(time = as.POSIXct(df_impu[[time_col]])[idx], y = serie_vec[idx]) ggplot(tibble(time = as.POSIXct(df_impu[[time_col]]), y = serie_vec), aes(time, y)) + geom_line(alpha = 0.6) + geom_point(data = df_ol, aes(time, y), color = &quot;red&quot;, size = 1.4) + labs(title = &quot;Outliers detectados (forecast::tsoutliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() } La gráfica revela que la serie de potencia presenta numerosos valores atípicos, distribuidos a lo largo de todo el periodo y de ambos signos. Esto confirma que la serie es altamente irregular y heterocedástica, por lo que requiere una etapa robusta de limpieza y preprocesamiento antes de aplicar cualquier modelo predictivo. # Supuestos del modelo ARIMA (residuales) checkresiduals(m_auto) # ACF de residuales, Ljung-Box, histograma, qq-plot ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,1)(2,0,1)[24] with drift ## Q* = 4269.1, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test p-value &lt; 2.2e-16, se rechaza H₀ (los residuos son ruido blanco), los residuos aún tienen correlación significativa. Diagnósticos residuales del modelo ARIMA Los residuos oscilan alrededor de 0, sin embargo, hay picos grandes (±2000), lo que sugiere valores atípicos o episodios de alta volatilidad no explicados por el modelo. La amplitud es variable (heterocedasticidad leve). ACF (Función de Autocorrelación de los residuos), los residuos aún presentan correlación, el modelo no captura por completo la estructura temporal. Las barras deben estar dentro de las bandas azules. Histograma y densidad de los residuos, es muy concentrado en torno a 0, pero con colas largas y picos extremos, indicando distribución leptocúrtica (no normal). Los residuos no son normales, lo que afecta la validez de los intervalos de predicción si se asume normalidad. El modelo no cumple totalmente los supuestos de ruido blanco, aunque capta bien la tendencia general, persisten correlaciones estacionales y algunos outliers o periodos anómalos. 5.2.10 Transformación logarítmica para estabilizar la varianza # ============================================================ # Transformación logarítmica de la serie de potencia # ============================================================ # Evitar log(0) o negativos df_log &lt;- df_impu %&gt;% mutate(val_log = log1p(val_impu)) # log(1 + x) evita infinitos # Crear serie temporal log-transformada ts_log &lt;- ts(df_log$val_log, frequency = 24) # frecuencia diaria (24 horas) # Visualización básica autoplot(ts_log) + labs(title = &quot;Serie transformada logarítmicamente (log1p)&quot;, y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal() La transformación logarítmica logró reducir la variabilidad y estabilizar la escala de la serie, mejorando su comportamiento estadístico. Sin embargo, persisten caídas bruscas que deben tratarse (por imputación o filtrado). La serie transformada es más regular y apta para modelado estadístico, pero sigue reflejando irregularidades de medición o interrupciones que conviene revisar antes de la predicción final. La serie log-transformada presenta una varianza más controlada, conserva la estructura temporal esencial y mitiga la influencia de outliers. 5.2.11 Ajuste del modelo ARIMA en escala logarítmica # ============================================================ # Ajuste automático ARIMA sobre serie log-transformada # ============================================================ tm(&quot;Ajuste SARIMA TS log-transformada&quot;, { m_log &lt;&lt;- auto.arima(ts_log, seasonal = TRUE, stepwise = FALSE, approximation = arima_approx, trace = TRUE) summary(m_log) }) ## ## Fitting models using approximations to speed things up... ## ## ARIMA(0,1,0) : -24007.62 ## ARIMA(0,1,0) with drift : -24005.63 ## ARIMA(0,1,0)(0,0,1)[24] : -24049.82 ## ARIMA(0,1,0)(0,0,1)[24] with drift : -24047.82 ## ARIMA(0,1,0)(0,0,2)[24] : -24115.74 ## ARIMA(0,1,0)(0,0,2)[24] with drift : -24113.74 ## ARIMA(0,1,0)(1,0,0)[24] : -24027.94 ## ARIMA(0,1,0)(1,0,0)[24] with drift : -24025.95 ## ARIMA(0,1,0)(1,0,1)[24] : Inf ## ARIMA(0,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(1,0,2)[24] : Inf ## ARIMA(0,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,0)[24] : -24068.68 ## ARIMA(0,1,0)(2,0,0)[24] with drift : -24066.69 ## ARIMA(0,1,0)(2,0,1)[24] : Inf ## ARIMA(0,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,2)[24] : Inf ## ARIMA(0,1,0)(2,0,2)[24] with drift : Inf ## ARIMA(0,1,1) : -24077 ## ARIMA(0,1,1) with drift : -24075.01 ## ARIMA(0,1,1)(0,0,1)[24] : -24120.59 ## ARIMA(0,1,1)(0,0,1)[24] with drift : -24118.6 ## ARIMA(0,1,1)(0,0,2)[24] : -24185.2 ## ARIMA(0,1,1)(0,0,2)[24] with drift : -24183.21 ## ARIMA(0,1,1)(1,0,0)[24] : -24098.76 ## ARIMA(0,1,1)(1,0,0)[24] with drift : -24096.77 ## ARIMA(0,1,1)(1,0,1)[24] : Inf ## ARIMA(0,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(1,0,2)[24] : Inf ## ARIMA(0,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,0)[24] : -24138.11 ## ARIMA(0,1,1)(2,0,0)[24] with drift : -24136.12 ## ARIMA(0,1,1)(2,0,1)[24] : Inf ## ARIMA(0,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,2)[24] : Inf ## ARIMA(0,1,1)(2,0,2)[24] with drift : Inf ## ARIMA(0,1,2) : -24111 ## ARIMA(0,1,2) with drift : -24109 ## ARIMA(0,1,2)(0,0,1)[24] : -24157.22 ## ARIMA(0,1,2)(0,0,1)[24] with drift : -24155.23 ## ARIMA(0,1,2)(0,0,2)[24] : -24225.37 ## ARIMA(0,1,2)(0,0,2)[24] with drift : -24223.37 ## ARIMA(0,1,2)(1,0,0)[24] : -24135.58 ## ARIMA(0,1,2)(1,0,0)[24] with drift : -24133.59 ## ARIMA(0,1,2)(1,0,1)[24] : Inf ## ARIMA(0,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,2)(1,0,2)[24] : Inf ## ARIMA(0,1,2)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,2)(2,0,0)[24] : -24178.38 ## ARIMA(0,1,2)(2,0,0)[24] with drift : -24176.39 ## ARIMA(0,1,2)(2,0,1)[24] : Inf ## ARIMA(0,1,2)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,3) : -24243.98 ## ARIMA(0,1,3) with drift : -24241.99 ## ARIMA(0,1,3)(0,0,1)[24] : -24290.47 ## ARIMA(0,1,3)(0,0,1)[24] with drift : -24288.48 ## ARIMA(0,1,3)(0,0,2)[24] : -24358.36 ## ARIMA(0,1,3)(0,0,2)[24] with drift : -24356.37 ## ARIMA(0,1,3)(1,0,0)[24] : -24268.83 ## ARIMA(0,1,3)(1,0,0)[24] with drift : -24266.84 ## ARIMA(0,1,3)(1,0,1)[24] : Inf ## ARIMA(0,1,3)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,3)(2,0,0)[24] : -24311.37 ## ARIMA(0,1,3)(2,0,0)[24] with drift : -24309.38 ## ARIMA(0,1,4) : -24977.57 ## ARIMA(0,1,4) with drift : -24975.58 ## ARIMA(0,1,4)(0,0,1)[24] : -25041.9 ## ARIMA(0,1,4)(0,0,1)[24] with drift : -25039.92 ## ARIMA(0,1,4)(1,0,0)[24] : -25021.29 ## ARIMA(0,1,4)(1,0,0)[24] with drift : -25019.3 ## ARIMA(0,1,5) : -25118.13 ## ARIMA(0,1,5) with drift : -25116.14 ## ARIMA(1,1,0) : -24073.54 ## ARIMA(1,1,0) with drift : -24071.55 ## ARIMA(1,1,0)(0,0,1)[24] : -24117.01 ## ARIMA(1,1,0)(0,0,1)[24] with drift : -24115.01 ## ARIMA(1,1,0)(0,0,2)[24] : -24181.56 ## ARIMA(1,1,0)(0,0,2)[24] with drift : -24179.57 ## ARIMA(1,1,0)(1,0,0)[24] : -24095.17 ## ARIMA(1,1,0)(1,0,0)[24] with drift : -24093.18 ## ARIMA(1,1,0)(1,0,1)[24] : Inf ## ARIMA(1,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(1,0,2)[24] : Inf ## ARIMA(1,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,0)[24] : -24134.47 ## ARIMA(1,1,0)(2,0,0)[24] with drift : -24132.48 ## ARIMA(1,1,0)(2,0,1)[24] : Inf ## ARIMA(1,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,2)[24] : Inf ## ARIMA(1,1,0)(2,0,2)[24] with drift : Inf ## ARIMA(1,1,1) : -24087.78 ## ARIMA(1,1,1) with drift : -24338.51 ## ARIMA(1,1,1)(0,0,1)[24] : -24131.77 ## ARIMA(1,1,1)(0,0,1)[24] with drift : -24369.11 ## ARIMA(1,1,1)(0,0,2)[24] : -24441.8 ## ARIMA(1,1,1)(0,0,2)[24] with drift : -24439.81 ## ARIMA(1,1,1)(1,0,0)[24] : -24348.78 ## ARIMA(1,1,1)(1,0,0)[24] with drift : -24107.14 ## ARIMA(1,1,1)(1,0,1)[24] : Inf ## ARIMA(1,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,1)(1,0,2)[24] : Inf ## ARIMA(1,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,1)(2,0,0)[24] : -24395.2 ## ARIMA(1,1,1)(2,0,0)[24] with drift : -24393.21 ## ARIMA(1,1,1)(2,0,1)[24] : Inf ## ARIMA(1,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,2) : -27833.16 ## ARIMA(1,1,2) with drift : -27831.51 ## ARIMA(1,1,2)(0,0,1)[24] : -27855.34 ## ARIMA(1,1,2)(0,0,1)[24] with drift : -27853.67 ## ARIMA(1,1,2)(0,0,2)[24] : -27931.72 ## ARIMA(1,1,2)(0,0,2)[24] with drift : -27930.08 ## ARIMA(1,1,2)(1,0,0)[24] : -27832.62 ## ARIMA(1,1,2)(1,0,0)[24] with drift : -27830.95 ## ARIMA(1,1,2)(1,0,1)[24] : Inf ## ARIMA(1,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,2)(2,0,0)[24] : -27885.64 ## ARIMA(1,1,2)(2,0,0)[24] with drift : -27883.99 ## ARIMA(1,1,3) : -27930.89 ## ARIMA(1,1,3) with drift : -27929.2 ## ARIMA(1,1,3)(0,0,1)[24] : -27951.36 ## ARIMA(1,1,3)(0,0,1)[24] with drift : -27950.19 ## ARIMA(1,1,3)(1,0,0)[24] : -27929.02 ## ARIMA(1,1,3)(1,0,0)[24] with drift : -27927.34 ## ARIMA(1,1,4) : -27971.44 ## ARIMA(1,1,4) with drift : -27969.72 ## ARIMA(2,1,0) : -24110.19 ## ARIMA(2,1,0) with drift : -24108.2 ## ARIMA(2,1,0)(0,0,1)[24] : -24156.26 ## ARIMA(2,1,0)(0,0,1)[24] with drift : -24154.27 ## ARIMA(2,1,0)(0,0,2)[24] : -24224.06 ## ARIMA(2,1,0)(0,0,2)[24] with drift : -24222.07 ## ARIMA(2,1,0)(1,0,0)[24] : -24134.6 ## ARIMA(2,1,0)(1,0,0)[24] with drift : -24132.61 ## ARIMA(2,1,0)(1,0,1)[24] : Inf ## ARIMA(2,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,0)(1,0,2)[24] : Inf ## ARIMA(2,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(2,1,0)(2,0,0)[24] : -24177.06 ## ARIMA(2,1,0)(2,0,0)[24] with drift : -24175.07 ## ARIMA(2,1,0)(2,0,1)[24] : Inf ## ARIMA(2,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(2,1,1) : -27860.19 ## ARIMA(2,1,1) with drift : -27858.51 ## ARIMA(2,1,1)(0,0,1)[24] : -27882.52 ## ARIMA(2,1,1)(0,0,1)[24] with drift : -27880.84 ## ARIMA(2,1,1)(0,0,2)[24] : -27957.02 ## ARIMA(2,1,1)(0,0,2)[24] with drift : -27955.35 ## ARIMA(2,1,1)(1,0,0)[24] : -27859.79 ## ARIMA(2,1,1)(1,0,0)[24] with drift : -27858.11 ## ARIMA(2,1,1)(1,0,1)[24] : Inf ## ARIMA(2,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,1)(2,0,0)[24] : -27910.86 ## ARIMA(2,1,1)(2,0,0)[24] with drift : -27909.2 ## ARIMA(2,1,2) : Inf ## ARIMA(2,1,2) with drift : Inf ## ARIMA(2,1,2)(0,0,1)[24] : -27959.77 ## ARIMA(2,1,2)(0,0,1)[24] with drift : -27957.64 ## ARIMA(2,1,2)(1,0,0)[24] : -27936.99 ## ARIMA(2,1,2)(1,0,0)[24] with drift : -27932.55 ## ARIMA(2,1,3) : -27941.17 ## ARIMA(2,1,3) with drift : -27942.36 ## ARIMA(3,1,0) : -24237.58 ## ARIMA(3,1,0) with drift : -24235.58 ## ARIMA(3,1,0)(0,0,1)[24] : -24283.51 ## ARIMA(3,1,0)(0,0,1)[24] with drift : -24281.52 ## ARIMA(3,1,0)(0,0,2)[24] : -24350.28 ## ARIMA(3,1,0)(0,0,2)[24] with drift : -24348.29 ## ARIMA(3,1,0)(1,0,0)[24] : -24261.83 ## ARIMA(3,1,0)(1,0,0)[24] with drift : -24259.84 ## ARIMA(3,1,0)(1,0,1)[24] : Inf ## ARIMA(3,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(3,1,0)(2,0,0)[24] : -24303.26 ## ARIMA(3,1,0)(2,0,0)[24] with drift : -24301.27 ## ARIMA(3,1,1) : -27938.18 ## ARIMA(3,1,1) with drift : -27936.48 ## ARIMA(3,1,1)(0,0,1)[24] : -27959.55 ## ARIMA(3,1,1)(0,0,1)[24] with drift : -27957.84 ## ARIMA(3,1,1)(1,0,0)[24] : -27936.7 ## ARIMA(3,1,1)(1,0,0)[24] with drift : -27934.99 ## ARIMA(3,1,2) : -27940.85 ## ARIMA(3,1,2) with drift : -27936.15 ## ARIMA(4,1,0) : -24785.01 ## ARIMA(4,1,0) with drift : -24783.02 ## ARIMA(4,1,0)(0,0,1)[24] : -24842.02 ## ARIMA(4,1,0)(0,0,1)[24] with drift : -24840.03 ## ARIMA(4,1,0)(1,0,0)[24] : -24820.95 ## ARIMA(4,1,0)(1,0,0)[24] with drift : -24818.96 ## ARIMA(4,1,1) : -27951.79 ## ARIMA(4,1,1) with drift : -27950.08 ## ARIMA(5,1,0) : -24836.46 ## ARIMA(5,1,0) with drift : -24834.47 ## ## Now re-fitting the best model(s) without approximations... ## ## ## ## ## Best model: ARIMA(1,1,4) 5.2.12 Verificación de supuestos del nuevo modelo ARIMA en escala logarítmica # ============================================================ # Diagnóstico de los residuos del modelo ARIMA (log) # ============================================================ checkresiduals(m_log) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,4) ## Q* = 647.2, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test El p-valor &lt; 0.05, se rechaza la hipótesis nula (los residuos no son completamente ruido blanco). Esto sugiere que el modelo no captura toda la dinámica temporal, aún quedan patrones correlacionados sin explicar. Diagnósticos residuales del modelo ARIMA En el gráfico de residuales los residuos oscilan alrededor de cero, lo que es esperable para un modelo bien ajustado. Sin embargo, se observan picos frecuentes (positivos y negativos) que indican fluctuaciones abruptas en la varianza o la presencia de valores atípicos. Hay periodos donde la variabilidad de los residuos aumenta, lo que sugiere heterocedasticidad (la varianza no es constante en el tiempo). El modelo logra eliminar la tendencia, pero no estabiliza completamente la varianza; aún hay ruido estructurado. En el gráfico de ACF de los residuos la mayoría de los rezagos se mantienen dentro de las bandas azules de confianza, lo cual indica autocorrelación residual débil o casi nula. Sin embargo, algunos picos (alrededor de los rezagos 24 y 48) exceden ligeramente las bandas, lo que sugiere que todavía puede haber estructura estacional residual leve o dependencias menores no capturadas. El modelo ARIMA(1,1,4) mejora la independencia de los residuos respecto a modelos anteriores, pero no elimina completamente la autocorrelación. En el gráfico de densidad de residuos la forma general es centrada en cero. Sin embargo, se observan colas delgadas pero extendidas, lo que sugiere no normalidad. El pico muy concentrado en torno a 0 confirma que los errores pequeños son frecuentes, pero los grandes (positivos o negativos) aún aparecen ocasionalmente. En general, se cumple parcialmente la normalidad, aunque la serie sigue afectada por outliers o por una distribución más leptocúrtica que la normal. El modelo ARIMA(1,1,4) representa una mejora respecto a versiones más simples (captura parcialmente la dinámica temporal), pero aún no cumple plenamente los supuestos de ruido blanco y homocedasticidad. 5.2.13 Pronóstico con el modelo mejorado (escala logarítmica) # ============================================================ # Pronóstico en escala logarítmica # ============================================================ h &lt;- 24 * horizon_days # pronóstico a 7 días (horas) fc_log &lt;- forecast(m_log, h = h) autoplot(fc_log) + labs(title = paste0(&quot;Pronóstico log-transformado con ARIMA (&quot;, horizon_days, &quot; días)&quot;), y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal(base_size = 12) Se observa que la mayor parte de la serie se mantiene entre valores logarítmicos de 6 a 7, pero hay muchas caídas bruscas hacia valores bajos (0–2). Esos saltos representan puntos donde la potencia real cayó casi a cero, y al aplicar la transformación logarítmica, visualmente se reducen las diferencias. La serie sigue mostrando alta variabilidad y picos anómalos, aunque en menor medida que en la escala original. Esto sugiere que la varianza aún no está completamente estabilizada o que hay eventos atípicos muy fuertes. 5.2.13.1 Reconversión a escala original (exponencial inversa) # ============================================================ # Transformar el pronóstico a escala original # ============================================================ fc_exp &lt;- expm1(fc_log$mean) # inversa de log1p fc_exp80 &lt;- expm1(fc_log$lower[,&quot;80%&quot;]) fc_exp95 &lt;- expm1(fc_log$upper[,&quot;95%&quot;]) # Crear data frame para visualización f_times &lt;- seq(from = max(df_impu[[time_col]]) + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) fc_plot &lt;- tibble( time = f_times, mean = fc_exp, lo80 = fc_exp80, hi80 = fc_exp95 ) # Graficar pronóstico en escala original ggplot(fc_plot, aes(x = time, y = mean)) + geom_ribbon(aes(ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25) + geom_line(color = &quot;#1f77b4&quot;, linewidth = 1.1) + labs(title = &quot;Pronóstico ARIMA (log-transformado, 7 días)&quot;, subtitle = &quot;Transformación log(1 + x) revertida a escala original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia estimada&quot;) + theme_minimal(base_size = 12) La línea azul muestra el pronóstico esperado: prácticamente plano y ligeramente creciente. Las bandas de confianza son amplias, lo cual significa alta incertidumbre en las predicciones. El modelo ARIMA no logra capturar del todo la estacionalidad o los cambios estructurales. Existen valores extremos en la serie original. En este caso, el modelo está promediando el comportamiento reciente, sin detectar tendencia fuerte ni patrón estacional marcado, por eso proyecta una línea casi recta. La transformación logarítmica ayudó a suavizar la serie, pero aún hay alta volatilidad. El modelo ARIMA produce pronósticos conservadores (casi planos) cuando no detecta tendencia o ciclo claro. Las bandas amplias muestran que el modelo no confía demasiado en su predicción a 7 días, posiblemente por residuos no estacionarios o valores atípicos persistentes. 5.3 Preprocesamiento de la serie de datos para Holt–Winters Para la aplicación de Holt–Winter se imputa faltantes, detecta/sustituye outliers y estabiliza la varianza (Box–Cox con inversa guardada) # ============================================================ # Preprocesamiento para Holt–Winters: # - Regulariza a malla horaria (si no existe) # - Imputa NAs # - Detecta y sustituye outliers # - Estabiliza varianza con Box–Cox (guarda lambda e inversa) # Expone: ts_hw_full (limpia, positiva), y_hw_bc, lambda_hw, inv_boxcox() # ============================================================ # 0) Cronometría t0 &lt;- Sys.time() # 1) Asegurar malla horaria y ordenar stopifnot(exists(&quot;df_full&quot;), exists(&quot;time_col&quot;), exists(&quot;y_col&quot;)) df_hw &lt;- df_full %&gt;% dplyr::arrange(.data[[time_col]]) %&gt;% dplyr::select(!!time_col, !!y_col) # 2) Asegurar positividad mínima (HW multiplicativo exige &gt; 0) # Si hay valores &lt;= 0, desplazamos toda la serie por un epsilon. y_raw &lt;- suppressWarnings(as.numeric(df_hw[[y_col]])) eps &lt;- 1e-6 shift &lt;- ifelse(is.finite(min(y_raw, na.rm = TRUE)) &amp;&amp; min(y_raw, na.rm = TRUE) &lt;= 0, abs(min(y_raw, na.rm = TRUE)) + eps, 0) y_pos &lt;- y_raw + shift # 3) Construir ts horaria (freq = 24) con el rango completo t_min &lt;- min(df_hw[[time_col]], na.rm = TRUE) t_max &lt;- max(df_hw[[time_col]], na.rm = TRUE) n_obs &lt;- length(y_pos) ts_hw &lt;- stats::ts(y_pos, frequency = 24) # asume datos ya a paso horario # 4) Conteo de NAs antes n_na_before &lt;- sum(is.na(y_pos)) # 5) Limpieza integrada: imputación + sustitución de outliers # tsclean usa STL internamente para suavizar y reemplazar ts_clean &lt;- forecast::tsclean(ts_hw, replace.missing = TRUE) ts_clean[ts_clean &lt; 10] &lt;- median(ts_clean, na.rm = TRUE) #############!!!!!!!! # 6) Detección explícita de outliers (solo para reporte) to_hw &lt;- try(forecast::tsoutliers(ts_hw), silent = TRUE) n_out &lt;- if (inherits(to_hw, &quot;try-error&quot;)) NA_integer_ else length(to_hw$index) # 7) Serie definitiva para HW (positiva, sin NA/outliers) ts_hw_full &lt;- ts_clean # 8) Estabilización de varianza (Box–Cox de Guerrero recomendado para estacionalidad) # Requiere positividad: ya garantizada por y_pos + tsclean lambda_hw &lt;- forecast::BoxCox.lambda(ts_hw_full, method = &quot;guerrero&quot;) y_hw_bc &lt;- forecast::BoxCox(ts_hw_full, lambda_hw) # Inversa de Box–Cox inv_boxcox &lt;- function(z, lambda) { if (isTRUE(all.equal(lambda, 0))) exp(z) else (lambda * z + 1)^(1/lambda) } # 9) Resumen y diagnóstico n_na_after &lt;- sum(is.na(as.numeric(ts_hw_full))) cat(&quot;Preprocesamiento HW — resumen\\n&quot;, &quot;- Observaciones: &quot;, length(ts_hw_full), &quot;\\n&quot;, &quot;- NAs antes: &quot;, n_na_before, &quot;\\n&quot;, &quot;- NAs después: &quot;, n_na_after, &quot;\\n&quot;, &quot;- Outliers (det.):&quot;, ifelse(is.na(n_out), &quot;no evaluado&quot;, n_out), &quot;\\n&quot;, &quot;- Shift aplicado: &quot;, signif(shift, 6), &quot; (para asegurar positividad)\\n&quot;, &quot;- Box–Cox lambda: &quot;, round(lambda_hw, 4), &quot;\\n&quot;, sep = &quot;&quot;) ## Preprocesamiento HW — resumen ## - Observaciones: 118653 ## - NAs antes: 620 ## - NAs después: 0 ## - Outliers (det.):2485 ## - Shift aplicado: 1e-06 (para asegurar positividad) ## - Box–Cox lambda: 0.9455 # 10) Gráfico diagnóstico: Original vs Limpia (+ Box–Cox en panel) df_diag_wide &lt;- tibble::tibble( time = as.POSIXct(df_hw[[time_col]], tz = TZ)[seq_along(ts_hw_full)], Original = y_pos[seq_along(ts_hw_full)], BoxCox = as.numeric(y_hw_bc), Limpia = as.numeric(ts_hw_full) ) ggplot2::ggplot(mapping = ggplot2::aes(x = time)) + # Fondo: serie original (gris, delgada y transparente) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = Original, color = &quot;Original&quot;), linewidth = 0.35, alpha = 0.45, na.rm = TRUE) + # Medio: Box-Cox (naranja, grosor medio) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = BoxCox, color = &quot;BoxCox&quot;), linewidth = 0.6, alpha = 0.85, na.rm = TRUE) + # Frente: serie limpia (azul, más gruesa) ggplot2::geom_line(data = df_diag_wide, ggplot2::aes(y = Limpia, color = &quot;Limpia&quot;), linewidth = 0.9, alpha = 0.95, na.rm = TRUE) + ggplot2::scale_color_manual( name = &quot;Serie&quot;, breaks = c(&quot;Original&quot;,&quot;BoxCox&quot;,&quot;Limpia&quot;), labels = c(&quot;Original (fondo)&quot;,&quot;Box–Cox&quot;,&quot;Limpia (frente)&quot;), values = c(Original = &quot;#9CA3AF&quot;, BoxCox = &quot;#ff7f0e&quot;, Limpia = &quot;#1f77b4&quot;) ) + ggplot2::labs( title = &quot;Preprocesamiento para Holt–Winters&quot;, subtitle = &quot;Fondo: Original | Medio: Box–Cox | Frente: Serie limpia (imputación + outliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme( plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank() ) # 11) Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Preprocesamiento&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } La serie fue limpiada, ya no tiene huecos ni valores extremos, y su escala fue estabilizada para un modelado robusto con Holt–Winters. En la gráfica el Gris claro corresponde a la Serie original con ruido, picos y alta dispersión. el Naranja corresponde la serie transformada con varianza más homogénea, suavizando los extremos. y la curva Azul es la serie final tras imputación y reemplazo de outliers; muestra comportamiento más regular y continuo. Los picos de potencia extrema (&gt;3000) fueron suavizados; la serie azul es más compacta y uniforme. Se mantienen los ciclos anuales y semanales, lo que garantiza que no se perdió información relevante. El Box–Cox (naranja) actúa como paso intermedio: reduce la amplitud sin eliminar fluctuaciones naturales. La serie limpia (azul) se ajusta mejor a los supuestos del modelo HW, evitando el sesgo causado por valores extremos o huecos. 5.4 División de los datos entre TRAIN/TEST # ============================================================ # Split TRAIN/TEST para Holt–Winters y ARIMA # Usa: ts_hw_full (serie limpia/positiva) y y_hw_bc (Box–Cox) # Expone: h, n_test, y_train, y_test, y_train_bc, y_test_bc, # time_train, time_test (para gráficas y métricas) # ============================================================ # Cronometría t0 &lt;- Sys.time() # 0) Utilidades `%||%` &lt;- function(a, b) if (!is.null(a)) a else b # 1) Horizonte en horas (24 * días) h &lt;- 24 * (horizon_days %||% 7) # 2) Longitudes y validaciones stopifnot(exists(&quot;ts_hw_full&quot;)) n &lt;- length(ts_hw_full) # Si el horizonte es mayor que la serie, lo acotamos y avisamos if (h &gt;= n) { message(sprintf(&quot;Horizonte (%d) &gt;= longitud de la serie (%d). Se ajusta a h = %d.&quot;, h, n, max(1L, floor(n/5)))) h &lt;- max(1L, floor(n/5)) } # 3) Definimos tamaño de TEST como el horizonte (común para evaluación) n_test &lt;- h n_train &lt;- n - n_test stopifnot(n_train &gt;= 24 * 7) # al menos ~1 semana para estimar estacionalidad # 4) Particiones en escala original (limpia, positiva) y_train &lt;- stats::ts(ts_hw_full[1:n_train], frequency = 24) y_test &lt;- stats::ts(ts_hw_full[(n_train+1):n], frequency = 24) # 5) Particiones en escala Box–Cox (para modelos aditivos en varianza estable) stopifnot(exists(&quot;y_hw_bc&quot;)) y_train_bc &lt;- stats::ts(y_hw_bc[1:n_train], frequency = 24) y_test_bc &lt;- stats::ts(y_hw_bc[(n_train+1):n], frequency = 24) # 6) Vectores de tiempo (útil para gráficas de comparación) stopifnot(exists(&quot;df_full&quot;), exists(&quot;time_col&quot;)) time_all &lt;- as.POSIXct(df_full[[time_col]]) time_train &lt;- time_all[1:n_train] time_test &lt;- time_all[(n_train+1):n] # 7) Métricas (si no existen) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } # 8) Resumen y chequeo visual rápido cat(&quot;Split TRAIN/TEST\\n&quot;, &quot;- Observaciones totales: &quot;, n, &quot;\\n&quot;, &quot;- TRAIN: &quot;, n_train, &quot; (&quot;, round(100*n_train/n,1),&quot;%)\\n&quot;, &quot;- TEST: &quot;, n_test, &quot; (&quot;, round(100*n_test/n,1),&quot;%)\\n&quot;, &quot;- Horizonte h (horas): &quot;, h, &quot;\\n&quot;, &quot;- Freq ts: &quot;, frequency(y_train), &quot;\\n&quot;, sep = &quot;&quot;) ## Split TRAIN/TEST ## - Observaciones totales: 118653 ## - TRAIN: 118485 (99.9%) ## - TEST: 168 (0.1%) ## - Horizonte h (horas): 168 ## - Freq ts: 24 # Gráfico base para verificar el split df_split &lt;- dplyr::bind_rows( tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;), tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) ) ggplot2::ggplot(df_split, ggplot2::aes(time, y, color = conj)) + ggplot2::geom_line(linewidth = 0.5, alpha = 0.9) + ggplot2::scale_color_manual(values = c(TRAIN = &quot;#1f77b4&quot;, TEST = &quot;#d62728&quot;)) + ggplot2::labs(title = &quot;Split de la serie: TRAIN vs TEST&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Conjunto&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank()) # 9) Cronometría (si la usas) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Split TRAIN/TEST&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), # trivial aquí status = &quot;OK&quot;, message = &quot;&quot; ) } Se dividio la serie de tiempo en dos partes, TRAIN (azul): casi toda la serie, usada para ajustar el modelo y TEST (rojo): los últimos 7 días, usados para evaluar la capacidad predictiva (este tramo es muy corto respecto al conjunto total, lo cual indica que el modelo se entrenará con casi toda la información disponible y se evaluará únicamente en una ventana reciente de 7 días). La serie muestra una alta variabilidad en la potencia a lo largo del tiempo, con fluctuaciones intensas dentro de cada año (posible patrón diario/semanal) e incremento gradual de los valores máximos a partir de 2020 (~tendencia leve al alza). Se observa ruido considerable y presencia de picos y caídas abruptas, lo que sugiere procesos operativos irregulares o mediciones con eventos extremos. 5.5 Ajuste Holt–Winters aditivo y multiplicativo (usando TRAIN y h definidos) # ========================================= # Holt–Winters: ajustes aditivo y multiplicativo (consistentes con 0 y 1) # Usa: y_train (escala original positiva), h # Deja: fc_hw_add, fc_hw_mul (objetos &#39;forecast&#39;) # ========================================= # Cronometría t0 &lt;- Sys.time() # Carga autoplot para objetos &#39;forecast&#39; if (!&quot;ggfortify&quot; %in% .packages()) suppressPackageStartupMessages(library(ggfortify)) # --- Aditivo (siempre válido en escala original) --- fc_hw_add &lt;- forecast::hw(y_train, seasonal = &quot;additive&quot;, h = h) # --- Multiplicativo (requiere todos &gt; 0) --- if (all(as.numeric(y_train) &gt; 0, na.rm = TRUE)) { fc_hw_mul &lt;- forecast::hw(y_train, seasonal = &quot;multiplicative&quot;, h = h) } else { message(&quot;HW multiplicativo omitido: la serie TRAIN contiene ceros o valores ≤ 0.&quot;) fc_hw_mul &lt;- NULL } # # Vista rápida # autoplot(fc_hw_add) + # labs(title = &quot;Pronóstico Holt–Winters (Aditivo)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal(base_size = 12) # # if (!is.null(fc_hw_mul)) { # autoplot(fc_hw_mul) + # labs(title = &quot;Pronóstico Holt–Winters (Multiplicativo)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + # theme_minimal(base_size = 12) # } # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Aditivo y multiplicativo&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } 5.6 Gráfica comparativa: TRAIN/TEST + pronósticos HW (aditivo vs. multiplicativo) # ========================================= # Gráfica comparativa con eje temporal real # Usa: time_train, time_test, y_train, y_test, h, fc_hw_add, fc_hw_mul, TZ # ========================================= stopifnot(exists(&quot;time_train&quot;), exists(&quot;time_test&quot;)) stopifnot(exists(&quot;TZ&quot;)) # DATAFRAME histórico df_train &lt;- tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;) df_test &lt;- tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) # Instantes de pronóstico a partir del final de TRAIN t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) # Pasar objetos forecast a data frame (si existen) as_fc_df &lt;- function(fc, nombre) { if (is.null(fc)) return(NULL) tibble::tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[, &quot;80%&quot;]), hi80 = as.numeric(fc$upper[, &quot;80%&quot;]), lo95 = as.numeric(fc$lower[, &quot;95%&quot;]), hi95 = as.numeric(fc$upper[, &quot;95%&quot;]), modelo = nombre ) } df_add &lt;- as_fc_df(fc_hw_add, &quot;HW Aditivo&quot;) df_mul &lt;- as_fc_df(fc_hw_mul, &quot;HW Multiplicativo&quot;) df_fc &lt;- dplyr::bind_rows(df_add, df_mul) # # Plot # ggplot2::ggplot() + # ggplot2::geom_line(data = df_train, ggplot2::aes(time, y), color = &quot;grey65&quot;, linewidth = 0.45) + # ggplot2::geom_line(data = df_test, ggplot2::aes(time, y), color = &quot;black&quot;, linewidth = 0.6) + # ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95, fill = modelo), # alpha = 0.12, show.legend = FALSE) + # ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80, fill = modelo), # alpha = 0.22, show.legend = FALSE) + # ggplot2::geom_line(data = df_fc, ggplot2::aes(x = time, y = mean, color = modelo), linewidth = 1.0) + # ggplot2::scale_color_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + # ggplot2::scale_fill_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + # ggplot2::labs(title = &quot;Pronóstico Holt–Winters — comparación&quot;, # subtitle = &quot;Gris: TRAIN | Negro: TEST | Colores: pronóstico&quot;, # x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Modelo&quot;) + # ggplot2::theme_minimal(base_size = 12) + # ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), # panel.grid.minor = ggplot2::element_blank()) stopifnot(exists(&quot;time_train&quot;), exists(&quot;y_train&quot;), exists(&quot;h&quot;), exists(&quot;TZ&quot;)) # ========================================= # ZOOM: últimos 21 días + predicción HW # Requiere: time_train, y_train, h, fc_hw_add / fc_hw_mul, TZ # ========================================= # 1) Instantes clave t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) # 2) Histórico (solo últimos 21 días de TRAIN) history_days &lt;- 21 t_zoom_ini &lt;- t_train_end - lubridate::days(history_days) df_hist &lt;- tibble::tibble( time = time_train, y = as.numeric(y_train) ) %&gt;% dplyr::filter(time &gt;= t_zoom_ini) # 3) Utilidad para llevar objetos forecast a data frame as_fc_df &lt;- function(fc, nombre) { if (is.null(fc)) return(NULL) tibble::tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[, &quot;80%&quot;]), hi80 = as.numeric(fc$upper[, &quot;80%&quot;]), lo95 = as.numeric(fc$lower[, &quot;95%&quot;]), hi95 = as.numeric(fc$upper[, &quot;95%&quot;]), modelo = nombre ) } df_add &lt;- as_fc_df(if (exists(&quot;fc_hw_add&quot;)) fc_hw_add else NULL, &quot;HW Aditivo&quot;) df_mul &lt;- as_fc_df(if (exists(&quot;fc_hw_mul&quot;)) fc_hw_mul else NULL, &quot;HW Multiplicativo&quot;) df_fc &lt;- dplyr::bind_rows(df_add, df_mul) # 4) Límite superior del eje X hasta el fin de la predicción t_fin &lt;- max(f_times, na.rm = TRUE) # 5) Gráfico: historia (21d) + pronóstico ggplot2::ggplot() + # Historia (fondo) ggplot2::geom_line(data = df_hist, ggplot2::aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.5, alpha = 0.9, na.rm = TRUE) + # Bandas 95% y 80% ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95, fill = modelo), alpha = 0.12, show.legend = FALSE, na.rm = TRUE) + ggplot2::geom_ribbon(data = df_fc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80, fill = modelo), alpha = 0.22, show.legend = FALSE, na.rm = TRUE) + # Media pronosticada ggplot2::geom_line(data = df_fc, ggplot2::aes(x = time, y = mean, color = modelo), linewidth = 1.0, na.rm = TRUE) + # Escalas y estilo ggplot2::scale_color_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + ggplot2::scale_fill_manual(values = c(&quot;HW Aditivo&quot;=&quot;#1f77b4&quot;, &quot;HW Multiplicativo&quot;=&quot;#d62728&quot;)) + ggplot2::scale_x_datetime(limits = c(t_zoom_ini, t_fin), date_breaks = &quot;3 days&quot;, date_labels = &quot;%d-%b&quot;) + ggplot2::guides(x = ggplot2::guide_axis(n.dodge = 2)) + ggplot2::labs( title = &quot;Últimos 21 días + predicción Holt–Winters&quot;, subtitle = &quot;Historia (gris) y media pronosticada con bandas de confianza (80% y 95%)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;, color = &quot;Modelo&quot; ) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme( plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank(), axis.text.x = ggplot2::element_text(angle = 35, hjust = 1) ) En la gráfica el Color gris representa los valores reales de la serie (últimos 21 días antes del pronóstico). Las líneas de color (azul y rojo): media del pronóstico para cada modelo (Azul: Holt–Winters aditivo / Rojo: Holt–Winters multiplicativo). Y las sombras corresponden a las bandas de confianza del 80% (más oscuras) y 95% (más claras), que indican la incertidumbre del pronóstico. Se observan oscilaciones regulares y cíclicas con picos diarios, lo cual indica una fuerte estacionalidad intradía (24h). La amplitud de los ciclos es relativamente estable, sin tendencia ascendente ni descendente marcada, confirmando que la serie es altamente estacional y estacionaria en media. Ambos modelos (aditivo y multiplicativo) mantienen el patrón periódico observado en los datos reales, lo que demuestra una buena captura de la estacionalidad. Las predicciones oscilan con amplitudes muy similares a las observadas, tanto el modelo multiplicativo (rojo) como el modelo aditivo (azul) mantienen una amplitud constante en el periodo predicción, sin embargo, el modelo aditivo tiene una mayor amplitud con respecto al modelo multiplicativo. Las bandas del 80% y 95% crecen gradualmente hacia el futuro, reflejando el aumento de la incertidumbre a medida que se pronostica más lejos. La superposición de las zonas azul y roja indica que ambos modelos ofrecen pronósticos muy próximos, lo cual sugiere que la serie no tiene una varianza fuertemente dependiente del nivel. El modelo Holt–Winters reproduce con éxito el comportamiento estacional de la serie en sus últimas semanas. Ambas versiones (aditiva y multiplicativa) generan pronósticos coherentes, capturando el patrón de ciclos diarios sin desviaciones abruptas. 5.7 Evaluación en TEST (MAPE y RMSE) # ========================================= # Evaluación (MAPE y RMSE) sobre TEST # Usa: y_test, h, fc_hw_add, fc_hw_mul, rmse(), mape() # ========================================= stopifnot(exists(&quot;y_test&quot;), exists(&quot;h&quot;)) # Longitud efectiva para comparar k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] pred_add &lt;- if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k) pred_mul &lt;- if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k) # Métricas auxiliares (por si no existen) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tab_hw &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;), RMSE = c(rmse(y_test_vec, pred_add), rmse(y_test_vec, pred_mul)), MAPE = c(mape(y_test_vec, pred_add), mape(y_test_vec, pred_mul)) ) knitr::kable(tab_hw, digits = 3, caption = &quot;Evaluación en TEST (MAPE y RMSE) — Holt–Winters&quot;) Table 5.1: Evaluación en TEST (MAPE y RMSE) — Holt–Winters Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 El modelo multiplicativo tiene un RMSE un 15.8% menor que el aditivo. Esto significa que, en promedio, las desviaciones entre los valores reales y pronosticados son menores en magnitud. El modelo aditivo aún predice bien, pero con mayor dispersión en torno a los valores reales. El Holt–Winters multiplicativo reduce los errores absolutos y genera pronósticos más estables. El MAPE de 31.1% para el modelo multiplicativo indica que, en promedio, las predicciones se desvían un 31% del valor real. En comparación, el modelo aditivo presenta 37.1%, es decir, un error relativo un poco mayor. Aunque ambos valores se ubican en el rango “moderadamente precisos”, el modelo multiplicativo es claramente superior. La diferencia entre ambos modelos refleja cómo cada versión maneja la relación entre nivel y variabilidad de la serie, en el modelo aditivo, la amplitud de las fluctuaciones es constante mientras que en el modelo multiplicativo, la amplitud crece o disminuye proporcionalmente al nivel de la serie. Dado que la serie de potencia muestra cierta variación en su amplitud (es decir, cuando la potencia aumenta, las oscilaciones también son mayores), el modelo multiplicativo se adapta mejor a esa estructura heterocedástica. El modelo Holt–Winters multiplicativo ofrece mejor precisión (MAPE 31.1%) y menor error absoluto (RMSE 394.6) que el aditivo. Esto confirma que la serie presenta fluctuaciones proporcionales a su nivel, y que el enfoque multiplicativo se ajusta mejor al comportamiento real de la potencia, proporcionando pronósticos más consistentes y confiables. 5.8 Comparación con un ARIMA simple # ========================================= # Comparación con ARIMA simple (auto.arima) # Usa: y_train, y_test, h, arima_approx, rmse(), mape() # ========================================= # Cronometría t0 &lt;- Sys.time() fit_arima_simple &lt;- forecast::auto.arima( y_train, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx ) fc_arima_simple &lt;- forecast::forecast(fit_arima_simple, h = h) # Comparar en TEST k &lt;- min(length(y_test), h) pred_arima &lt;- as.numeric(fc_arima_simple$mean)[seq_len(k)] y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] tab_cmp &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;, &quot;ARIMA simple&quot;), RMSE = c( rmse(y_test_vec, if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k)), rmse(y_test_vec, if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k)), rmse(y_test_vec, pred_arima) ), MAPE = c( mape(y_test_vec, if (!is.null(fc_hw_add)) as.numeric(fc_hw_add$mean)[seq_len(k)] else rep(NA_real_, k)), mape(y_test_vec, if (!is.null(fc_hw_mul)) as.numeric(fc_hw_mul$mean)[seq_len(k)] else rep(NA_real_, k)), mape(y_test_vec, pred_arima) ) ) knitr::kable(tab_cmp, digits = 3, caption = &quot;Comparación en TEST — Holt–Winters vs. ARIMA simple&quot;) Table 5.2: Comparación en TEST — Holt–Winters vs. ARIMA simple Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 ARIMA simple 325.303 27.377 # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - ARIMA simple&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } El modelo ARIMA simple logra el mejor desempeño predictivo, con un RMSE de 325.3 y un MAPE de 27.4%, superando significativamente a las versiones de Holt–Winters. Esto indica que la serie presenta autocorrelaciones y fluctuaciones no perfectamente estacionales, las cuales ARIMA logra capturar mejor. Los modelos Holt–Winters siguen siendo útiles como referencia y ofrecen pronósticos razonables, pero suponen una estructura estacional más rígida, lo que limita su precisión frente al ARIMA. El nivel de error obtenido (MAPE &lt; 30%) es aceptable y operativo, mostrando que los pronósticos pueden emplearse con confianza en planificación o simulación de demanda energética. 5.9 Holt Winter en Box–Cox (ajuste + pronóstico en BC + reconversión a escala original) # ============================================================ # Holt–Winters sobre la serie Box–Cox (aditivo en varianza estabilizada) # Requiere: y_train_bc (ts), y_test_bc (ts), lambda_hw, inv_boxcox(), h # Expone: fc_hw_bc (forecast en BC) y df_hw_bc (pronóstico reconvertido) # ============================================================ # Cronometría t0 &lt;- Sys.time() stopifnot(exists(&quot;y_train_bc&quot;), exists(&quot;lambda_hw&quot;), exists(&quot;inv_boxcox&quot;)) if (!&quot;ggfortify&quot; %in% .packages()) suppressPackageStartupMessages(library(ggfortify)) # Ajuste HW aditivo en la escala Box–Cox fc_hw_bc &lt;- forecast::hw(y_train_bc, seasonal = &quot;additive&quot;, h = h) # Reconversión a escala original (aprox. aplicando inversa a banda y media) # NOTA: transformar límites por separado no preserva exactamente la cobertura, # pero es la práctica usual para visualización/comparación. bc_to_orig &lt;- function(x) inv_boxcox(x, lambda_hw) # Tiempos para el pronóstico: siguen el final de TRAIN real t_train_end &lt;- max(time_train, na.rm = TRUE) f_times &lt;- seq(from = t_train_end + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) df_hw_bc &lt;- tibble::tibble( time = f_times, mean = bc_to_orig(as.numeric(fc_hw_bc$mean)), lo80 = bc_to_orig(as.numeric(fc_hw_bc$lower[, &quot;80%&quot;])), hi80 = bc_to_orig(as.numeric(fc_hw_bc$upper[, &quot;80%&quot;])), lo95 = bc_to_orig(as.numeric(fc_hw_bc$lower[, &quot;95%&quot;])), hi95 = bc_to_orig(as.numeric(fc_hw_bc$upper[, &quot;95%&quot;])) ) # # Vista rápida del forecast en BC # autoplot(fc_hw_bc) + # labs(title = &quot;Pronóstico Holt–Winters (Box–Cox, escala BC)&quot;, # x = &quot;Tiempo&quot;, y = &quot;Valor (Box–Cox)&quot;) + # theme_minimal(base_size = 12) # Cronometría (si usas el registrador .timing) if (exists(&quot;.timing&quot;)) { .timing[[&quot;HW - Box-CoX&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = &quot;OK&quot;, message = &quot;&quot; ) } 5.10 Gráfica comparativa (TRAIN/TEST en original) + HW Box–Cox reconvertido # ============================================================ # Overlay en escala original: # - TRAIN (gris) y TEST (negro) # - Pronóstico HW Box–Cox reconvertido (azul) # Requiere: time_train, time_test, y_train (original), y_test (original), df_hw_bc # ============================================================ stopifnot(exists(&quot;df_hw_bc&quot;)) df_train &lt;- tibble::tibble(time = time_train, y = as.numeric(y_train), conj = &quot;TRAIN&quot;) df_test &lt;- tibble::tibble(time = time_test, y = as.numeric(y_test), conj = &quot;TEST&quot;) ggplot2::ggplot() + ggplot2::geom_line(data = df_train, ggplot2::aes(time, y), color = &quot;grey65&quot;, linewidth = 0.45) + ggplot2::geom_line(data = df_test, ggplot2::aes(time, y), color = &quot;black&quot;, linewidth = 0.60) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.12) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.22) + ggplot2::geom_line(data = df_hw_bc, ggplot2::aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0) + ggplot2::labs(title = &quot;Pronóstico Holt–Winters (Box–Cox → escala original)&quot;, subtitle = &quot;Gris: TRAIN | Negro: TEST | Azul: pronóstico reconvertido&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank()) 5.11 Zoom al pronóstico Holt Winter Box–Cox en original # ============================================================ # Zoom al pronóstico HW Box–Cox reconvertido (últimos N días) # Requiere: df_hw_bc, df_impu, time_col, TZ # ============================================================ history_days &lt;- 21 hist_df &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) t_ini &lt;- t_max - lubridate::days(history_days) t_fin &lt;- max(df_hw_bc$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot2::ggplot() + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + ggplot2::geom_ribbon(data = df_hw_bc, ggplot2::aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + ggplot2::geom_line(data = df_hw_bc, ggplot2::aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + ggplot2::geom_line(data = hist_zoom, ggplot2::aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.45, na.rm = TRUE) + ggplot2::scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, date_labels = &quot;%d-%b&quot;) + ggplot2::labs(title = paste0(&quot;Holt–Winters Box–Cox (&quot;, ceiling(h/24), &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días + pronóstico reconvertido&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + ggplot2::theme_minimal(base_size = 12) + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;), panel.grid.minor = ggplot2::element_blank(), axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)) El modelo Holt–Winters Box–Cox conserva la estacionalidad y la estructura de la serie, generando predicciones coherentes con la dinámica histórica. La transformación Box–Cox mejora la estabilidad del modelo y evita explosiones de varianza en los pronósticos. En los últimos 21 días históricos, se observa un patrón cíclico altamente repetitivo, con picos y valles diarios. A partir del punto de pronóstico (el último dato del conjunto de entrenamiento), el modelo mantiene el mismo patrón estacional, reproduciendo los picos y valles con amplitud similar, lo que demuestra que el componente estacional fue correctamente capturado. Las bandas de confianza se expanden gradualmente conforme avanza el horizonte temporal, lo que refleja un aumento natural de la incertidumbre en predicciones futuras. El modelo no muestra sesgos significativos: el promedio del pronóstico (línea azul) sigue de cerca el comportamiento central de los datos reales. El modelo logra una predicción estable, con un patrón estacional diario bien ajustado y sin desviaciones sistemáticas. Las bandas de confianza muestran incertidumbre controlada y coherente con la naturaleza estocástica de la serie. 5.12 Métricas en TEST comparando en escala original (Holt Winter y Box–Cox) # ============================================================ # Evaluación en TEST (RMSE y MAPE) en escala ORIGINAL # Añade HW Box–Cox (reconvertido) a la tabla de comparación # Requiere: y_test, h, df_hw_bc y (si existen) fc_hw_add/fc_hw_mul/ARIMA # ============================================================ stopifnot(exists(&quot;y_test&quot;)) k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # Predicciones de los modelos existentes (si existen) get_preds &lt;- function(obj, k) { if (is.null(obj)) return(rep(NA_real_, k)) as.numeric(obj)[seq_len(k)] } pred_add &lt;- if (exists(&quot;fc_hw_add&quot;)) get_preds(fc_hw_add$mean, k) else rep(NA_real_, k) pred_mul &lt;- if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) get_preds(fc_hw_mul$mean, k) else rep(NA_real_, k) pred_arima &lt;- if (exists(&quot;fc_arima_simple&quot;)) get_preds(fc_arima_simple$mean, k) else rep(NA_real_, k) pred_hwbc &lt;- get_preds(df_hw_bc$mean, k) # Métricas (si no están) if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tab_cmp_all &lt;- dplyr::tibble( Modelo = c(&quot;HW Aditivo&quot;, &quot;HW Multiplicativo&quot;, &quot;ARIMA simple&quot;, &quot;HW Box–Cox (aditivo)&quot;), RMSE = c(rmse(y_test_vec, pred_add), rmse(y_test_vec, pred_mul), rmse(y_test_vec, pred_arima), rmse(y_test_vec, pred_hwbc)), MAPE = c(mape(y_test_vec, pred_add), mape(y_test_vec, pred_mul), mape(y_test_vec, pred_arima), mape(y_test_vec, pred_hwbc)) ) knitr::kable(tab_cmp_all, digits = 3, caption = &quot;Evaluación en TEST (escala original) — HW Aditivo, HW Multiplicativo, ARIMA simple y HW Box–Cox&quot;) Table 5.3: Evaluación en TEST (escala original) — HW Aditivo, HW Multiplicativo, ARIMA simple y HW Box–Cox Modelo RMSE MAPE HW Aditivo 468.700 37.098 HW Multiplicativo 394.586 31.117 ARIMA simple 325.303 27.377 HW Box–Cox (aditivo) 465.434 36.858 El Holt–Winters con Box–Cox (aditivo) no mejora de manera sustancial. La transformación Box–Cox estabiliza la varianza y suaviza valores extremos, pero al reconvertir a la escala original, el beneficio se diluye. Por eso sus métricas son casi idénticas a las del modelo aditivo original, aunque genera pronósticos más estables y visualmente más suaves. Holt–Winters con Box–Cox proporciona una alternativa robusta cuando hay heterocedasticidad o valores extremos, aunque no mejora de forma drástica la precisión. 5.13 Resumen final de métricas (RMSE / MAPE) # ============================================================ # RESUMEN FINAL DE MÉTRICAS (RMSE / MAPE) EN ESCALA ORIGINAL # Detecta y consolida: SARIMA (fc), ARIMA simple, HW (add/mult), # HW Box–Cox (reconvertido), y ARIMA (log) si existe. # Requiere: y_test, h, rmse(), mape() # ============================================================ suppressPackageStartupMessages({ library(dplyr); library(tibble); library(ggplot2) }) # --- 1) Validaciones y utilidades --- stopifnot(exists(&quot;y_test&quot;), exists(&quot;h&quot;)) # función segura para extraer primeras k predicciones de un objeto &quot;mean&quot; forecast get_fc_mean &lt;- function(obj, k) { if (is.null(obj)) return(rep(NA_real_, k)) as.numeric(obj)[seq_len(k)] } # --- 2) Longitud de comparación y vector TEST (escala original) --- k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # --- 3) Recolección de predicciones por modelo (si existen) --- preds &lt;- list() # SARIMA (auto.arima original) -&gt; objeto &#39;fc&#39; if (exists(&quot;fc&quot;)) { preds[[&quot;SARIMA (auto.arima)&quot;]] &lt;- get_fc_mean(fc$mean, k) } # ARIMA simple (train/test mismo split) -&gt; objeto &#39;fc_arima_simple&#39; if (exists(&quot;fc_arima_simple&quot;)) { preds[[&quot;ARIMA simple&quot;]] &lt;- get_fc_mean(fc_arima_simple$mean, k) } # Holt–Winters Aditivo -&gt; objeto &#39;fc_hw_add&#39; if (exists(&quot;fc_hw_add&quot;)) { preds[[&quot;HW Aditivo&quot;]] &lt;- get_fc_mean(fc_hw_add$mean, k) } # Holt–Winters Multiplicativo -&gt; objeto &#39;fc_hw_mul&#39; (puede ser NULL) if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { preds[[&quot;HW Multiplicativo&quot;]] &lt;- get_fc_mean(fc_hw_mul$mean, k) } # Holt–Winters Box–Cox (aditivo) -&gt; data.frame &#39;df_hw_bc&#39; (ya en original) if (exists(&quot;df_hw_bc&quot;)) { preds[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- as.numeric(df_hw_bc$mean)[seq_len(k)] } # ARIMA (log) -&gt; objeto &#39;fc_log&#39; (reconvertimos con expm1) if (exists(&quot;fc_log&quot;)) { preds[[&quot;ARIMA (log)&quot;]] &lt;- expm1(as.numeric(fc_log$mean))[seq_len(k)] } # Si no hay ningún modelo, avisar y salir if (!length(preds)) { cat(&quot;No se encontraron objetos de pronóstico para resumir.\\n&quot;) } else { # --- 4) Cálculo de métricas --- if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- obs != 0 &amp; is.finite(obs) &amp; is.finite(pred) if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } tabla &lt;- lapply(names(preds), function(nm) { pr &lt;- preds[[nm]] tibble::tibble( Modelo = nm, RMSE = rmse(y_test_vec, pr), MAPE = mape(y_test_vec, pr) ) }) |&gt; bind_rows() # Ranking por RMSE y % mejora respecto al peor tabla &lt;- tabla |&gt; arrange(RMSE) |&gt; mutate(Rank_RMSE = row_number(), Mejora_vs_Peor = 100 * (max(RMSE, na.rm = TRUE) - RMSE) / max(RMSE, na.rm = TRUE)) # --- 5) Mostrar tabla --- knitr::kable(tabla, digits = 3, caption = &quot;Resumen final de desempeño en TEST (escala original)&quot;) # --- 6) (Opcional) Gráfico de barras por RMSE --- ggplot(tabla, aes(x = reorder(Modelo, RMSE), y = RMSE)) + geom_col() + coord_flip() + geom_text(aes(label = sprintf(&quot;%.1f&quot;, RMSE)), hjust = -0.1, size = 3) + labs(title = &quot;Comparación de RMSE por modelo&quot;, x = &quot;Modelo&quot;, y = &quot;RMSE (menor es mejor)&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) + expand_limits(y = max(tabla$RMSE, na.rm = TRUE) * 1.1) } # --- Funciones de métricas (por si acaso) --- if (!exists(&quot;rmse&quot;, mode = &quot;function&quot;)) { rmse &lt;- function(obs, pred) sqrt(mean((obs - pred)^2, na.rm = TRUE)) } if (!exists(&quot;mape&quot;, mode = &quot;function&quot;)) { mape &lt;- function(obs, pred) { ok &lt;- is.finite(obs) &amp; is.finite(pred) &amp; obs != 0 if (!any(ok)) return(NA_real_) mean(abs((obs[ok] - pred[ok]) / obs[ok])) * 100 } } if (!exists(&quot;mae&quot;, mode = &quot;function&quot;)) { mae &lt;- function(obs, pred) mean(abs(obs - pred), na.rm = TRUE) } # --- Vector de verdad (TEST) acotado a k --- # (asumiendo que ya definiste y_test, h y k) k &lt;- min(length(y_test), h) y_test_vec &lt;- as.numeric(y_test)[seq_len(k)] # --- Construir lista de predicciones realmente disponibles --- preds &lt;- list() if (exists(&quot;fc_hw_add&quot;) &amp;&amp; !is.null(fc_hw_add)) { preds[[&quot;HW Aditivo&quot;]] &lt;- as.numeric(fc_hw_add$mean)[seq_len(k)] } if (exists(&quot;df_hw_bc&quot;) &amp;&amp; !is.null(df_hw_bc)) { preds[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- as.numeric(df_hw_bc$mean)[seq_len(k)] } if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { preds[[&quot;HW Multiplicativo&quot;]] &lt;- as.numeric(fc_hw_mul$mean)[seq_len(k)] } if (exists(&quot;fc_arima_simple&quot;) &amp;&amp; !is.null(fc_arima_simple)) { preds[[&quot;ARIMA simple&quot;]] &lt;- as.numeric(fc_arima_simple$mean)[seq_len(k)] } if (exists(&quot;fc&quot;) &amp;&amp; !is.null(fc)) { preds[[&quot;SARIMA (auto.arima)&quot;]] &lt;- as.numeric(fc$mean)[seq_len(k)] } # Si tienes otro modelo (p. ej. ARIMA log) añádelo así: if (exists(&quot;fc_exp&quot;) &amp;&amp; !is.null(fc_exp)) { # fc_exp debe ser un vector numérico en escala original preds[[&quot;ARIMA (log)&quot;]] &lt;- as.numeric(fc_exp)[seq_len(k)] } # --- Tabla final con list-column y métricas por fila --- library(tibble) library(dplyr) library(purrr) tabla &lt;- tibble( Modelo = names(preds), Pred = unname(preds) ) %&gt;% mutate( RMSE = map_dbl(Pred, ~ rmse(y_test_vec, .x)), MAPE = map_dbl(Pred, ~ mape(y_test_vec, .x)), MAE = map_dbl(Pred, ~ mae (y_test_vec, .x)) ) %&gt;% select(-Pred) knitr::kable(tabla, digits = 3, caption = &quot;Comparación en TEST — RMSE, MAPE y MAE (escala original)&quot;) Table 5.4: Comparación en TEST — RMSE, MAPE y MAE (escala original) Modelo RMSE MAPE MAE HW Aditivo 468.700 37.098 414.311 HW Box–Cox (aditivo) 465.434 36.858 411.644 HW Multiplicativo 394.586 31.117 348.839 ARIMA simple 325.303 27.377 302.346 SARIMA (auto.arima) 280.641 23.245 258.154 ARIMA (log) 149.209 12.046 131.731 El ARIMA (log) es el modelo más preciso y estable, su transformación logarítmica estabilizó la varianza y suavizó los picos extremos, redujo los errores de manera drástica (RMSE ≈ 149, MAPE ≈ 12%). Es el modelo más adecuado para pronósticos precisos y consistentes en contextos con alta variabilidad o ruido. El SARIMA (auto.arima) también muestra un excelente desempeño, incorpora componentes estacionales (periodicidad de 24 horas) que reflejan patrones horarios o diarios, su RMSE (280.6) y MAPE (23.2%) indican alta precisión sin requerir transformaciones adicionales. Es un modelo balanceado entre complejidad y exactitud. El ARIMA simple (sin estacionalidad explícita) sigue siendo competitivo, logra capturar buena parte de la estructura temporal con pocos parámetros, su rendimiento (RMSE = 325.3, MAPE = 27.4%) lo posiciona por encima de todos los Holt–Winters. Los modelos Holt–Winters (HW) presentan resultados claramente inferiores, aunque coherentes con su simplicidad: El HW aditivo es el más limitado, porque no ajusta amplitudes variables. El HW multiplicativo mejora sustancialmente, al modelar estacionalidad proporcional al nivel de la serie. El HW Box–Cox suaviza la varianza pero no alcanza mejoras sustanciales frente al HW clásico. Los modelos ARIMA y SARIMA superan ampliamente a los de Holt–Winters porque logran capturar dependencias dinámicas, estacionalidad compleja y no linealidades que los modelos de suavizamiento no pueden representar. El ARIMA log-transformado se consolida como el modelo óptimo para la serie, al combinar estabilidad de varianza, bajo error absoluto y porcentual, y una excelente capacidad de ajuste temporal. El SARIMA es una alternativa igualmente robusta para escenarios donde se desea mantener la serie en escala original y enfatizar la estacionalidad. Los modelos Holt–Winters, si bien más simples, son útiles para análisis exploratorios o pronósticos rápidos, pero no alcanzan la precisión de los modelos ARIMA. 5.14 Gráficas de predicción por modelo suppressPackageStartupMessages({ library(dplyr); library(tibble); library(ggplot2); library(lubridate) }) # -------- Utilidades -------- build_fc_df &lt;- function(fc_obj, t_start, label, from_log = FALSE) { # fc_obj: objeto forecast con $mean/$lower/$upper o data.frame ya listo # t_start: POSIXct fin del histórico (última observación) # label: nombre del modelo para título # from_log: si TRUE, aplica expm1 a medias/bandas if (is.null(fc_obj)) return(NULL) # Caso forecast::forecast if (all(c(&quot;mean&quot;,&quot;lower&quot;,&quot;upper&quot;) %in% names(fc_obj))) { h &lt;- length(fc_obj$mean) f_times &lt;- seq(from = t_start + hours(1), by = &quot;1 hour&quot;, length.out = h) mean_v &lt;- as.numeric(fc_obj$mean) lo80_v &lt;- as.numeric(fc_obj$lower[,&quot;80%&quot;]) hi80_v &lt;- as.numeric(fc_obj$upper[,&quot;80%&quot;]) lo95_v &lt;- as.numeric(fc_obj$lower[,&quot;95%&quot;]) hi95_v &lt;- as.numeric(fc_obj$upper[,&quot;95%&quot;]) if (isTRUE(from_log)) { mean_v &lt;- expm1(mean_v); lo80_v &lt;- expm1(lo80_v); hi80_v &lt;- expm1(hi80_v) lo95_v &lt;- expm1(lo95_v); hi95_v &lt;- expm1(hi95_v) } return(tibble( modelo = label, time = f_times, mean = mean_v, lo80 = lo80_v, hi80 = hi80_v, lo95 = lo95_v, hi95 = hi95_v )) } # Caso data.frame ya convertido (espera columnas: time, mean, lo80, hi80[, lo95, hi95]) req_cols &lt;- c(&quot;time&quot;,&quot;mean&quot;,&quot;lo80&quot;,&quot;hi80&quot;) if (is.data.frame(fc_obj) &amp;&amp; all(req_cols %in% names(fc_obj))) { out &lt;- as_tibble(fc_obj) out$modelo &lt;- label # Si trae columnas 95% las respetamos; si no, las estimamos como NA if (!(&quot;lo95&quot; %in% names(out))) out$lo95 &lt;- NA_real_ if (!(&quot;hi95&quot; %in% names(out))) out$hi95 &lt;- NA_real_ return(out[,c(&quot;modelo&quot;,&quot;time&quot;,&quot;mean&quot;,&quot;lo80&quot;,&quot;hi80&quot;,&quot;lo95&quot;,&quot;hi95&quot;)]) } return(NULL) } plot_zoom_model &lt;- function(hist_df, fc_df, title_txt, history_days = 21, y_limits = NULL, breaks_x = &quot;3 days&quot;, fmt_x = &quot;%d-%b&quot;) { if (is.null(fc_df) || nrow(fc_df) == 0) return(invisible(NULL)) t_max &lt;- max(hist_df$time, na.rm = TRUE) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time, na.rm = TRUE) hist_zoom &lt;- filter(hist_df, time &gt;= t_ini) p &lt;- ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.12, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.22, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.45, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = breaks_x, date_labels = fmt_x) + labs(title = title_txt, subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia (escala original)&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1)) if (!is.null(y_limits)) { p &lt;- p + coord_cartesian(ylim = y_limits) } print(p) } # -------- Datos históricos (últimos N días) -------- stopifnot(exists(&quot;df_impu&quot;), exists(&quot;time_col&quot;)) history_days &lt;- 21 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) # -------- Construir data frames de pronóstico por modelo (condicional) -------- fc_list &lt;- list() # SARIMA principal (auto.arima) -&gt; &#39;fc&#39; if (exists(&quot;fc&quot;)) { fc_list[[&quot;SARIMA (auto.arima)&quot;]] &lt;- build_fc_df(fc, t_max, &quot;SARIMA (auto.arima)&quot;) } # ARIMA simple -&gt; &#39;fc_arima_simple&#39; if (exists(&quot;fc_arima_simple&quot;)) { fc_list[[&quot;ARIMA simple&quot;]] &lt;- build_fc_df(fc_arima_simple, t_max, &quot;ARIMA simple&quot;) } # HW aditivo -&gt; &#39;fc_hw_add&#39; if (exists(&quot;fc_hw_add&quot;)) { fc_list[[&quot;HW Aditivo&quot;]] &lt;- build_fc_df(fc_hw_add, t_max, &quot;Holt–Winters (aditivo)&quot;) } # HW multiplicativo -&gt; &#39;fc_hw_mul&#39; if (exists(&quot;fc_hw_mul&quot;) &amp;&amp; !is.null(fc_hw_mul)) { fc_list[[&quot;HW Multiplicativo&quot;]] &lt;- build_fc_df(fc_hw_mul, t_max, &quot;Holt–Winters (multiplicativo)&quot;) } # HW Box–Cox (aditivo) ya reconvertido (si preparaste df_hw_bc: time/mean/lo80/hi80[/lo95/hi95]) if (exists(&quot;df_hw_bc&quot;)) { fc_list[[&quot;HW Box–Cox (aditivo)&quot;]] &lt;- build_fc_df(df_hw_bc, t_max, &quot;Holt–Winters Box–Cox (aditivo)&quot;) } # ARIMA en log -&gt; &#39;fc_log&#39; (reconvertimos con expm1) if (exists(&quot;fc_log&quot;)) { fc_list[[&quot;ARIMA (log)&quot;]] &lt;- build_fc_df(fc_log, t_max, &quot;ARIMA (log → original)&quot;, from_log = TRUE) } # -------- Graficar uno por uno (solo los disponibles) -------- # Ajusta y_limits si quieres forzar un rango (p.ej. c(0, 10000)); déjalo NULL para automático y_limits &lt;- NULL for (nm in names(fc_list)) { plot_zoom_model(hist_df, fc_list[[nm]], title_txt = paste(&quot;Zoom final del pronóstico —&quot;, nm), history_days = history_days, y_limits = y_limits, breaks_x = &quot;3 days&quot;, fmt_x = &quot;%d-%b&quot;) } 5.15 Resumen de tiempos de ejecución del código tabla_tiempos &lt;- report_timing_table() if (!is.null(tabla_tiempos)) { knitr::kable(tabla_tiempos, caption = &quot;Resumen de tiempos por bloque&quot;) } else { cat(&quot;No se registraron bloques cronometrados.\\n&quot;) } Table 5.5: Resumen de tiempos por bloque Bloque Tiempo Unidad Estado Mensaje Imputación (na.interp) 0.023 s OK ACF/PACF (original) 0.143 s OK ACF/PACF (diferenciada) 0.131 s OK Ajuste SARIMA + Pronóstico 297.090 s OK Changepoint 0.017 s OK Ajuste SARIMA TS log-transformada 566.191 s OK HW - Preprocesamiento 16.390 s OK HW - Split TRAIN/TEST 1.106 s OK HW - Aditivo y multiplicativo 52.772 s OK HW - ARIMA simple 391.953 s OK HW - Box-CoX 28.914 s OK "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
