[["index.html", "Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos 1 Presentación del Bookdown", " Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo Maestría en Ciencia de Datos Fredy A. Ordoñez · Oscar F. Velásquez · José L. Sánchez 27 de octubre de 2025 1 Presentación del Bookdown Este Bookdown recopila las actividades desarrolladas a lo largo del curso de Series de Tiempo. Cada capítulo corresponde a una entrega o avance del proyecto, permitiendo evidenciar el progreso del análisis, los modelos aplicados y las conclusiones del trabajo final. ## NULL "],["propuesta.html", "2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? 2.2 ¿Por qué es importante? 2.3 Fuente de datos y permisos 2.4 Impacto esperado 2.5 Referencias", " 2 Propuesta de serie de tiempo: Predicción de demanda eléctrica a corto plazo 2.1 ¿Qué voy a pronosticar? La demanda eléctrica de corto plazo (1 hora adelante) en una subestación de distribución, usando la serie de potencia activa (kW) con resolución horaria. 2.2 ¿Por qué es importante? Operación eficiente: anticipar picos para evitar sobrecargas y maniobras reactivas. Calidad del servicio (SAIDI/SAIFI): programar mantenimientos y gestionar eventos reduciendo frecuencia y duración de interrupciones.SAIFI (System Average Interruption Frequency Index) indica la frecuencia promedio de las interrupciones que un cliente experimenta en un período determinado (por ejemplo, cuántas veces se va la luz al año), y el SAIDI (System Average Interruption Duration Index) mide la duración promedio acumulada de esas interrupciones para un cliente en ese mismo período (cuánto tiempo en total está sin servicio). Valor agregado: entregar una plantilla reproducible (scripts, métricas y gráficos) que soporte decisiones operativas. 2.3 Fuente de datos y permisos Fuente: datos SCADA históricos del operador de red de una subestación específica resolución horaria. Permisos: uso académico con anonimización de subestación y operador; no se publican datos crudos, solo resultados agregados y visualizaciones. Alcance: una subestación; análisis offline (sin integración en tiempo real). 2.4 Impacto esperado Técnico: reducción de error frente a métodos manuales; soporte a decisiones en turnos. Económico: mejor dimensionamiento de respaldo y diferimiento de inversiones. Académico: caso replicable en otras subestaciones con datos equivalentes. 2.5 Referencias Hyndman, R. &amp; Athanasopoulos (2018). Forecasting: Principles and Practice (3ª). Box, G. et al. (2015). Time Series Analysis: Forecasting and Control (5ª). Zhang, H. et al. (2019). “Short-term Load Forecasting Using LSTM Networks”, IEEE TSG. Herramienta TIC: Bookdown + GitHub Pages Sitio: https://joseluissanchezceballos.github.io/TimeSeries/propuesta.html Repo: https://github.com/joseluissanchezceballos/TimeSeries "],["análisis-de-serie-de-tiempo-potencia-eléctrica-horaria.html", "3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos 3.2 Cargue de Librerías 3.3 Lectura y preparación de los datos 3.4 Funciones auxiliares de visualización de la serie de tiempo 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) 3.7 Promedios móviles 3.8 Rezagos (lags) y autocorrelación 3.9 Estacionalidad (gráficos y descomposición) 3.10 Indicadores resumidos 3.11 Conclusiones", " 3 Análisis de Serie de Tiempo: Potencia Eléctrica Horaria 3.1 Contexto y objetivos El estudio analiza una serie temporal de potencia eléctrica horaria entre 2018 y 2025. El objetivo fue detectar patrones, ciclos y estacionalidades usando herramientas de R (lubridate, zoo, forecast) y visualizar la calidad de los datos (huecos, tendencias, estacionalidad, rezagos). El conjunto de datos es altamente completo: Completitud global: 99.48%. Años con menos completitud: 2019 (97.9%) y 2021 (99.4%). Años recientes (2022–2025): 100% de registros, sin huecos. La idea es detectar patrones y ciclos del comportamiento de la potencia eléctrica. 3.2 Cargue de Librerías library(readr) library(dplyr) ## ## Adjuntando el paquete: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(tidyr) library(lubridate) ## ## Adjuntando el paquete: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(ggplot2) library(scales) ## ## Adjuntando el paquete: &#39;scales&#39; ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor library(zoo) ## ## Adjuntando el paquete: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo 3.3 Lectura y preparación de los datos csv_dir &lt;- &quot;C:/Users/Lenovo/PUJ Cali/OSCAR VELASQUEZ CHALA - Proyecto Aplicado - Proy. Demanda Electrica/2. Fuentes de Datos&quot; csv_name &lt;- &quot;015 SOLO POTENCIA PARA SUBI A BOOKDOWN.csv&quot; csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot; y_col &lt;- &quot;VALOR_IMPUTADO&quot; TZ &lt;- &quot;America/Bogota&quot; # Lectura robusta df &lt;- tryCatch( readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE) ) stopifnot(time_col %in% names(df), y_col %in% names(df)) # Parseo de fechas (varios formatos) df[[time_col]] &lt;- parse_date_time( df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ ) # A numérico df[[y_col]] &lt;- suppressWarnings(readr::parse_number(as.character(df[[y_col]]))) # Malla horaria completa (sin imputar, para marcar huecos) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% select(!!time_col, !!y_col) %&gt;% arrange(.data[[time_col]]) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) summary(df_full[[y_col]]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0 1241 3550 3244 4996 10000 610 cat(&quot;Proporción de NA:&quot;, mean(is.na(df_full[[y_col]])), &quot;\\n&quot;) ## Proporción de NA: 0.005141302 3.4 Funciones auxiliares de visualización de la serie de tiempo # Unir horas NA contiguas en bandas na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% dplyr::filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } # Agregación genérica sin imputar tagrega &lt;- function(data, unit, time_col, y_col, tz = TZ) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) } 3.5 Vista general del comportamiento de la potencia eléctrica por escalas (diaria, semanal, mensual, anual) na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) plot_df &lt;- bind_rows( tagrega(df_full, &quot;day&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Diaria&quot;), tagrega(df_full, &quot;week&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Semanal&quot;), tagrega(df_full, &quot;month&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Mensual&quot;), tagrega(df_full, &quot;year&quot;, time_col, y_col) %&gt;% mutate(freq = &quot;Anual&quot;) ) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;,&quot;Semanal&quot;,&quot;Mensual&quot;,&quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.25) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.7, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + scale_x_datetime(labels = date_format(&quot;%Y&quot;), date_breaks = &quot;1 year&quot;) + labs(title = &quot;Potencia con huecos (NA)&quot;, subtitle = &quot;Bandas rojas = periodos con NA en la serie horaria original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Curva de Potencia Diaria: muestra alta variabilidad horaria con picos bien definidos, evidenciando que la potencia cambia fuertemente a lo largo del día. Curva de Potencia Semanal: suaviza los ciclos, pero aún se aprecian repeticiones cada pocos días, sugiriendo un patrón operativo estable. Curva de Potencia Mensual: las oscilaciones se atenúan, revelando la tendencia global; los huecos rojos (NA) se observan concentrados en pocos periodos. Curva de Potencia Anual: la línea muestra el comportamiento global a largo rango: valores medios estables sin deriva significativa, lo que sugiere una operación controlada y sin aumento sostenido del consumo. La serie mantiene un patrón estacional fuerte (diario y semanal) y una tendencia global estacionaria. Los huecos (en rojo) son mínimos y no distorsionan las medias agregadas. 3.6 Curvas de potencia eléctrica por periodo (día, semana, mes, año) # Día dia_obj &lt;- as.Date(&quot;2023-02-01&quot;) ini_dia &lt;- as.POSIXct(dia_obj, tz = TZ); fin_dia &lt;- ini_dia + days(1) df_day &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_dia, .data[[time_col]] &lt; fin_dia) na_day &lt;- na_spans_runs(df_day[[time_col]], df_day$is_na) g_day &lt;- ggplot() + geom_rect(data = na_day, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_day, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_dia, fin_dia), date_labels=&quot;%H:%M&quot;, breaks=seq(ini_dia, fin_dia, by=&quot;2 hour&quot;)) + labs(title=paste0(&quot;Curva horaria — &quot;, dia_obj), x=&quot;Hora&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_day Día: 1 febrero 2023:Curva con forma sinusoidal: potencia baja en la madrugada, aumento progresivo durante el día, pico en horas centrales y descenso nocturno. Refleja un ciclo operativo típico diario. # Semana semana_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_sem &lt;- as.POSIXct(floor_date(semana_ref, &quot;week&quot;, week_start=1), tz=TZ) fin_sem &lt;- ini_sem + weeks(1) df_week &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_sem, .data[[time_col]] &lt; fin_sem) na_week &lt;- na_spans_runs(df_week[[time_col]], df_week$is_na) g_week &lt;- ggplot() + geom_rect(data = na_week, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.35) + geom_line(data = filter(df_week, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.8) + scale_x_datetime(limits=c(ini_sem, fin_sem), date_labels=&quot;%a %d&quot;, breaks=seq(ini_sem, fin_sem, by=&quot;1 day&quot;)) + labs(title=paste0(&quot;Semana del &quot;, ini_sem), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_week Semana: 1–7 febrero 2021: Repetición diaria clara, pero con leves diferencias entre días. Puede reflejar cambios de carga entre jornadas laborales y fines de semana. # Mes mes_ref &lt;- as.Date(&quot;2021-02-01&quot;) ini_mes &lt;- as.POSIXct(floor_date(mes_ref, &quot;month&quot;), tz=TZ); fin_mes &lt;- as.POSIXct(ceiling_date(mes_ref, &quot;month&quot;), tz=TZ) df_month &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_mes, .data[[time_col]] &lt; fin_mes) na_month &lt;- na_spans_runs(df_month[[time_col]], df_month$is_na) g_month &lt;- ggplot() + geom_rect(data = na_month, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.25) + geom_line(data = filter(df_month, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.6) + scale_x_datetime(limits=c(ini_mes, fin_mes), date_labels=&quot;%d-%b&quot;, breaks=seq(ini_mes, fin_mes, by=&quot;3 days&quot;)) + labs(title=paste0(&quot;Mes &quot;, format(ini_mes, &#39;%Y-%m&#39;)), x=&quot;Fecha&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_month Mes: febrero 2021: Patrón reiterado de picos semanales. Los huecos rojos (NA) marcan interrupciones puntuales sin afectar la tendencia global. # Año (panel único) anio_ref &lt;- 2021 ini_anio &lt;- as.POSIXct(ymd(paste0(anio_ref, &quot;-01-01&quot;)), tz=TZ); fin_anio &lt;- as.POSIXct(ymd(paste0(anio_ref+1, &quot;-01-01&quot;)), tz=TZ) df_year &lt;- df_full %&gt;% filter(.data[[time_col]] &gt;= ini_anio, .data[[time_col]] &lt; fin_anio) na_year &lt;- na_spans_runs(df_year[[time_col]], df_year$is_na) g_year &lt;- ggplot() + geom_rect(data = na_year, aes(xmin = xmin, xmax = xmax, ymin=-Inf, ymax=Inf), inherit.aes = FALSE, fill=&quot;red&quot;, alpha = 0.20) + geom_line(data = filter(df_year, !is_na), aes_string(x=time_col, y=y_col), linewidth=0.3) + scale_x_datetime(limits=c(ini_anio, fin_anio), date_labels=&quot;%b&quot;, breaks=seq(ini_anio, fin_anio, by=&quot;1 month&quot;)) + labs(title=paste0(&quot;Año &quot;, anio_ref), x=&quot;Mes&quot;, y=&quot;Potencia&quot;) + theme_minimal() g_year Año: 2021: Oscilaciones estacionales sin tendencia definida. No se observan desviaciones estructurales. A nivel temporal, la potencia responde a ciclos regulares con comportamiento casi periódico. 3.7 Promedios móviles Promedios móviles sobre la serie horaria (imputada solo para continuidad visual con na.interp). # --- Promedios móviles coloreados (24h, 168h, 720h) --- # 1) Crea la serie imputada y los MAs df_impu &lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) df_ma &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), `MA 24h` = zoo::rollmean(val_impu, k = 24, align = &quot;right&quot;, fill = NA), `MA 168h` = zoo::rollmean(val_impu, k = 168, align = &quot;right&quot;, fill = NA), `MA 720h` = zoo::rollmean(val_impu, k = 720, align = &quot;right&quot;, fill = NA) ) # 2) Pasar los MAs a formato largo para mapear color por serie library(tidyr) df_ma_long &lt;- df_ma %&gt;% tidyr::pivot_longer(cols = c(`MA 24h`,`MA 168h`,`MA 720h`), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) # 3) Graficar: original en gris, MAs en colores ggplot(df_ma, aes(x = time)) + # Serie original geom_line(aes(y = y), color = &quot;grey80&quot;, linewidth = 0.2, alpha = 0.6) + # Promedio móvil corto (24h) — se dibuja primero geom_line(aes(y = `MA 24h`), color = &quot;#1f77b4&quot;, linewidth = 0.6, alpha = 0.8) + # Promedio móvil intermedio (168h) — encima de la azul geom_line(aes(y = `MA 168h`), color = &quot;#2ca02c&quot;, linewidth = 0.9, alpha = 0.9) + # Promedio móvil largo (720h) — encima de las anteriores geom_line(aes(y = `MA 720h`), color = &quot;#d62728&quot;, linewidth = 1.1, alpha = 1) + labs( title = &quot;Promedios móviles (24h, 168h, 720h)&quot;, subtitle = &quot;Curvas suavizadas de corto, mediano y largo plazo&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;)) La línea gris (serie original) muestra picos horarios abruptos. La línea azul (media móvil 24h) suaviza el ruido diario. La línea verde (media móvil 168h) identifica la tendencia semanal. La línea roja (media móvil 720h) resume la tendencia mensual. No se observan rupturas ni tendencias marcadas. Las tres medias convergen en un rango estable. 3.8 Rezagos (lags) y autocorrelación # --- Rezagos a nivel horario (1, 24, 168, 720) --- df_lags &lt;- df_impu %&gt;% transmute( time = .data[[time_col]], y = as.numeric(val_impu), lag_1 = dplyr::lag(as.numeric(val_impu), 1), lag_24 = dplyr::lag(as.numeric(val_impu), 24), lag_168 = dplyr::lag(as.numeric(val_impu), 168), lag_720 = dplyr::lag(as.numeric(val_impu), 720) ) # Correlaciones cors &lt;- c( cor(df_lags$y, df_lags$lag_1, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_24, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_168, use = &quot;complete.obs&quot;), cor(df_lags$y, df_lags$lag_720, use = &quot;complete.obs&quot;) ) setNames(round(cors, 3), c(&quot;lag1&quot;,&quot;lag24&quot;,&quot;lag168&quot;,&quot;lag720&quot;)) ## lag1 lag24 lag168 lag720 ## 0.977 0.802 0.766 0.749 Lag 1: 0.977 → fuerte dependencia entre horas consecutivas. Lag 24: 0.802 → patrón diario repetitivo. Lag 168: 0.766 → correlación semanal clara. Lag 720: 0.749 → correlación mensual aún significativa. Los altos valores confirman una autocorrelación fuerte y múltiple (hora, día, semana, mes). Esto valida la presencia de estacionalidad múltiple y un comportamiento cíclico persistente. #ACF y PACF: Análisis de Autocorrelación library(ggplot2) # 1) Serie imputada -&gt; vector numérico sin NA serie_vec &lt;- as.numeric(df_impu$val_impu) serie_vec &lt;- serie_vec[!is.na(serie_vec)] # 2) Definir lag máximo (p.ej. 30 días = 24*30) max_lag &lt;- 24 * 30 # 3) Calcular ACF y PACF sin graficar acf_obj &lt;- acf(serie_vec, lag.max = max_lag, plot = FALSE) pacf_obj &lt;- pacf(serie_vec, lag.max = max_lag, plot = FALSE) # 4) Pasar a data frame (ojo: ambos traen valores en $acf) acf_df &lt;- data.frame( lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf) ) pacf_df &lt;- data.frame( lag = as.numeric(pacf_obj$lag), # lags desde 1 normalmente pacf = as.numeric(pacf_obj$acf) # valores de PACF están en $acf ) # 5) Bandas de confianza 95% n_eff &lt;- length(serie_vec) ci &lt;- 1.96 / sqrt(n_eff) # 6) Graficar con ggplot2 # --- ACF --- ggplot(acf_df, aes(x = lag, y = acf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;ACF - Autocorrelación de la serie horaria&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal(base_size = 12) El gráfico ACF muestra la correlación de la serie de potencia horaria consigo misma a diferentes rezagos (lags), medidos en horas. En el rezago 0 la autocorrelación es 1, cada punto está completamente correlacionado consigo mismo. Se observa una autocorrelación muy alta y sostenida en casi todos los rezagos, con valores cercanos a 0.75–0.80 hasta aproximadamente 700 horas (~30 días). Esta persistencia indica que la serie mantiene una dependencia temporal fuerte, es decir, los valores pasados tienen gran influencia sobre los futuros. Se aprecian picos regulares (aprox. cada 24, 168 y 720 rezagos), lo que evidencia patrones estacionales diarios, semanales y mensuales. Las bandas rojas horizontales representan los límites de significancia al 95% (±0.006). Todos los valores de la ACF están muy por encima de esas bandas, lo que confirma que la autocorrelación es estadísticamente significativa en todos los horizontes analizados. La serie presenta una estructura fuertemente autocorrelacionada, con periodicidad marcada y ciclos regulares. Esto indica que no es una serie puramente aleatoria, sino que está dominada por una estacionalidad sistemática de carácter diario y semanal. # --- PACF --- ggplot(pacf_df, aes(x = lag, y = pacf)) + geom_col(width = 0.9) + geom_hline(yintercept = 0, linewidth = 0.3) + geom_hline(yintercept = c(-ci, ci), linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;PACF - Autocorrelación parcial&quot;, subtitle = paste(&quot;Límites 95% ±&quot;, round(ci, 3)), x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal(base_size = 12) El gráfico PACF muestra la correlación entre la serie y sus rezagos una vez eliminada la influencia de los rezagos intermedios. Se observa un pico alto en el primer rezago (lag = 1), lo que indica una fuerte dependencia inmediata (efecto de la hora anterior). Después del primer rezago, los valores de la PACF caen rápidamente y se mantienen cerca de cero, salvo algunos picos débiles en rezagos aproximadamente iguales a 24, 168 y 720 horas, que corresponden a efectos estacionales. Estos picos secundarios son pequeños pero significativos, lo que sugiere una estacionalidad múltiple (día, semana, mes). La PACF confirma que el comportamiento actual de la potencia depende principalmente de su valor en la hora anterior (AR(1)), junto con componentes estacionales de largo plazo. 3.9 Estacionalidad (gráficos y descomposición) Para descomponer, usamos un objeto ts regular con frecuencia diaria (24), semanal (24*7) o anual (24*365). Utilizamos la serie imputada val_impu para evitar huecos. # Construir ts con frecuencia diaria (24 por ciclo) start_time &lt;- min(df_impu[[time_col]], na.rm = TRUE) Indice.ts.diaria &lt;- ts(df_impu$val_impu, start = c(year(start_time), hour(start_time) + 1), frequency = 24) # Gráficos estacionales (por hora del día y por mes) autoplot(Indice.ts.diaria) + ggtitle(&quot;Serie ts (freq=24)&quot;) Serie ts (freq = 24) La serie presenta alta variabilidad (cada día cambia mucho), con rupturas o cambios estructurales en determinados años. Esto indica que el sistema de potencia tiene patrones por periodos largos más que una estacionalidad estricta diaria. # STL y gráficos estacionales fit_stl &lt;- stl(Indice.ts.diaria, s.window = &quot;periodic&quot;) plot(fit_stl, main = &quot;Descomposición STL (frecuencia diaria)&quot;) Decomposición STL frecuencia diaria * data: Muestra la potencia total observada con todas sus fluctuaciones. * seasonal: Se observa una banda negra uniforme, porque la variabilidad de la serie es mucho mayor que la amplitud de la estacionalidad. * trend: Se observan periodos con incrementos o descensos sostenidos de potencia * remainder: Presenta la variabilidad de corto plazo, los picos, fallos de medición y valores atípicos # Define un inicio dinámico (o fija una fecha) ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) slice &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(slice$val_impu), frequency = 24) fit_zoom &lt;- stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE) plot(fit_zoom, range.bars = FALSE, main = &quot;STL en ventana (4 semanas)&quot;) Decomposición STL en una ventana de 4 semanas data: Se observan oscilaciones regulares de subida y bajada cada 24 horas, lo cual refleja el patrón de potencia diario. Hay algunos huecos o caídas abruptas que corresponden a datos faltantes o interrupciones de registro de los datos. La serie se mueve alrededor de una media aproximada de 5000–6000 KW, con variaciones diarias de alrededor de ±1000 – 1500 KW. seasonal: Se observa una forma de onda repetitiva tipo sinusoinal, con un ciclo por día. La serie tiene una estacionalidad clara diaria: la potencia sube en ciertas horas (probablemente durante el día laboral) y baja en otras (probablemente por la noche). La amplitud del patrón se mantiene bastante constante, lo que sugiere que la estacionalidad diaria no cambia mucho entre semanas. trend: Se observan ondas de mayor periodo que podrían corresponder a variaciones semanales. La tendencia muestra subidas y bajadas lentas, lo que indica variabilidad estructural o cambios progresivos en el nivel medio de potencia. La escala vertical está alrededor de los 5000–7000 KW. remainder: Los picos hacia arriba o abajo representan anomalías, errores o eventos inusuales. Se observan algunos picos negativos fuertes, que podrían deberse a interrupciones o registros incorrectos de potencia (NA o 0). El resto del residuo oscila cerca de cero, lo cual es deseable (significa que la mayor parte de la variabilidad fue capturada por tendencia + estacionalidad). En resumen, la serie de potencia tiene una estacionalidad diaria fuerte, una tendencia suave semanal, y ruido moderado. 3.10 Indicadores resumidos # Completitud global comp_global &lt;- 1 - mean(is.na(df_full[[y_col]])) # Completitud por año comp_anio &lt;- df_full %&gt;% dplyr::group_by(anio = lubridate::year(.data[[time_col]])) %&gt;% dplyr::summarise( comp = 1 - mean(is.na(.data[[y_col]])), n_obs = dplyr::n(), .groups = &quot;drop&quot; ) comp_global ## [1] 0.9948587 comp_anio ## # A tibble: 8 × 3 ## anio comp n_obs ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2018 0.996 38330 ## 2 2019 0.979 15639 ## 3 2020 0.997 17424 ## 4 2021 0.994 11444 ## 5 2022 1 9793 ## 6 2023 1 9893 ## 7 2024 1 9712 ## 8 2025 1 6412 Año Completitud Observaciones 2018 99.6% Muy buena cobertura 2019 97.9% Ligera pérdida de datos 2020 99.7% Excelente 2021 99.4% Alta 2022–2025 100% Sin huecos 3.11 Conclusiones La serie de potencia es altamente estacionaria y cíclica. Existen ciclos claros de 24 y 168 horas, reflejando comportamientos diarios y semanales. No se detectan tendencias de crecimiento, lo que indica estabilidad en la operación. Los promedios móviles confirman consistencia estructural. La descomposición STL y la ACF refuerzan la idea de una estacionalidad regular y predecible. La calidad del registro (99.5%) garantiza confiabilidad para análisis predictivos. "],["Preprocesamiento.html", "4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen 4.2 Carga de librerías 4.3 Carga de datos y visualización 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación 4.5 ACF y PACF (original y diferenciada) 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico 4.8 Puntos de cambio y visualización 4.9 Outliers y verificación de supuestos del ARIMA 4.10 Transformación logarítmica para estabilizar la varianza 4.11 Ajuste del modelo ARIMA en escala logarítmica 4.12 Verificación de supuestos del nuevo modelo 4.13 Pronóstico con el modelo mejorado (escala logarítmica) 4.14 Conclusiones", " 4 Preprocesamiento y visualización - Estacionariedad, ACF/PACF, STL, ARIMA, Puntos de cambio y Pronóstico 4.1 Resumen Este cápitulo presenta una interpretación detallada de los resultados de Preprocesamiento y visualización de la serie temporal horaria de potencia. Se describen los patrones de tendencia y estacionalidad a distintas escalas (diaria, semanal, mensual y anual), la verificación/inducción de estacionariedad (diferenciación), el análisis ACF/PACF, la descomposición STL/MSTL, la detección de puntos de cambio, la identificación de outliers, el ajuste SARIMA (auto.arima) y el pronóstico. 4.2 Carga de librerías library(readr) library(dplyr) library(tidyr) library(lubridate) library(ggplot2) library(scales) library(zoo) library(forecast) library(tseries) library(changepoint) 4.3 Carga de datos y visualización csv_path &lt;- file.path(csv_dir, csv_name) time_col &lt;- &quot;FECHA&quot;; y_col &lt;- &quot;VALOR_IMPUTADO&quot; df &lt;- tryCatch(readr::read_csv(csv_path, show_col_types = FALSE), error = function(e) readr::read_csv2(csv_path, show_col_types = FALSE)) # Parseo robusto de fecha-hora y valor df[[time_col]] &lt;- parse_date_time(df[[time_col]], orders = c(&quot;ymd HMS&quot;,&quot;ymd HM&quot;,&quot;dmy HMS&quot;,&quot;dmy HM&quot;,&quot;ymd&quot;,&quot;dmy&quot;), tz = TZ) df[[y_col]] &lt;- suppressWarnings(as.numeric(df[[y_col]])) # Malla horaria completa para marcar NA (sin imputar) df0 &lt;- df %&gt;% filter(!is.na(.data[[time_col]])) %&gt;% arrange(.data[[time_col]]) %&gt;% select(!!time_col, !!y_col) full_time &lt;- tibble(!!time_col := seq(min(df0[[time_col]]), max(df0[[time_col]]), by = &quot;1 hour&quot;)) df_full &lt;- full_time %&gt;% left_join(df0, by = time_col) %&gt;% mutate(is_na = is.na(.data[[y_col]])) %&gt;% arrange(.data[[time_col]]) # Serie imputada (para métodos que exigen regularidad) tm(&quot;Imputación (na.interp)&quot;, { df_impu &lt;&lt;- df_full %&gt;% mutate(val_impu = forecast::na.interp(.data[[y_col]])) }) # Vista rápida: primer tramo ggplot(df_full, aes(x = .data[[time_col]], y = .data[[y_col]])) + geom_line(na.rm = TRUE) + labs(title = &quot;Serie horaria de potencia (con huecos)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() Se observa la secuencia temporal de los valores de potencia con discontinuidades. 4.3.1 Bandas para huecos (NA) y vistas multiescala na_spans_runs &lt;- function(x_time, is_na_logical) { r &lt;- rle(is_na_logical) ed &lt;- cumsum(r$lengths); st &lt;- ed - r$lengths + 1 tibble(is_na = r$values, i_start = st, i_end = ed) %&gt;% filter(is_na) %&gt;% transmute(xmin = x_time[i_start], xmax = x_time[i_end] + hours(1)) } agg_by &lt;- function(data, unit, label, time_col, y_col) { data %&gt;% mutate(period = floor_date(.data[[time_col]], unit)) %&gt;% group_by(period) %&gt;% summarise(value = mean(.data[[y_col]], na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% mutate(freq = label) } na_runs &lt;- na_spans_runs(df_full[[time_col]], df_full$is_na) diaria &lt;- agg_by(df_full, &quot;day&quot;, &quot;Diaria&quot;, time_col, y_col) semanal &lt;- agg_by(df_full, &quot;week&quot;, &quot;Semanal&quot;, time_col, y_col) mensual &lt;- agg_by(df_full, &quot;month&quot;, &quot;Mensual&quot;, time_col, y_col) anual &lt;- agg_by(df_full, &quot;year&quot;, &quot;Anual&quot;, time_col, y_col) plot_df &lt;- bind_rows(diaria, semanal, mensual, anual) %&gt;% mutate(freq = factor(freq, levels = c(&quot;Diaria&quot;, &quot;Semanal&quot;, &quot;Mensual&quot;, &quot;Anual&quot;))) ggplot() + geom_rect(data = na_runs, aes(xmin = xmin, xmax = xmax, ymin = -Inf, ymax = Inf), inherit.aes = FALSE, fill = &quot;red&quot;, alpha = 0.3) + geom_line(data = plot_df, aes(x = period, y = value), linewidth = 0.6, na.rm = TRUE) + facet_wrap(~ freq, scales = &quot;free_x&quot;, ncol = 2) + labs(title = &quot;Potencia — vistas diaria, semanal, mensual y anual&quot;, subtitle = &quot;Bandas rojas: periodos con NA en la serie original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 11) Las discontinuidades se indicaron con franjas de color rojo. Estos huecos fueron imputados usando forecast::na.interp, método lineal-local que mantiene la coherencia temporal. La imputación es obligatoria para construir una serie regular (necesaria para ARIMA, STL y MSTL). Si no se hace, los modelos no convergen ni generan predicciones confiables. La potencia muestra una variabilidad cíclica, con fluctuaciones más suaves en las escalas semanales y mensuales. Las bandas rojas señalan períodos con datos ausentes; su distribución ayuda a evaluar si hay estacionalidad interrumpida. El análisis multiescala permite identificar tendencias de largo plazo y patrones repetitivos en diferentes horizontes. 4.4 Estacionariedad: prueba ADF (Augmented Dickey-Fuller Test) y diferenciación # Vector numérico imputado serie_vec &lt;- as.numeric(df_impu$val_impu) # ADF en serie original adf_raw &lt;- tseries::adf.test(serie_vec, k = 24) adf_raw ## ## Augmented Dickey-Fuller Test ## ## data: serie_vec ## Dickey-Fuller = -24.434, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria en media. # Diferenciación sugerida y gráfico d_sugerido &lt;- forecast::ndiffs(serie_vec) cat(&quot;Diferenciaciones sugeridas por ndiffs:&quot;, d_sugerido, &quot;\\n&quot;) ## Diferenciaciones sugeridas por ndiffs: 1 “ndiffs” sugiere una diferenciación (d = 1) para estabilizar tendencia y variabilidad. serie_diff &lt;- if (d_sugerido &gt; 0) diff(serie_vec, differences = d_sugerido) else serie_vec df_diff &lt;- tibble::tibble( time = as.POSIXct(df_impu[[time_col]])[seq_along(serie_vec)], Original = as.numeric(serie_vec), Diferenciada = c(rep(NA, d_sugerido), as.numeric(serie_diff)) ) |&gt; tidyr::pivot_longer(cols = c(Original, Diferenciada), names_to = &quot;Serie&quot;, values_to = &quot;Valor&quot;) ggplot(df_diff, aes(time, Valor, color = Serie)) + geom_line(linewidth = 0.6, alpha = 0.9, na.rm = TRUE) + scale_color_manual(values = c(Original = &quot;#6B7280&quot;, Diferenciada = &quot;#1F77B4&quot;)) + labs(title = &quot;Serie original vs. diferenciada&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia / ΔPotencia&quot;, color = &quot;Serie&quot;) + theme_minimal(base_size = 12) La serie original presenta tendencia ascendente y picos altos. La serie diferenciada elimina la tendencia de la serie original, centrando la media alrededor de cero y reduciendo varianza. # ADF nuevamente si se diferenció if (d_sugerido &gt; 0) { cat(&quot;\\nRe-prueba ADF en la serie diferenciada (d =&quot;, d_sugerido, &quot;):\\n&quot;) print(tseries::adf.test(serie_diff, k = 24)) } ## ## Re-prueba ADF en la serie diferenciada (d = 1 ): ## ## Augmented Dickey-Fuller Test ## ## data: serie_diff ## Dickey-Fuller = -91.566, Lag order = 24, p-value = 0.01 ## alternative hypothesis: stationary El resultado de la Prueba ADF (Dickey-Fuller aumentada) para la serie diferenciada indica que p-value = 0.01 &lt; 0.05, indicando que es una serie estacionaria. En modelos ARIMA se necesita estacionariedad. La diferenciación controla la no estacionariedad estructural sin alterar la forma estacional de corto plazo. 4.5 ACF y PACF (original y diferenciada) # ============================================================ # 6. ACF y PACF (original y diferenciada) # ============================================================ # --- Calcular ACF/PACF de la serie original --- t0 &lt;- Sys.time() acf_obj &lt;- try(acf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_obj &lt;- try(pacf(serie_vec, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (original)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_obj, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) # --- Graficar ACF/PACF de la serie original --- if (!inherits(acf_obj, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_obj, &quot;try-error&quot;)) { acf_df &lt;- data.frame(lag = as.numeric(acf_obj$lag), acf = as.numeric(acf_obj$acf)) pacf_df &lt;- data.frame(lag = as.numeric(pacf_obj$lag), pacf = as.numeric(pacf_obj$acf)) ci &lt;- 1.96 / sqrt(length(serie_vec)) p1 &lt;- ggplot(acf_df, aes(lag, acf)) + geom_col(fill = &quot;#1f77b4&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p2 &lt;- ggplot(pacf_df, aes(lag, pacf)) + geom_col(fill = &quot;#ff7f0e&quot;) + geom_hline(yintercept = c(-ci, ci), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie original)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p1); print(p2) } else { cat(&quot;Error al calcular ACF/PACF de la serie original.\\n&quot;) } # --- Serie diferenciada --- if (exists(&quot;serie_diff&quot;) &amp;&amp; length(serie_diff) &gt; 10 &amp;&amp; !identical(serie_diff, serie_vec)) { t0 &lt;- Sys.time() acf_d &lt;- try(acf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) pacf_d &lt;- try(pacf(serie_diff, lag.max = lag_max, plot = FALSE), silent = TRUE) .timing[[&quot;ACF/PACF (diferenciada)&quot;]] &lt;- list(seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(acf_d, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = NA_character_) if (!inherits(acf_d, &quot;try-error&quot;) &amp;&amp; !inherits(pacf_d, &quot;try-error&quot;)) { acf_df_d &lt;- data.frame(lag = as.numeric(acf_d$lag), acf = as.numeric(acf_d$acf)) pacf_df_d &lt;- data.frame(lag = as.numeric(pacf_d$lag), pacf = as.numeric(pacf_d$acf)) ci_d &lt;- 1.96 / sqrt(length(serie_diff)) p3 &lt;- ggplot(acf_df_d, aes(lag, acf)) + geom_col(fill = &quot;#17becf&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;ACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;ACF&quot;) + theme_minimal() p4 &lt;- ggplot(pacf_df_d, aes(lag, pacf)) + geom_col(fill = &quot;#2ca02c&quot;) + geom_hline(yintercept = c(-ci_d, ci_d), linetype=&quot;dashed&quot;, color=&quot;red&quot;) + labs(title = &quot;PACF (serie diferenciada)&quot;, x = &quot;Rezago (horas)&quot;, y = &quot;PACF&quot;) + theme_minimal() print(p3); print(p4) } else { cat(&quot;Error al calcular ACF/PACF diferenciada.\\n&quot;) } } La ACF de la serie original muestra valores muy altos (cercanos a 1) en los primeros rezagos y una disminución muy lenta a medida que aumenta el lag (hasta aproximadamente 168 horas, es decir, 7 días). La curva no cruza la banda de significancia (líneas rojas), lo cual indica una persistencia fuerte. La alta autocorrelación inicial y su decaimiento lento son señales claras de no estacionariedad. Este patrón implica que los valores pasados influyen fuertemente en los futuros, y que la serie tiene una tendencia o un ciclo estacional persistente. La leve oscilación alrededor de los rezagos 24, 48, 72, etc., sugiere la presencia de una estacionalidad diaria (24 horas). En conjunto, la ACF indica que la serie no tiene media constante y no fluctúa alrededor de un equilibrio estable. La serie original no es estacionaria y requiere una transformación (diferenciación) para eliminar la tendencia y permitir el uso de modelos ARIMA. La PACF de la serie original presenta un pico muy pronunciado en el lag 1 y luego una rápida caída hacia valores pequeños alrededor de cero. El gran valor en el primer rezago indica un componente autoregresivo fuerte de orden 1 (AR(1)). La rápida caída posterior confirma que la mayor parte de la dependencia directa se concentra en los primeros rezagos. Los valores bajos pero persistentes en rezagos múltiples reflejan todavía efectos indirectos acumulados, producto de la tendencia no estacionaria detectada. La PACF confirma un componente autoregresivo significativo en la estructura de la serie original, aunque su interpretación precisa se distorsiona por la presencia de tendencia y estacionalidad. La ACF de la serie diferenciada muestra una autocorrelación fuerte únicamente en el rezago 1, pero el resto de las barras caen rápidamente dentro del intervalo de confianza (líneas rojas). La diferenciación ha eliminado con éxito la tendencia y la dependencia a largo plazo. Los valores cercanos a cero en los rezagos mayores indican que la serie ya no tiene memoria prolongada, es decir, es estacionaria en media. El ligero pico negativo en los primeros rezagos podría sugerir un componente MA (Media Móvil) de bajo orden. Tras la diferenciación, la ACF evidencia una serie estacionaria y más estable, con correlación significativa sólo a corto plazo. En la PACF de la serie diferenciada se observa un primer pico negativo (ligeramente pronunciado) y luego valores pequeños oscilando alrededor de cero, sin superar el umbral de significancia. Este patrón es típico de una serie con componente MA (q) después de la diferenciación. La ausencia de picos claros más allá del primer rezago indica que no existen dependencias autoregresivas persistentes. La PACF de la serie diferenciada confirma que el proceso se estabilizó tras la diferenciación, y que la estructura autoregresiva se redujo sustancialmente, favoreciendo modelos ARIMA sencillos con un componente de media móvil dominante. 4.6 Descomposición STL (Seasonal-Trend decomposition using Loess) y MSTL (Multiple Seasonal-Trend decomposition using Loess) val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else if (&quot;VALOR_IMPUTADO&quot; %in% names(df_impu)) &quot;VALOR_IMPUTADO&quot; else stop(&quot;No encuentro columna de valores: usa &#39;val_impu&#39; o &#39;VALOR_IMPUTADO&#39;.&quot;) # Utilidad para detectar columna estacional por periodo (acepta &#39;Seasonal-24&#39;, &#39;Seasonal 24&#39;, etc.) find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) if (!any(is_seas)) return(NULL) seas_nm &lt;- nm[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # ========== A) df_seas24: Estacionalidad diaria (24h) desde SERIE HORARIA ========== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_m_hour &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_h &lt;- as.data.frame(fit_m_hour) col_s24 &lt;- find_seasonal_col(comp_h, 24) if (is.null(col_s24)) { # fallback: primera &#39;Seasonal&#39; si no se pudo detectar 24 específicamente cand &lt;- grep(&quot;^Seasonal&quot;, names(comp_h), ignore.case = TRUE, value = TRUE) col_s24 &lt;- cand[1] } df_seas24 &lt;- tibble( time = time_hr, Componente = &quot;Estacionalidad diaria (24h)&quot;, Valor = comp_h[[col_s24]] ) # ========== B) df_seas12: Estacionalidad mensual (12) desde SERIE MENSUAL ========== monthly &lt;- df_impu %&gt;% mutate(mes = floor_date(.data[[time_col]], &quot;month&quot;)) %&gt;% summarise(.by = mes, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(mes) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(year(min(monthly$mes)), month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # detectar columna estacional (nombre puede ser &quot;seasonal&quot;/&quot;Seasonal&quot;) seas_col_m &lt;- names(comp_m)[grepl(&quot;season&quot;, names(comp_m), ignore.case = TRUE)][1] if (is.na(seas_col_m)) stop(&quot;No se encontró columna estacional en STL mensual.&quot;) df_seas12 &lt;- tibble( time = as.POSIXct(monthly$mes), # unificamos a POSIXct Componente = &quot;Estacionalidad mensual (12)&quot;, Valor = comp_m[[seas_col_m]] ) # ========== C) df_day_panel: Observada, Tendencia, Semanal(7d), Anual(365d), Residuo (SERIE DIARIA) ========== daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% summarise(.by = day, y = mean(.data[[val_col]], na.rm = TRUE)) %&gt;% arrange(day) ts_day &lt;- forecast::msts(daily$y, seasonal.periods = c(7, 365)) fit_m_day &lt;- forecast::mstl(ts_day, robust = TRUE) comp_d &lt;- as.data.frame(fit_m_day) # Normalizamos nombres para &#39;Trend&#39; y &#39;Remainder&#39; nmd &lt;- names(comp_d) nmd &lt;- sub(&quot;^trend$&quot;, &quot;Trend&quot;, nmd, ignore.case = TRUE) nmd &lt;- sub(&quot;^remainder$&quot;, &quot;Remainder&quot;, nmd, ignore.case = TRUE) names(comp_d) &lt;- nmd # Detectar columnas estacionales 7 y 365 is_seas &lt;- grepl(&quot;^Seasonal&quot;, names(comp_d), ignore.case = TRUE) seas_nms &lt;- names(comp_d)[is_seas] getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } seas_p &lt;- vapply(seas_nms, getp, integer(1)) idx7 &lt;- which(seas_p == 7) idx365 &lt;- which(seas_p == 365) seas7 &lt;- if (length(idx7)) comp_d[[seas_nms[idx7[1]]]] else NULL seas365 &lt;- if (length(idx365)) comp_d[[seas_nms[idx365[1]]]] else NULL df_day_panel &lt;- tibble( time = as.POSIXct(daily$day), Observada = daily$y, Tendencia = if (&quot;Trend&quot; %in% names(comp_d)) comp_d$Trend else NA_real_, Residuo = if (&quot;Remainder&quot; %in% names(comp_d)) comp_d$Remainder else NA_real_ ) if (!is.null(seas7)) df_day_panel[[&quot;Estacionalidad semanal (7d)&quot;]] &lt;- seas7 if (!is.null(seas365)) df_day_panel[[&quot;Estacionalidad anual (365d)&quot;]] &lt;- seas365 df_day_panel &lt;- df_day_panel |&gt; pivot_longer(-time, names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) # ========== D) Panel combinado ========== panel_all &lt;- bind_rows( df_day_panel, # Observada/Tendencia/Residuo + 7d/365d si existen df_seas24, # Estacionalidad diaria (24h) desde HORAS df_seas12 # Estacionalidad mensual (12) desde MESES ) %&gt;% mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;, &quot;Tendencia&quot;, &quot;Estacionalidad diaria (24h)&quot;, &quot;Estacionalidad semanal (7d)&quot;, &quot;Estacionalidad mensual (12)&quot;, &quot;Estacionalidad anual (365d)&quot;, &quot;Residuo&quot;) ) ) # ========== E) Gráfico ========== ggplot(panel_all, aes(x = time, y = Valor)) + geom_line(linewidth = 0.45, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;, drop = FALSE) + scale_x_datetime(date_breaks = &quot;6 months&quot;, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) + labs( title = &quot;Descomposición combinada de la serie completa&quot;, subtitle = &quot;Tendencia + Estacionalidades diaria (24h), semanal (7d), mensual (12) y anual (365d) + Residuo&quot;, x = &quot;Tiempo&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) 4.6.1 Descomposición de la serie por estacionalidades # ============================================================ # Descomposición óptima de la serie: # - Diaria (24h) → serie horaria (MSTL, seasonal.periods=24) # - Semanal (7d) → serie horaria (MSTL, seasonal.periods=168) # - Mensual (12) → serie mensual (STL, frequency=12) # - Anual (365d) → serie diaria (STL, frequency=365) # Gráficos en orden: Observada → Tendencia → Estacionalidad → Residuo # ============================================================ # ==== 0) Utilidades ==== val_col &lt;- if (&quot;val_impu&quot; %in% names(df_impu)) &quot;val_impu&quot; else &quot;VALOR_IMPUTADO&quot; # Detecta, dentro de un data.frame de mstl/stl, la columna estacional de un periodo dado find_seasonal_col &lt;- function(df_comp, target_period) { nm &lt;- names(df_comp) # posibles nombres: &quot;Seasonal-24&quot;, &quot;Seasonal 24&quot;, &quot;seasonal24&quot;, etc. is_seas &lt;- grepl(&quot;^Seasonal&quot;, nm, ignore.case = TRUE) seas_nm &lt;- nm[is_seas] if (!length(seas_nm)) return(NULL) getp &lt;- function(s) { p &lt;- gsub(&quot;[^0-9]&quot;, &quot;&quot;, s); if (nzchar(p)) as.integer(p) else NA_integer_ } periods &lt;- vapply(seas_nm, getp, integer(1)) idx &lt;- which(periods == target_period) if (length(idx)) seas_nm[idx[1]] else NULL } # Devuelve nombres (o NA) para Trend y Remainder segun el objeto mstl/stl find_trend_remainder &lt;- function(df_comp) { nm &lt;- names(df_comp) trend &lt;- nm[grepl(&quot;^Trend$&quot;, nm, ignore.case = TRUE)] remainder &lt;- nm[grepl(&quot;^Remainder$&quot;, nm, ignore.case = TRUE)] list(trend = if (length(trend)) trend[1] else NA_character_, remainder = if (length(remainder)) remainder[1] else NA_character_) } # Constructor genérico de gráfico con orden fijo de facetas plot_decomp &lt;- function(df_wide, time_col_name = &quot;time&quot;, title_txt = &quot;&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) { df_long &lt;- df_wide |&gt; tidyr::pivot_longer(-dplyr::all_of(time_col_name), names_to = &quot;Componente&quot;, values_to = &quot;Valor&quot;) |&gt; dplyr::mutate( Componente = factor( Componente, levels = c(&quot;Observada&quot;,&quot;Tendencia&quot;,&quot;Estacionalidad&quot;,&quot;Residuo&quot;) ) ) p &lt;- ggplot(df_long, aes(x = .data[[time_col_name]], y = Valor)) + geom_line(linewidth = 0.6, alpha = 0.95, na.rm = TRUE) + facet_wrap(~ Componente, ncol = 1, scales = &quot;free_y&quot;) + labs(title = title_txt, x = &quot;Tiempo&quot;, y = &quot;Valor&quot;) + theme_minimal(base_size = 12) + theme(plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank()) if (x_is_date) { p &lt;- p + scale_x_date(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } else { p &lt;- p + scale_x_datetime(date_breaks = date_breaks_main, date_labels = &quot;%b-%Y&quot;) + guides(x = guide_axis(n.dodge = 2)) } p } # ==== 1) Serie HORARIA → diaria(24h) y semanal(168h) con MSTL ==== x_hour &lt;- as.numeric(df_impu[[val_col]]) time_hr &lt;- as.POSIXct(df_impu[[time_col]]) stopifnot(length(x_hour) &gt;= 24*14) # al menos ~2 semanas ts_hour &lt;- forecast::msts(x_hour, seasonal.periods = c(24, 168)) fit_mstl_hr &lt;- forecast::mstl(ts_hour, robust = TRUE) comp_hr &lt;- as.data.frame(fit_mstl_hr) # columnas clave cols_hr &lt;- find_trend_remainder(comp_hr) col_trend_hr &lt;- cols_hr$trend col_rem_hr &lt;- cols_hr$remainder col_s24 &lt;- find_seasonal_col(comp_hr, 24) col_s168 &lt;- find_seasonal_col(comp_hr, 168) # --- A) Diaria (24h) sobre la serie horaria --- df_day24 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s24)) comp_hr[[col_s24]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_day24 &lt;- plot_decomp(df_day24, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición DIARIA (24h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;3 months&quot;) # --- B) Semanal (7d=168h) sobre la serie horaria --- df_week168 &lt;- dplyr::tibble( time = time_hr, Observada = x_hour, Tendencia = if (!is.na(col_trend_hr)) comp_hr[[col_trend_hr]] else NA_real_, Estacionalidad = if (!is.null(col_s168)) comp_hr[[col_s168]] else NA_real_, Residuo = if (!is.na(col_rem_hr)) comp_hr[[col_rem_hr]] else NA_real_ ) p_week168 &lt;- plot_decomp(df_week168, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición SEMANAL (7d = 168h) — serie horaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;6 months&quot;) # ==== 2) Serie MENSUAL → mensual(12) con STL ==== monthly &lt;- df_impu |&gt; dplyr::mutate(mes = lubridate::floor_date(.data[[time_col]], &quot;month&quot;)) |&gt; dplyr::group_by(mes) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(monthly) &gt;= 24) ts_month &lt;- stats::ts( monthly$y, frequency = 12, start = c(lubridate::year(min(monthly$mes)), lubridate::month(min(monthly$mes))) ) fit_stl_m &lt;- stats::stl(ts_month, s.window = &quot;periodic&quot;, robust = TRUE) comp_m &lt;- as.data.frame(fit_stl_m$time.series) # seasonal, trend, remainder # nombres estandar names(comp_m) &lt;- tolower(names(comp_m)) df_month12 &lt;- dplyr::tibble( time = as.Date(monthly$mes), Observada = as.numeric(ts_month), Tendencia = comp_m$trend, Estacionalidad= comp_m$seasonal, Residuo = comp_m$remainder ) p_month12 &lt;- plot_decomp(df_month12, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición MENSUAL (12) — serie mensual&quot;, x_is_date = TRUE, date_breaks_main = &quot;6 months&quot;) # ==== 3) Serie DIARIA → anual(365) con STL ==== daily &lt;- df_impu |&gt; dplyr::mutate(day = lubridate::floor_date(.data[[time_col]], &quot;day&quot;)) |&gt; dplyr::group_by(day) |&gt; dplyr::summarise(y = mean(.data[[val_col]], na.rm = TRUE), .groups = &quot;drop&quot;) stopifnot(nrow(daily) &gt;= 365) # ideal ≥ 2*365 para patrón robusto ts_year &lt;- stats::ts( daily$y, frequency = 365, start = c(lubridate::year(min(daily$day)), as.integer(format(min(daily$day), &quot;%j&quot;))) ) fit_stl_y &lt;- stats::stl(ts_year, s.window = &quot;periodic&quot;, robust = TRUE) comp_y &lt;- as.data.frame(fit_stl_y$time.series) names(comp_y) &lt;- tolower(names(comp_y)) df_year365 &lt;- dplyr::tibble( time = as.POSIXct(daily$day), Observada = as.numeric(ts_year), Tendencia = comp_y$trend, Estacionalidad= comp_y$seasonal, Residuo = comp_y$remainder ) p_year365 &lt;- plot_decomp(df_year365, time_col_name = &quot;time&quot;, title_txt = &quot;Descomposición ANUAL (365d) — serie diaria&quot;, x_is_date = FALSE, date_breaks_main = &quot;1 year&quot;) # ==== 4) Mostrar los 4 gráficos ==== p_day24 p_week168 p_month12 p_year365 Tendencia: suaviza el comportamiento global; muestra una evolución sostenida de la potencia en el tiempo. Estacionalidades: 24 h: patrón diario con repeticiones claras (potencia eléctrica según horas). 7 d: variación semanal con máximos en ciertos días. 12 m: ciclo anual ligado a estaciones o periodos de consumo. 365 d: refina oscilaciones de largo plazo. Residuo: oscilaciones aleatorias sin patrón sistemático. La descomposición MSTL permite aislar múltiples estacionalidades y verificar si cada componente explica variaciones específicas. No requiere transformaciones adicionales al trabajar sobre serie imputada y diferenciada. 4.6.2 Descomposición de la serie en una ventana de 4 semanas t0 &lt;- Sys.time() ini_zoom &lt;- as.POSIXct(&quot;2021-02-01&quot;, tz = TZ) fin_zoom &lt;- ini_zoom + lubridate::weeks(4) seg_4w &lt;- df_impu %&gt;% dplyr::filter(.data[[time_col]] &gt;= ini_zoom, .data[[time_col]] &lt; fin_zoom) ts24_zoom &lt;- ts(as.numeric(seg_4w$val_impu), frequency = 24) fit_stl &lt;- try(stl(ts24_zoom, s.window = &quot;periodic&quot;, robust = TRUE), silent = TRUE) .timing[[&quot;STL (ventana 4 semanas)&quot;]] &lt;- list( seconds = as.numeric(difftime(Sys.time(), t0, units = &quot;secs&quot;)), status = if (inherits(fit_stl, &quot;try-error&quot;)) &quot;ERROR&quot; else &quot;OK&quot;, message = if (inherits(fit_stl, &quot;try-error&quot;)) as.character(fit_stl) else &quot;&quot; ) if (!inherits(fit_stl, &quot;try-error&quot;)) { plot(fit_stl, range.bars = FALSE, main = &quot;STL (ventana de 4 semanas)&quot;) } else { cat(&quot;No se pudo calcular STL (ver mensaje en la tabla de tiempos).\\n&quot;) } Muestra el detalle de la estructura estacional de corto plazo: ciclos diarios consistentes. Permite comprobar estabilidad local de la tendencia y detectar posibles cambios abruptos. Analizar ventanas cortas sirve para validar la homogeneidad de los patrones estacionales dentro del año. 4.7 Selección del modelo eficiente (auto.arima) y Pronóstico tm(&quot;Ajuste SARIMA + Pronóstico&quot;, { y_fit &lt;&lt;- ts(serie_vec, frequency = 24) m_auto &lt;&lt;- forecast::auto.arima( y_fit, d = d_sugerido, seasonal = TRUE, stepwise = TRUE, approximation = arima_approx, max.p = 5, max.q = 5, max.P = 2, max.Q = 2 ) print(m_auto) h_days &lt;&lt;- horizon_days h &lt;&lt;- 24 * h_days fc &lt;&lt;- forecast::forecast(m_auto, h = h) print(autoplot(fc) + labs(title = paste0(&quot;Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;)) }) ## Series: y_fit ## ARIMA(1,1,1)(0,0,2)[24] ## ## Coefficients: ## ar1 ma1 sma1 sma2 ## -0.8940 0.9736 0.0222 0.0110 ## s.e. 0.0023 0.0012 0.0029 0.0028 ## ## sigma^2 = 249612: log likelihood = -905595.9 ## AIC=1811202 AICc=1811202 BIC=1811250 auto.arima selecciona automáticamente (p, d, q) y (P, D, Q)[s] d = 1 (diferenciación no estacional) para eliminar tendencia. [24] como periodicidad diaria. MA/AR estacionales que capturan los picos en ACF/PACF. El modelo incluye diferenciación (d = 1) y componente estacional de 24 h; por tanto, controla la tendencia y la variabilidad residual detectadas en etapas anteriores. SARIMA es apropiado cuando existe estructura autoregresiva + estacionalidad fija. La diferenciación previa y la evidencia ACF/PACF respaldan esta elección. 4.7.1 Zoom al Pronóstico # ==== ZOOM FINAL AL PRONÓSTICO ==== history_days &lt;- 21 h_days &lt;- horizon_days %||% 7 hist_df &lt;- tibble( time = as.POSIXct(df_impu[[time_col]], tz = TZ), y = as.numeric(df_impu$val_impu) ) t_max &lt;- max(hist_df$time, na.rm = TRUE) h &lt;- length(fc$mean) f_times &lt;- seq(from = t_max + hours(1), by = &quot;1 hour&quot;, length.out = h) fc_df &lt;- tibble( time = f_times, mean = as.numeric(fc$mean), lo80 = as.numeric(fc$lower[,&quot;80%&quot;]), hi80 = as.numeric(fc$upper[,&quot;80%&quot;]), lo95 = as.numeric(fc$lower[,&quot;95%&quot;]), hi95 = as.numeric(fc$upper[,&quot;95%&quot;]) ) t_ini &lt;- t_max - days(history_days) t_fin &lt;- max(fc_df$time) hist_zoom &lt;- dplyr::filter(hist_df, time &gt;= t_ini) ggplot() + geom_ribbon(data = fc_df, aes(x = time, ymin = lo95, ymax = hi95), fill = &quot;#1f77b4&quot;, alpha = 0.15, na.rm = TRUE) + geom_ribbon(data = fc_df, aes(x = time, ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25, na.rm = TRUE) + geom_line(data = fc_df, aes(x = time, y = mean), color = &quot;#1f77b4&quot;, linewidth = 1.0, na.rm = TRUE) + geom_line(data = hist_zoom, aes(x = time, y = y), color = &quot;grey40&quot;, linewidth = 0.4, na.rm = TRUE) + scale_x_datetime(limits = c(t_ini, t_fin), date_breaks = &quot;3 days&quot;, # ← espaciado más grande date_labels = &quot;%d-%b&quot;) + # ← formato sin hora coord_cartesian(ylim = c(0, 10000)) + # recorta sin descartar filas labs(title = paste0(&quot;Zoom final del Pronóstico SARIMA (&quot;, h_days, &quot; días)&quot;), subtitle = paste0(&quot;Últimos &quot;, history_days, &quot; días de historia + predicción&quot;), x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal(base_size = 12) + theme( plot.title = element_text(face = &quot;bold&quot;), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1) # ← evita solapamiento ) Línea negra: representa los últimos 21 días de la serie observada, durante este período, la potencia muestra una variabilidad marcada con picos altos (entre 7000 y 10000 unidades) y caídas bruscas hacia valores bajos. Línea azul: corresponde a la predicción puntual generada por el modelo SARIMA para los siguientes 7 días. Esta predicción se mantiene estable y suavizada en comparación con la serie observada, lo que indica que el modelo estima que la potencia tenderá a estabilizarse alrededor de un valor medio cercano a los 4500–5000 unidades. Franjas azules (bandas de confianza): La franja más oscura representa el intervalo de confianza al 80 % y la franja más clara, el intervalo al 95 %. Estas bandas muestran la incertidumbre asociada a la predicción: a medida que el horizonte temporal avanza, las bandas se ensanchan, lo que significa que el modelo tiene menos certeza sobre los valores futuros. El ensanchamiento pronunciado indica que la volatilidad pasada influye fuertemente en la incertidumbre del pronóstico. El modelo sugiere una tendencia de estabilización en los valores de potencia para la semana siguiente. No se anticipan picos extremos ni caídas abruptas. Dado que las bandas de confianza se mantienen dentro del rango esperado (0 – 10000), el ajuste es razonable y coherente con la magnitud de los datos históricos. Las bandas amplias implican que, aunque el modelo capta bien la tendencia general, la precisión puntual es limitada. Esto es común en series con ruido y estacionalidades múltiples. 4.8 Puntos de cambio y visualización daily &lt;- df_impu %&gt;% mutate(day = floor_date(.data[[time_col]], &quot;day&quot;)) %&gt;% group_by(day) %&gt;% summarise(y = mean(val_impu), .groups = &quot;drop&quot;) tm(&quot;Changepoint (media diaria, PELT)&quot;, { cp &lt;&lt;- cpt.mean(daily$y, method = &quot;PELT&quot;, penalty = &quot;SIC&quot;) }) head (cp@cpts,100) # índices de cambio ## [1] 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ## [19] 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 66 ## [37] 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 ## [55] 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## [73] 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 ## [91] 121 123 124 125 126 127 128 129 130 131 # Overlay en la curva diaria ggplot(daily, aes(day, y)) + geom_line() + geom_vline(xintercept = daily$day[cp@cpts], linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Media diaria con puntos de cambio (cpt.mean)&quot;, x = &quot;Día&quot;, y = &quot;Potencia media diaria&quot;) + theme_minimal() El método utilizado (cpt.mean del paquete changepoint) permite identificar momentos en el tiempo donde la media del proceso cambia significativamente, lo cual es muy útil para detectar rupturas, transiciones o alteraciones del régimen de la serie. Líneas negras, corresponden a la serie diaria suavizada. Es decir, los valores promedio por día de la potencia, eliminando la variación horaria interna. Líneas horizontales rojas (puntos de cambio), indican los momentos en que el algoritmo PELT (Pruned Exact Linear Time) identificó cambios estadísticamente significativos en la media. Cada línea roja marca una ruptura: un punto donde el nivel promedio de la serie cambia de forma abrupta o sostenida. La gran cantidad de líneas rojas indica múltiples cambios en la media a lo largo de la serie. Esto sugiere que la potencia no sigue un comportamiento estacionario estable, sino que ha tenido varios periodos con medias distintas —lo cual puede corresponder a modificaciones en la demanda, mantenimiento de equipos, cambios operativos o condiciones externas. Periodo 2018–2020: Los valores son relativamente bajos y estables, con algunos incrementos graduales. Los puntos de cambio aquí podrían asociarse a una transición hacia niveles más altos de consumo o potencia. Periodo 2020–2021: Se observa una mayor volatilidad, con picos y caídas pronunciadas. Es probable que los puntos de cambio detecten episodios transitorios de aumento o reducción drástica. 2022 en adelante: La serie aumenta en nivel medio y muestra mayor dispersión, con valores que alcanzan niveles altos de potencia (&gt;6000). Las múltiples líneas rojas en esta etapa indican fluctuaciones más frecuentes, reflejando un sistema con variabilidad estructural más alta o cambios en los patrones de uso. La serie de potencia no es homogénea en el tiempo: exhibe múltiples cambios estructurales en su comportamiento medio. Estos cambios pueden ser interpretados como etapas operativas o periodos de régimen distinto, lo que justifica la necesidad de aplicar modelos con parámetros variables o segmentados.. La alta frecuencia de cambios después de 2022 podría indicar mayor inestabilidad del sistema o sensibilidad a factores externos, lo cual también se relaciona con la amplia incertidumbre observada en las bandas del pronóstico SARIMA. 4.9 Outliers y verificación de supuestos del ARIMA # Outliers to &lt;- tryCatch(forecast::tsoutliers(ts(serie_vec, frequency = 24)), error = function(e) NULL) if (!is.null(to)) { #print(to) idx &lt;- to$index df_ol &lt;- tibble(time = as.POSIXct(df_impu[[time_col]])[idx], y = serie_vec[idx]) ggplot(tibble(time = as.POSIXct(df_impu[[time_col]]), y = serie_vec), aes(time, y)) + geom_line(alpha = 0.6) + geom_point(data = df_ol, aes(time, y), color = &quot;red&quot;, size = 1.4) + labs(title = &quot;Outliers detectados (forecast::tsoutliers)&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia&quot;) + theme_minimal() } El análisis de valores atípicos (outliers) identifica puntos que se desvían significativamente del patrón esperado de la serie, considerando su tendencia, estacionalidad y variabilidad histórica. Línea gris: Muestra la serie temporal original de potencia, donde se pueden observar los patrones de oscilación, los aumentos progresivos y los periodos de mayor variabilidad. Puntos rojos: Señalan los outliers detectados automáticamente por el algoritmo de tsoutliers.Estos puntos representan valores que el modelo considera anómalos, es decir, que se alejan más de lo esperado de acuerdo con la estructura de tendencia y estacionalidad estimada. 2018–2019: Pocos outliers, mayormente en valores bajos, lo que sugiere una etapa relativamente estable. 2020–2021: Aumenta la cantidad de outliers tanto por exceso como por defecto (picos y caídas abruptas).Esto puede estar asociado con eventos externos (fallos eléctricos, cambios en la demanda o mantenimiento del sistema) o ajustes en la infraestructura que alteraron momentáneamente los registros. 2022–2025: Se observa una alta concentración de outliers en la parte superior de la serie, especialmente en los valores más altos de potencia (por encima de 7500). Esto indica un incremento de la variabilidad o posiblemente una saturación del sistema, donde las mediciones superan los niveles esperados con frecuencia.También podría sugerir la presencia de nuevas condiciones operativas no captadas por el modelo (por ejemplo, aumento de la capacidad instalada o un cambio en los hábitos de consumo). Los outliers más extremos se presentan en valores cercanos a 0 y por encima de 9000, indicando errores o comportamientos anómalos graves. En los periodos intermedios (2019–2020 y 2023–2024), los picos son muy frecuentes, lo que puede afectar la estimación de parámetros del modelo si no se tratan adecuadamente. La presencia de tantos outliers sugiere que la serie presenta eventos atípicos recurrentes, los cuales rompen la suposición de normalidad y homocedasticidad requerida por muchos modelos de series temporales. Es recomendable tratar o ajustar estos valores antes del modelado. # Supuestos del modelo ARIMA (residuales) checkresiduals(m_auto) # ACF de residuales, Ljung-Box, histograma, qq-plot ## ## Ljung-Box test ## ## data: Residuals from ARIMA(1,1,1)(0,0,2)[24] ## Q* = 3889, df = 44, p-value &lt; 2.2e-16 ## ## Model df: 4. Total lags used: 48 Ljung-Box test La prueba de Ljung–Box aplicada a los residuales del modelo ARIMA(1,1,1)(0,0,2)[24], se realiza para evaluar la independencia (no autocorrelación) de los residuos en un modelo de series temporales. El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, los residuos presentan autocorrelación, el modelo no explica completamente la dependencia temporal. Los residuos NO son ruido blanco, es decir, conservan autocorrelación significativa a lo largo del tiempo. Diagnósticos residuales del modelo ARIMA(1,1,1)(0,0,2)[24] Estas tres gráficas es evaluar si los residuos del modelo cumplen los supuestos de un buen ajuste estadístico: independencia, homocedasticidad y normalidad. La primera gráfica representa los residuos en el tiempo (diferencia entre los valores observados y los predichos por el modelo ARIMA). Cada punto corresponde al error de predicción en una hora. Los residuos oscilan alrededor de 0, lo cual es un signo deseable. Sin embargo, la amplitud de las oscilaciones aumenta considerablemente con el tiempo (desde 2020 en adelante). Esto evidencia heterocedasticidad, la varianza de los errores no es constante a lo largo del tiempo. Hay picos extremos, tanto positivos como negativos (superiores a ±10.000), lo que sugiere la presencia de outliers o errores sistemáticos del modelo en determinados periodos. Las secciones con mayor densidad de oscilaciones indican que el modelo no logra seguir bien los cambios de nivel o tendencia en esas etapas (por ejemplo, entre 2022 y 2025, coincidiendo con tus resultados de cambio estructural). Los residuos no son homogéneos ni estacionarios en varianza. Esto implica que el modelo ARIMA(1,1,1)(0,0,2)[24] no captura completamente la dinámica temporal ni la variabilidad creciente de la serie. ACF (Función de Autocorrelación de los residuos), mide la dependencia serial entre los residuos en diferentes rezagos (lags). Las líneas azules representan los límites de confianza (±1.96/√n), dentro de los cuales las autocorrelaciones deberían estar si los residuos fueran puro ruido blanco. En los primeros rezagos (1–10), se aprecian barras que superan los límites de confianza, indicando autocorrelación significativa. A partir del lag 24 (una periodicidad diaria), todavía se observa un patrón repetitivo leve, lo que sugiere persistencia estacional no explicada. El resto de los lags muestran valores cercanos a 0, pero el exceso inicial es suficiente para rechazar la hipótesis de independencia. Los residuos no son completamente independientes, existen dependencias a corto plazo (y posiblemente estacionales) que el modelo no eliminó. Esto coincide con el resultado del test de Ljung–Box, que arrojó un p-valor &lt; 2.2e-16, confirmando la autocorrelación residual. Histograma y densidad de los residuos, muestra la distribución de los errores del modelo comparada con una curva normal teórica (línea roja). La distribución está altamente concentrada en torno a 0, pero con colas muy largas y picos extremos. Es decir, los residuos no siguen una distribución normal (hay asimetría y curtosis alta). Existen muchos valores extremos tanto positivos como negativos, coherentes con los outliers detectados. La curva teórica normal (en rojo) es mucho más estrecha que la real, lo que confirma la no normalidad de los residuos. Los residuos no son normales, presentando colas pesadas y picos excesivos.Esto sugiere que el modelo no solo deja autocorrelación, sino también errores estructurados y variabilidad anómala. Las tres gráficas indican que el modelo ARIMA(1,1,1)(0,0,2)[24] no logra capturar completamente la estructura de la serie temporal. Los residuos conservan autocorrelación, varianza no constante y outliers, por lo que no pueden considerarse ruido blanco. 4.9.1 Q–Q Plot de los residuos del modelo ARIMA # 1) Extraer residuos del modelo ajustado residuales &lt;- residuals(m_auto) # 2) Q-Q Plot base (comparación con distribución normal) qqnorm(residuales, main = &quot;Q–Q Plot de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24]&quot;, xlab = &quot;Cuantiles teóricos (Normal)&quot;, ylab = &quot;Cuantiles de los residuos&quot;, pch = 19, col = &quot;#1f77b4&quot;, cex = 0.8) qqline(residuales, col = &quot;red&quot;, lwd = 2) El Q–Q Plot (Quantile–Quantile Plot) de los residuos del modelo ARIMA(1,1,1)(0,0,2)[24], una herramienta fundamental para evaluar la normalidad de los errores del modelo. En el eje X (horizontal) se representan los cuantiles teóricos de una distribución normal estándar. En el eje Y (vertical) se muestran los cuantiles observados de los residuos del modelo. La línea roja representa la situación ideal, si los residuos fueran perfectamente normales, los puntos azules se alinearían a lo largo de esa línea. Los puntos se desvían fuertemente de la línea roja, formando una curva escalonada y asimétrica. En las colas (extremos izquierdo y derecho) se observan valores alejados de la recta, indicando colas pesadas o valores extremos. En la zona central (cercana a 0), los puntos permanecen relativamente agrupados, pero el patrón general muestra una marcada asimetría vertical, con una diferencia notable entre los residuos negativos (abajo) y positivos (arriba). La forma escalonada del gráfico indica que los residuos no siguen una distribución normal. Los valores extremos (outliers) son responsables de la curvatura al inicio y al final del gráfico. 4.10 Transformación logarítmica para estabilizar la varianza # ============================================================ # Transformación logarítmica de la serie de potencia # ============================================================ # Evitar log(0) o negativos df_log &lt;- df_impu %&gt;% mutate(val_log = log1p(val_impu)) # log(1 + x) evita infinitos # Crear serie temporal log-transformada ts_log &lt;- ts(df_log$val_log, frequency = 24) # frecuencia diaria (24 horas) # Visualización básica autoplot(ts_log) + labs(title = &quot;Serie transformada logarítmicamente (log1p)&quot;, y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal() La transformación logarítmica se aplicó para reducir la heterocedasticidad (variabilidad creciente con el nivel de la serie), atenuar los valores extremos (outliers), especialmente los picos de alta potencia y aproximar la distribución de los datos a la normalidad, facilitando la aplicación del modelo ARIMA. En otras palabras, se busca estabilizar la varianza y mejorar el cumplimiento de los supuestos del modelo. En la gráfica se observa un comportamiento estructural similar al de la serie original, pero con amplitud comprimida; los picos muy altos (de más de 10.000 en escala original) se reducen a valores entre 7 y 9 en log(1+x); las fluctuaciones bruscas entre periodos de alta y baja potencia se suavizan notablemente; aun cuando existen saltos entre periodos (régimenes distintos), la variabilidad interna dentro de cada tramo es mucho más homogénea. La serie transformada conserva la estructura temporal fundamental (tendencia y estacionalidad) pero elimina gran parte del ruido que dificulta el modelado. 4.11 Ajuste del modelo ARIMA en escala logarítmica # ============================================================ # Ajuste automático ARIMA sobre serie log-transformada # ============================================================ tm(&quot;Ajuste SARIMA TS log-transformada&quot;, { m_log &lt;&lt;- auto.arima(ts_log, seasonal = TRUE, stepwise = FALSE, approximation = arima_approx, trace = TRUE) summary(m_log) }) ## ## Fitting models using approximations to speed things up... ## ## ARIMA(0,1,0) : 114852.4 ## ARIMA(0,1,0) with drift : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] : 114854.4 ## ARIMA(0,1,0)(0,0,1)[24] with drift : 114856.4 ## ARIMA(0,1,0)(0,0,2)[24] : 114855.9 ## ARIMA(0,1,0)(0,0,2)[24] with drift : 114857.9 ## ARIMA(0,1,0)(1,0,0)[24] : 114878.2 ## ARIMA(0,1,0)(1,0,0)[24] with drift : 114880.2 ## ARIMA(0,1,0)(1,0,1)[24] : Inf ## ARIMA(0,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(1,0,2)[24] : Inf ## ARIMA(0,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,0)[24] : 114903.7 ## ARIMA(0,1,0)(2,0,0)[24] with drift : 114905.7 ## ARIMA(0,1,0)(2,0,1)[24] : Inf ## ARIMA(0,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,0)(2,0,2)[24] : 114907.7 ## ARIMA(0,1,0)(2,0,2)[24] with drift : 114909.7 ## ARIMA(0,1,1) : 114849.4 ## ARIMA(0,1,1) with drift : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] : 114851.4 ## ARIMA(0,1,1)(0,0,1)[24] with drift : 114853.4 ## ARIMA(0,1,1)(0,0,2)[24] : 114853 ## ARIMA(0,1,1)(0,0,2)[24] with drift : 114854.9 ## ARIMA(0,1,1)(1,0,0)[24] : 114875.2 ## ARIMA(0,1,1)(1,0,0)[24] with drift : 114877.2 ## ARIMA(0,1,1)(1,0,1)[24] : Inf ## ARIMA(0,1,1)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(1,0,2)[24] : Inf ## ARIMA(0,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,0)[24] : 114900.7 ## ARIMA(0,1,1)(2,0,0)[24] with drift : 114902.7 ## ARIMA(0,1,1)(2,0,1)[24] : Inf ## ARIMA(0,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,1)(2,0,2)[24] : 114904.7 ## ARIMA(0,1,1)(2,0,2)[24] with drift : 114906.7 ## ARIMA(0,1,2) : 114534.4 ## ARIMA(0,1,2) with drift : 114536.4 ## ARIMA(0,1,2)(0,0,1)[24] : 114536.2 ## ARIMA(0,1,2)(0,0,1)[24] with drift : 114538.2 ## ARIMA(0,1,2)(0,0,2)[24] : 114537.7 ## ARIMA(0,1,2)(0,0,2)[24] with drift : 114539.7 ## ARIMA(0,1,2)(1,0,0)[24] : 114560.1 ## ARIMA(0,1,2)(1,0,0)[24] with drift : 114562.1 ## ARIMA(0,1,2)(1,0,1)[24] : Inf ## ARIMA(0,1,2)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,2)(1,0,2)[24] : Inf ## ARIMA(0,1,2)(1,0,2)[24] with drift : Inf ## ARIMA(0,1,2)(2,0,0)[24] : 114585.5 ## ARIMA(0,1,2)(2,0,0)[24] with drift : 114587.5 ## ARIMA(0,1,2)(2,0,1)[24] : Inf ## ARIMA(0,1,2)(2,0,1)[24] with drift : Inf ## ARIMA(0,1,3) : 114522.7 ## ARIMA(0,1,3) with drift : 114524.6 ## ARIMA(0,1,3)(0,0,1)[24] : 114524.4 ## ARIMA(0,1,3)(0,0,1)[24] with drift : 114526.4 ## ARIMA(0,1,3)(0,0,2)[24] : 114526 ## ARIMA(0,1,3)(0,0,2)[24] with drift : 114528 ## ARIMA(0,1,3)(1,0,0)[24] : 114548.3 ## ARIMA(0,1,3)(1,0,0)[24] with drift : 114550.3 ## ARIMA(0,1,3)(1,0,1)[24] : Inf ## ARIMA(0,1,3)(1,0,1)[24] with drift : Inf ## ARIMA(0,1,3)(2,0,0)[24] : 114573.7 ## ARIMA(0,1,3)(2,0,0)[24] with drift : 114575.7 ## ARIMA(0,1,4) : 104511.7 ## ARIMA(0,1,4) with drift : 104513.7 ## ARIMA(0,1,4)(0,0,1)[24] : 104481.2 ## ARIMA(0,1,4)(0,0,1)[24] with drift : 104483.2 ## ARIMA(0,1,4)(1,0,0)[24] : 104504.9 ## ARIMA(0,1,4)(1,0,0)[24] with drift : 104506.9 ## ARIMA(0,1,5) : 104454.2 ## ARIMA(0,1,5) with drift : 104456.2 ## ARIMA(1,1,0) : 114850.7 ## ARIMA(1,1,0) with drift : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] : 114852.7 ## ARIMA(1,1,0)(0,0,1)[24] with drift : 114854.7 ## ARIMA(1,1,0)(0,0,2)[24] : 114854.3 ## ARIMA(1,1,0)(0,0,2)[24] with drift : 114856.3 ## ARIMA(1,1,0)(1,0,0)[24] : 114876.6 ## ARIMA(1,1,0)(1,0,0)[24] with drift : 114878.6 ## ARIMA(1,1,0)(1,0,1)[24] : Inf ## ARIMA(1,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(1,0,2)[24] : Inf ## ARIMA(1,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,0)[24] : 114902.1 ## ARIMA(1,1,0)(2,0,0)[24] with drift : 114904.1 ## ARIMA(1,1,0)(2,0,1)[24] : Inf ## ARIMA(1,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,0)(2,0,2)[24] : 114906.1 ## ARIMA(1,1,0)(2,0,2)[24] with drift : 114908.1 ## ARIMA(1,1,1) : 111225.1 ## ARIMA(1,1,1) with drift : 111227.1 ## ARIMA(1,1,1)(0,0,1)[24] : 111226.3 ## ARIMA(1,1,1)(0,0,1)[24] with drift : 111228.3 ## ARIMA(1,1,1)(0,0,2)[24] : 111226.8 ## ARIMA(1,1,1)(0,0,2)[24] with drift : 111228.8 ## ARIMA(1,1,1)(1,0,0)[24] : 111250.2 ## ARIMA(1,1,1)(1,0,0)[24] with drift : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] : 111252.2 ## ARIMA(1,1,1)(1,0,1)[24] with drift : 111254.2 ## ARIMA(1,1,1)(1,0,2)[24] : Inf ## ARIMA(1,1,1)(1,0,2)[24] with drift : Inf ## ARIMA(1,1,1)(2,0,0)[24] : 111274.5 ## ARIMA(1,1,1)(2,0,0)[24] with drift : 111276.5 ## ARIMA(1,1,1)(2,0,1)[24] : Inf ## ARIMA(1,1,1)(2,0,1)[24] with drift : Inf ## ARIMA(1,1,2) : 107610.3 ## ARIMA(1,1,2) with drift : 107612 ## ARIMA(1,1,2)(0,0,1)[24] : 107611.4 ## ARIMA(1,1,2)(0,0,1)[24] with drift : 107613.1 ## ARIMA(1,1,2)(0,0,2)[24] : 107612.9 ## ARIMA(1,1,2)(0,0,2)[24] with drift : 107614.5 ## ARIMA(1,1,2)(1,0,0)[24] : 107635.3 ## ARIMA(1,1,2)(1,0,0)[24] with drift : 107637 ## ARIMA(1,1,2)(1,0,1)[24] : 107637.3 ## ARIMA(1,1,2)(1,0,1)[24] with drift : 107639 ## ARIMA(1,1,2)(2,0,0)[24] : 107660.6 ## ARIMA(1,1,2)(2,0,0)[24] with drift : 107662.3 ## ARIMA(1,1,3) : 107440.7 ## ARIMA(1,1,3) with drift : 107442.4 ## ARIMA(1,1,3)(0,0,1)[24] : 107442.1 ## ARIMA(1,1,3)(0,0,1)[24] with drift : 107443.7 ## ARIMA(1,1,3)(1,0,0)[24] : 107466 ## ARIMA(1,1,3)(1,0,0)[24] with drift : 107467.7 ## ARIMA(1,1,4) : 104357.1 ## ARIMA(1,1,4) with drift : 104359.1 ## ARIMA(2,1,0) : 114693.2 ## ARIMA(2,1,0) with drift : 114695.2 ## ARIMA(2,1,0)(0,0,1)[24] : 114695.1 ## ARIMA(2,1,0)(0,0,1)[24] with drift : 114697.1 ## ARIMA(2,1,0)(0,0,2)[24] : 114696.6 ## ARIMA(2,1,0)(0,0,2)[24] with drift : 114698.6 ## ARIMA(2,1,0)(1,0,0)[24] : 114718.9 ## ARIMA(2,1,0)(1,0,0)[24] with drift : 114720.9 ## ARIMA(2,1,0)(1,0,1)[24] : Inf ## ARIMA(2,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(2,1,0)(1,0,2)[24] : Inf ## ARIMA(2,1,0)(1,0,2)[24] with drift : Inf ## ARIMA(2,1,0)(2,0,0)[24] : 114744.4 ## ARIMA(2,1,0)(2,0,0)[24] with drift : 114746.4 ## ARIMA(2,1,0)(2,0,1)[24] : Inf ## ARIMA(2,1,0)(2,0,1)[24] with drift : Inf ## ARIMA(2,1,1) : 107556.5 ## ARIMA(2,1,1) with drift : 107558.1 ## ARIMA(2,1,1)(0,0,1)[24] : 107557.7 ## ARIMA(2,1,1)(0,0,1)[24] with drift : 107559.4 ## ARIMA(2,1,1)(0,0,2)[24] : 107559.3 ## ARIMA(2,1,1)(0,0,2)[24] with drift : 107561 ## ARIMA(2,1,1)(1,0,0)[24] : 107581.6 ## ARIMA(2,1,1)(1,0,0)[24] with drift : 107583.2 ## ARIMA(2,1,1)(1,0,1)[24] : 107583.6 ## ARIMA(2,1,1)(1,0,1)[24] with drift : 107585.2 ## ARIMA(2,1,1)(2,0,0)[24] : 107606.9 ## ARIMA(2,1,1)(2,0,0)[24] with drift : 107608.6 ## ARIMA(2,1,2) : 104088.8 ## ARIMA(2,1,2) with drift : 104090.5 ## ARIMA(2,1,2)(0,0,1)[24] : 104087.4 ## ARIMA(2,1,2)(0,0,1)[24] with drift : 104089 ## ARIMA(2,1,2)(1,0,0)[24] : 104111.2 ## ARIMA(2,1,2)(1,0,0)[24] with drift : 104112.9 ## ARIMA(2,1,3) : 104080.4 ## ARIMA(2,1,3) with drift : 104082.1 ## ARIMA(3,1,0) : 114683 ## ARIMA(3,1,0) with drift : 114685 ## ARIMA(3,1,0)(0,0,1)[24] : 114684.9 ## ARIMA(3,1,0)(0,0,1)[24] with drift : 114686.9 ## ARIMA(3,1,0)(0,0,2)[24] : 114686.5 ## ARIMA(3,1,0)(0,0,2)[24] with drift : 114688.5 ## ARIMA(3,1,0)(1,0,0)[24] : 114708.8 ## ARIMA(3,1,0)(1,0,0)[24] with drift : 114710.8 ## ARIMA(3,1,0)(1,0,1)[24] : Inf ## ARIMA(3,1,0)(1,0,1)[24] with drift : Inf ## ARIMA(3,1,0)(2,0,0)[24] : 114734.2 ## ARIMA(3,1,0)(2,0,0)[24] with drift : 114736.2 ## ARIMA(3,1,1) : 107367.9 ## ARIMA(3,1,1) with drift : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] : 107369.6 ## ARIMA(3,1,1)(0,0,1)[24] with drift : 107371.3 ## ARIMA(3,1,1)(1,0,0)[24] : 107393.5 ## ARIMA(3,1,1)(1,0,0)[24] with drift : 107395.2 ## ARIMA(3,1,2) : 104077.9 ## ARIMA(3,1,2) with drift : 104079.5 ## ARIMA(4,1,0) : 107261.2 ## ARIMA(4,1,0) with drift : 107263.2 ## ARIMA(4,1,0)(0,0,1)[24] : 107260.4 ## ARIMA(4,1,0)(0,0,1)[24] with drift : 107262.4 ## ARIMA(4,1,0)(1,0,0)[24] : 107284.3 ## ARIMA(4,1,0)(1,0,0)[24] with drift : 107286.3 ## ARIMA(4,1,1) : 107262.6 ## ARIMA(4,1,1) with drift : 107264.6 ## ARIMA(5,1,0) : 107263.9 ## ARIMA(5,1,0) with drift : 107265.9 ## ## Now re-fitting the best model(s) without approximations... ## ## ## ## ## Best model: ARIMA(3,1,2) El mejor modelo ARIMA(3,1,2) tiene: Tres términos autorregresivos (AR), la serie depende de los tres valores anteriores de sí misma. Diferenciación (d=1), se toma la primera diferencia para estabilizar la tendencia. Dos términos de media móvil (MA) presentaron el menor AICc (Akaike Information Criterion corregido), por tanto, el mejor equilibrio entre ajuste y simplicidad. ARIMA(3,1,2) describe una dinámica compleja pero estable, donde tanto la inercia de los valores pasados como los errores anteriores influyen en la predicción actual. 4.12 Verificación de supuestos del nuevo modelo # ============================================================ # Diagnóstico de los residuos del modelo ARIMA (log) # ============================================================ checkresiduals(m_log) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(3,1,2) ## Q* = 3151.5, df = 43, p-value &lt; 2.2e-16 ## ## Model df: 5. Total lags used: 48 Ljung-Box test El valor p-value &lt; 2.2e-16, se rechaza la hipótesis nula H₀, por lo tanto, existe autocorrelación significativa en los errores a ciertos rezagos. El modelo ARIMA(3,1,2), aunque mejora respecto al anterior, no captura toda la estructura dependiente de la serie. Diagnósticos residuales del modelo ARIMA(3,1,2) Los residuos son en general estacionarios, pero aún presentan fluctuaciones en la varianza y algunos picos pronunciados que podrían afectar la normalidad. El modelo logra reducir significativamente la autocorrelación, aunque persisten correlaciones menores en rezagos cortos, coherentes con el resultado del test de Ljung–Box La distribución de los residuos se aproxima a la normalidad, aunque no perfectamente. La transformación logarítmica ayudó a estabilizar la varianza, pero persisten valores extremos. 4.13 Pronóstico con el modelo mejorado (escala logarítmica) # ============================================================ # Pronóstico en escala logarítmica # ============================================================ h &lt;- 24 * horizon_days # pronóstico a 7 días (horas) fc_log &lt;- forecast(m_log, h = h) autoplot(fc_log) + labs(title = paste0(&quot;Pronóstico log-transformado con ARIMA (&quot;, horizon_days, &quot; días)&quot;), y = &quot;log(1 + Potencia)&quot;, x = &quot;Tiempo&quot;) + theme_minimal(base_size = 12) 4.13.1 Reconversión a escala original (exponencial inversa) # ============================================================ # Transformar el pronóstico a escala original # ============================================================ fc_exp &lt;- expm1(fc_log$mean) # inversa de log1p fc_exp80 &lt;- expm1(fc_log$lower[,&quot;80%&quot;]) fc_exp95 &lt;- expm1(fc_log$upper[,&quot;95%&quot;]) # Crear data frame para visualización f_times &lt;- seq(from = max(df_impu[[time_col]]) + lubridate::hours(1), by = &quot;1 hour&quot;, length.out = h) fc_plot &lt;- tibble( time = f_times, mean = fc_exp, lo80 = fc_exp80, hi80 = fc_exp95 ) # Graficar pronóstico en escala original ggplot(fc_plot, aes(x = time, y = mean)) + geom_ribbon(aes(ymin = lo80, ymax = hi80), fill = &quot;#1f77b4&quot;, alpha = 0.25) + geom_line(color = &quot;#1f77b4&quot;, linewidth = 1.1) + labs(title = &quot;Pronóstico ARIMA (log-transformado, 7 días)&quot;, subtitle = &quot;Transformación log(1 + x) revertida a escala original&quot;, x = &quot;Tiempo&quot;, y = &quot;Potencia estimada&quot;) + theme_minimal(base_size = 12) El modelo proyecta una potencia promedio estable a lo largo del horizonte de 7 días, con un leve crecimiento progresivo. Este patrón indica que no se esperan cambios abruptos ni tendencia marcada en el corto plazo, lo cual concuerda con una serie que, tras la transformación y diferenciación, se comporta de manera estacionaria. Las bandas de confianza se ensanchán conforme avanza el tiempo, lo que es normal en modelos ARIMA: la incertidumbre aumenta al alejarnos de la última observación disponible. La transformación log1p() redujo la asimetría de la serie, estabilizó la varianza y permitió que el modelo ARIMA se ajustara mejor. Al revertir la transformación (exp(x) - 1), los valores pronosticados se amplifican exponencialmente, por lo que incluso pequeñas variaciones en los residuos logarítmicos se traducen en grandes rangos de incertidumbre en la escala original. 4.14 Conclusiones El análisis realizado sobre la serie temporal de potencia permitió evaluar y comparar el desempeño del modelo ARIMA bajo dos enfoques: primero, utilizando la serie en su escala original, y posteriormente aplicando una transformación logarítmica (log1p) para estabilizar la varianza y mejorar la capacidad predictiva del modelo. Modelo con la serie original El ajuste inicial con el modelo ARIMA(1,1,1)(0,0,2)[24] mostró limitaciones en los residuos: El test de Ljung–Box (Q = 3889, p &lt; 0.05)* reveló autocorrelación significativa, indicando que el modelo no capturó completamente la estructura temporal de los datos. Los gráficos diagnósticos evidenciaron heterocedasticidad y valores atípicos, lo cual afectó la normalidad de los residuos. En consecuencia, aunque el modelo reprodujo la tendencia general, su precisión predictiva fue limitada y las bandas de confianza del pronóstico resultaron amplias e inestables. Modelo con la serie log-transformada Para mejorar el comportamiento del modelo, se aplicó una transformación logarítmica que redujo la variabilidad extrema y permitió una distribución más simétrica. El modelo seleccionado automáticamente fue ARIMA(3,1,2), que presentó un AIC significativamente menor (≈ 104 080 frente a &gt;111 000 en la serie original), reflejando un mejor ajuste global. Los residuos del modelo se centraron alrededor de cero, con autocorrelación mínima y distribución casi normal. El test de Ljung–Box (Q = 3151, p &lt; 0.05)* indicó todavía cierta dependencia remanente, aunque en menor grado que el modelo previo. El pronóstico a 7 días, una vez revertida la transformación (exp(x) - 1), mostró una tendencia estable y coherente con el comportamiento reciente de la serie, con bandas de confianza más razonables que en el caso anterior, aunque naturalmente amplias por la incertidumbre acumulada. En conclusión, el modelo ARIMA aplicado sobre la serie original permitió identificar la tendencia general, pero su desempeño predictivo se vio afectado por la alta varianza y la presencia de valores atípicos. En contraste, la aplicación de la transformación logarítmica mejoró la calidad del ajuste, redujo la dispersión y generó un modelo ARIMA(3,1,2) más parsimonioso y estable, con predicciones más coherentes y bandas de confianza razonables. En términos prácticos, se evidencia que la transformación logarítmica es una estrategia efectiva para estabilizar la varianza y mejorar la capacidad de predicción de modelos ARIMA en series con gran amplitud y comportamiento no estacionario. Por tanto, se recomienda utilizar la versión log-transformada para futuras predicciones y análisis, dado que ofrece un mejor equilibrio entre ajuste, estabilidad y capacidad interpretativa, reflejando de manera más realista la evolución de la potencia en el tiempo. Se recomienda analizar los valores de potencia de la serie de tiempo de forma independiente para cada uno de los tres circuitos eléctricos que conforman la potencia de salida de la subestación. Asimismo, se sugiere generar predicciones individuales por circuito y consolidarlas posteriormente. Esta estrategia permite evitar problemas de valores faltantes y atípicos, además de reducir la variabilidad de los datos. 4.14.1 Resumen de tiempos de ejecución del código tabla_tiempos &lt;- report_timing_table() if (!is.null(tabla_tiempos)) { knitr::kable(tabla_tiempos, caption = &quot;Resumen de tiempos por bloque&quot;) } else { cat(&quot;No se registraron bloques cronometrados.\\n&quot;) } Table 4.1: Resumen de tiempos por bloque Bloque Tiempo Unidad Estado Mensaje Imputación (na.interp) 0.016 s OK ACF/PACF (original) 0.113 s OK ACF/PACF (diferenciada) 0.105 s OK STL (ventana 4 semanas) 0.018 s OK Ajuste SARIMA + Pronóstico 181.854 s OK Changepoint (media diaria, PELT) 0.026 s OK Ajuste SARIMA TS log-transformada 337.818 s OK "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
